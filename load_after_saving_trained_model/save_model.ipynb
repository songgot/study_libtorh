{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9c762b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f770885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7600b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.Tensor([\n",
    "    [0,0],\n",
    "    [1,0],\n",
    "    [1,1],\n",
    "    [0,0],\n",
    "    [0,0],\n",
    "    [0,1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91221f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = torch.LongTensor([\n",
    "    0, # etc\n",
    "    1, # mammal\n",
    "    2, # birds\n",
    "    0,\n",
    "    0,\n",
    "    2\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3310ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.w1 = nn.Linear(2, 10)\n",
    "        self.bias1 = torch.zeros([10])\n",
    "\n",
    "        self.w2 = nn.Linear(10, 3)\n",
    "        self.bias2 = torch.zeros([3])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.w1(x) + self.bias1\n",
    "        y = self.relu(y)\n",
    "\n",
    "        y = self.w2(y) + self.bias2\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "058afd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a2db0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss() #손실함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "959ccfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c573f4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6055, -0.9689, -0.3881],\n",
      "        [-0.4583,  0.3857,  0.3464],\n",
      "        [-1.9124,  0.1971,  2.2112],\n",
      "        [ 1.6055, -0.9689, -0.3881],\n",
      "        [ 1.6055, -0.9689, -0.3881],\n",
      "        [-0.0201, -1.1072,  1.6573]], grad_fn=<AddBackward0>)\n",
      "progress: 0 loss= 0.3020242154598236\n",
      "tensor([[ 1.6068, -0.9702, -0.3883],\n",
      "        [-0.4590,  0.3859,  0.3468],\n",
      "        [-1.9146,  0.1969,  2.2134],\n",
      "        [ 1.6068, -0.9702, -0.3883],\n",
      "        [ 1.6068, -0.9702, -0.3883],\n",
      "        [-0.0212, -1.1082,  1.6593]], grad_fn=<AddBackward0>)\n",
      "progress: 1 loss= 0.30169597268104553\n",
      "tensor([[ 1.6080, -0.9702, -0.3895],\n",
      "        [-0.4594,  0.3876,  0.3457],\n",
      "        [-1.9172,  0.1993,  2.2142],\n",
      "        [ 1.6080, -0.9702, -0.3895],\n",
      "        [ 1.6080, -0.9702, -0.3895],\n",
      "        [-0.0215, -1.1081,  1.6598]], grad_fn=<AddBackward0>)\n",
      "progress: 2 loss= 0.3012702763080597\n",
      "tensor([[ 1.6094, -0.9715, -0.3898],\n",
      "        [-0.4601,  0.3877,  0.3461],\n",
      "        [-1.9194,  0.1991,  2.2165],\n",
      "        [ 1.6094, -0.9715, -0.3898],\n",
      "        [ 1.6094, -0.9715, -0.3898],\n",
      "        [-0.0226, -1.1091,  1.6617]], grad_fn=<AddBackward0>)\n",
      "progress: 3 loss= 0.3009260594844818\n",
      "tensor([[ 1.6105, -0.9715, -0.3909],\n",
      "        [-0.4606,  0.3894,  0.3450],\n",
      "        [-1.9221,  0.2015,  2.2172],\n",
      "        [ 1.6105, -0.9715, -0.3909],\n",
      "        [ 1.6105, -0.9715, -0.3909],\n",
      "        [-0.0229, -1.1090,  1.6623]], grad_fn=<AddBackward0>)\n",
      "progress: 4 loss= 0.30051910877227783\n",
      "tensor([[ 1.6121, -0.9728, -0.3913],\n",
      "        [-0.4612,  0.3894,  0.3454],\n",
      "        [-1.9243,  0.2014,  2.2195],\n",
      "        [ 1.6121, -0.9728, -0.3913],\n",
      "        [ 1.6121, -0.9728, -0.3913],\n",
      "        [-0.0240, -1.1100,  1.6642]], grad_fn=<AddBackward0>)\n",
      "progress: 5 loss= 0.3001587986946106\n",
      "tensor([[ 1.6130, -0.9728, -0.3922],\n",
      "        [-0.4617,  0.3912,  0.3443],\n",
      "        [-1.9269,  0.2037,  2.2203],\n",
      "        [ 1.6130, -0.9728, -0.3922],\n",
      "        [ 1.6130, -0.9728, -0.3922],\n",
      "        [-0.0243, -1.1099,  1.6648]], grad_fn=<AddBackward0>)\n",
      "progress: 6 loss= 0.299770712852478\n",
      "tensor([[ 1.6148, -0.9741, -0.3929],\n",
      "        [-0.4623,  0.3912,  0.3447],\n",
      "        [-1.9291,  0.2036,  2.2226],\n",
      "        [ 1.6148, -0.9741, -0.3929],\n",
      "        [ 1.6148, -0.9741, -0.3929],\n",
      "        [-0.0254, -1.1109,  1.6667]], grad_fn=<AddBackward0>)\n",
      "progress: 7 loss= 0.2993942201137543\n",
      "tensor([[ 1.6155, -0.9741, -0.3936],\n",
      "        [-0.4629,  0.3930,  0.3436],\n",
      "        [-1.9317,  0.2059,  2.2233],\n",
      "        [ 1.6155, -0.9741, -0.3936],\n",
      "        [ 1.6155, -0.9741, -0.3936],\n",
      "        [-0.0257, -1.1108,  1.6672]], grad_fn=<AddBackward0>)\n",
      "progress: 8 loss= 0.2990249693393707\n",
      "tensor([[ 1.6173, -0.9754, -0.3943],\n",
      "        [-0.4634,  0.3930,  0.3440],\n",
      "        [-1.9339,  0.2058,  2.2256],\n",
      "        [ 1.6173, -0.9754, -0.3943],\n",
      "        [ 1.6173, -0.9754, -0.3943],\n",
      "        [-0.0268, -1.1118,  1.6692]], grad_fn=<AddBackward0>)\n",
      "progress: 9 loss= 0.2986498177051544\n",
      "tensor([[ 1.6172, -0.9753, -0.3945],\n",
      "        [-0.4659,  0.3952,  0.3443],\n",
      "        [-1.9384,  0.2084,  2.2277],\n",
      "        [ 1.6172, -0.9753, -0.3945],\n",
      "        [ 1.6172, -0.9753, -0.3945],\n",
      "        [-0.0290, -1.1114,  1.6711]], grad_fn=<AddBackward0>)\n",
      "progress: 10 loss= 0.2982644736766815\n",
      "tensor([[ 1.6197, -0.9767, -0.3956],\n",
      "        [-0.4645,  0.3948,  0.3433],\n",
      "        [-1.9387,  0.2080,  2.2286],\n",
      "        [ 1.6197, -0.9767, -0.3956],\n",
      "        [ 1.6197, -0.9767, -0.3956],\n",
      "        [-0.0282, -1.1127,  1.6717]], grad_fn=<AddBackward0>)\n",
      "progress: 11 loss= 0.29791396856307983\n",
      "tensor([[ 1.6198, -0.9766, -0.3960],\n",
      "        [-0.4670,  0.3970,  0.3435],\n",
      "        [-1.9432,  0.2106,  2.2307],\n",
      "        [ 1.6198, -0.9766, -0.3960],\n",
      "        [ 1.6198, -0.9766, -0.3960],\n",
      "        [-0.0304, -1.1123,  1.6735]], grad_fn=<AddBackward0>)\n",
      "progress: 12 loss= 0.29750046133995056\n",
      "tensor([[ 1.6222, -0.9780, -0.3970],\n",
      "        [-0.4656,  0.3966,  0.3426],\n",
      "        [-1.9435,  0.2102,  2.2317],\n",
      "        [ 1.6222, -0.9780, -0.3970],\n",
      "        [ 1.6222, -0.9780, -0.3970],\n",
      "        [-0.0296, -1.1136,  1.6741]], grad_fn=<AddBackward0>)\n",
      "progress: 13 loss= 0.2971804738044739\n",
      "tensor([[ 1.6225, -0.9779, -0.3975],\n",
      "        [-0.4682,  0.3988,  0.3428],\n",
      "        [-1.9480,  0.2128,  2.2338],\n",
      "        [ 1.6225, -0.9779, -0.3975],\n",
      "        [ 1.6225, -0.9779, -0.3975],\n",
      "        [-0.0318, -1.1132,  1.6760]], grad_fn=<AddBackward0>)\n",
      "progress: 14 loss= 0.2967393696308136\n",
      "tensor([[ 1.6247, -0.9793, -0.3984],\n",
      "        [-0.4667,  0.3983,  0.3419],\n",
      "        [-1.9483,  0.2124,  2.2347],\n",
      "        [ 1.6247, -0.9793, -0.3984],\n",
      "        [ 1.6247, -0.9793, -0.3984],\n",
      "        [-0.0310, -1.1145,  1.6766]], grad_fn=<AddBackward0>)\n",
      "progress: 15 loss= 0.2964492440223694\n",
      "tensor([[ 1.6251, -0.9792, -0.3990],\n",
      "        [-0.4693,  0.4007,  0.3421],\n",
      "        [-1.9528,  0.2150,  2.2368],\n",
      "        [ 1.6251, -0.9792, -0.3990],\n",
      "        [ 1.6251, -0.9792, -0.3990],\n",
      "        [-0.0332, -1.1141,  1.6785]], grad_fn=<AddBackward0>)\n",
      "progress: 16 loss= 0.2959813177585602\n",
      "tensor([[ 1.6271, -0.9806, -0.3998],\n",
      "        [-0.4678,  0.4001,  0.3412],\n",
      "        [-1.9531,  0.2146,  2.2377],\n",
      "        [ 1.6271, -0.9806, -0.3998],\n",
      "        [ 1.6271, -0.9806, -0.3998],\n",
      "        [-0.0324, -1.1154,  1.6791]], grad_fn=<AddBackward0>)\n",
      "progress: 17 loss= 0.2957204282283783\n",
      "tensor([[ 1.6277, -0.9805, -0.4005],\n",
      "        [-0.4704,  0.4025,  0.3414],\n",
      "        [-1.9576,  0.2173,  2.2398],\n",
      "        [ 1.6277, -0.9805, -0.4005],\n",
      "        [ 1.6277, -0.9805, -0.4005],\n",
      "        [-0.0346, -1.1149,  1.6809]], grad_fn=<AddBackward0>)\n",
      "progress: 18 loss= 0.29522737860679626\n",
      "tensor([[ 1.6287, -0.9817, -0.4005],\n",
      "        [-0.4708,  0.4022,  0.3418],\n",
      "        [-1.9598,  0.2171,  2.2421],\n",
      "        [ 1.6287, -0.9817, -0.4005],\n",
      "        [ 1.6287, -0.9817, -0.4005],\n",
      "        [-0.0356, -1.1159,  1.6829]], grad_fn=<AddBackward0>)\n",
      "progress: 19 loss= 0.2949924170970917\n",
      "tensor([[ 1.6302, -0.9818, -0.4018],\n",
      "        [-0.4716,  0.4043,  0.3407],\n",
      "        [-1.9624,  0.2195,  2.2428],\n",
      "        [ 1.6302, -0.9818, -0.4018],\n",
      "        [ 1.6302, -0.9818, -0.4018],\n",
      "        [-0.0360, -1.1158,  1.6834]], grad_fn=<AddBackward0>)\n",
      "progress: 20 loss= 0.294498473405838\n",
      "tensor([[ 1.6313, -0.9830, -0.4020],\n",
      "        [-0.4719,  0.4040,  0.3411],\n",
      "        [-1.9646,  0.2193,  2.2451],\n",
      "        [ 1.6313, -0.9830, -0.4020],\n",
      "        [ 1.6313, -0.9830, -0.4020],\n",
      "        [-0.0370, -1.1168,  1.6853]], grad_fn=<AddBackward0>)\n",
      "progress: 21 loss= 0.2942448556423187\n",
      "tensor([[ 1.6326, -0.9830, -0.4032],\n",
      "        [-0.4727,  0.4061,  0.3400],\n",
      "        [-1.9672,  0.2217,  2.2458],\n",
      "        [ 1.6326, -0.9830, -0.4032],\n",
      "        [ 1.6326, -0.9830, -0.4032],\n",
      "        [-0.0374, -1.1167,  1.6859]], grad_fn=<AddBackward0>)\n",
      "progress: 22 loss= 0.2937721312046051\n",
      "tensor([[ 1.6339, -0.9843, -0.4035],\n",
      "        [-0.4730,  0.4058,  0.3404],\n",
      "        [-1.9694,  0.2215,  2.2481],\n",
      "        [ 1.6339, -0.9843, -0.4035],\n",
      "        [ 1.6339, -0.9843, -0.4035],\n",
      "        [-0.0384, -1.1177,  1.6878]], grad_fn=<AddBackward0>)\n",
      "progress: 23 loss= 0.2934997081756592\n",
      "tensor([[ 1.6350, -0.9843, -0.4046],\n",
      "        [-0.4738,  0.4080,  0.3393],\n",
      "        [-1.9720,  0.2239,  2.2488],\n",
      "        [ 1.6350, -0.9843, -0.4046],\n",
      "        [ 1.6350, -0.9843, -0.4046],\n",
      "        [-0.0388, -1.1176,  1.6883]], grad_fn=<AddBackward0>)\n",
      "progress: 24 loss= 0.2930483818054199\n",
      "tensor([[ 1.6366, -0.9856, -0.4050],\n",
      "        [-0.4742,  0.4076,  0.3397],\n",
      "        [-1.9742,  0.2238,  2.2511],\n",
      "        [ 1.6366, -0.9856, -0.4050],\n",
      "        [ 1.6366, -0.9856, -0.4050],\n",
      "        [-0.0398, -1.1186,  1.6903]], grad_fn=<AddBackward0>)\n",
      "progress: 25 loss= 0.29275721311569214\n",
      "tensor([[ 1.6375, -0.9855, -0.4059],\n",
      "        [-0.4750,  0.4098,  0.3386],\n",
      "        [-1.9768,  0.2261,  2.2518],\n",
      "        [ 1.6375, -0.9855, -0.4059],\n",
      "        [ 1.6375, -0.9855, -0.4059],\n",
      "        [-0.0401, -1.1185,  1.6908]], grad_fn=<AddBackward0>)\n",
      "progress: 26 loss= 0.2923293113708496\n",
      "tensor([[ 1.6380, -0.9855, -0.4066],\n",
      "        [-0.4765,  0.4109,  0.3389],\n",
      "        [-1.9813,  0.2288,  2.2539],\n",
      "        [ 1.6380, -0.9855, -0.4066],\n",
      "        [ 1.6380, -0.9855, -0.4066],\n",
      "        [-0.0424, -1.1181,  1.6926]], grad_fn=<AddBackward0>)\n",
      "progress: 27 loss= 0.29201504588127136\n",
      "tensor([[ 1.6399, -0.9868, -0.4073],\n",
      "        [-0.4761,  0.4116,  0.3379],\n",
      "        [-1.9816,  0.2283,  2.2548],\n",
      "        [ 1.6399, -0.9868, -0.4073],\n",
      "        [ 1.6399, -0.9868, -0.4073],\n",
      "        [-0.0415, -1.1194,  1.6932]], grad_fn=<AddBackward0>)\n",
      "progress: 28 loss= 0.29161375761032104\n",
      "tensor([[ 1.6405, -0.9867, -0.4080],\n",
      "        [-0.4776,  0.4127,  0.3382],\n",
      "        [-1.9861,  0.2310,  2.2569],\n",
      "        [ 1.6405, -0.9867, -0.4080],\n",
      "        [ 1.6405, -0.9867, -0.4080],\n",
      "        [-0.0438, -1.1190,  1.6951]], grad_fn=<AddBackward0>)\n",
      "progress: 29 loss= 0.291283518075943\n",
      "tensor([[ 1.6415, -0.9879, -0.4081],\n",
      "        [-0.4791,  0.4137,  0.3386],\n",
      "        [-1.9882,  0.2308,  2.2592],\n",
      "        [ 1.6415, -0.9879, -0.4081],\n",
      "        [ 1.6415, -0.9879, -0.4081],\n",
      "        [-0.0448, -1.1199,  1.6970]], grad_fn=<AddBackward0>)\n",
      "progress: 30 loss= 0.2908911406993866\n",
      "tensor([[ 1.6429, -0.9880, -0.4093],\n",
      "        [-0.4787,  0.4145,  0.3375],\n",
      "        [-1.9908,  0.2332,  2.2599],\n",
      "        [ 1.6429, -0.9880, -0.4093],\n",
      "        [ 1.6429, -0.9880, -0.4093],\n",
      "        [-0.0451, -1.1198,  1.6976]], grad_fn=<AddBackward0>)\n",
      "progress: 31 loss= 0.2905687987804413\n",
      "tensor([[ 1.6442, -0.9892, -0.4096],\n",
      "        [-0.4802,  0.4155,  0.3379],\n",
      "        [-1.9930,  0.2330,  2.2622],\n",
      "        [ 1.6442, -0.9892, -0.4096],\n",
      "        [ 1.6442, -0.9892, -0.4096],\n",
      "        [-0.0462, -1.1208,  1.6995]], grad_fn=<AddBackward0>)\n",
      "progress: 32 loss= 0.29015693068504333\n",
      "tensor([[ 1.6454, -0.9892, -0.4107],\n",
      "        [-0.4799,  0.4163,  0.3368],\n",
      "        [-1.9956,  0.2354,  2.2629],\n",
      "        [ 1.6454, -0.9892, -0.4107],\n",
      "        [ 1.6454, -0.9892, -0.4107],\n",
      "        [-0.0465, -1.1207,  1.7000]], grad_fn=<AddBackward0>)\n",
      "progress: 33 loss= 0.2898566424846649\n",
      "tensor([[ 1.6468, -0.9905, -0.4111],\n",
      "        [-0.4813,  0.4173,  0.3372],\n",
      "        [-1.9977,  0.2352,  2.2652],\n",
      "        [ 1.6468, -0.9905, -0.4111],\n",
      "        [ 1.6468, -0.9905, -0.4111],\n",
      "        [-0.0475, -1.1217,  1.7019]], grad_fn=<AddBackward0>)\n",
      "progress: 34 loss= 0.28942522406578064\n",
      "tensor([[ 1.6478, -0.9905, -0.4120],\n",
      "        [-0.4810,  0.4182,  0.3361],\n",
      "        [-2.0004,  0.2376,  2.2659],\n",
      "        [ 1.6478, -0.9905, -0.4120],\n",
      "        [ 1.6478, -0.9905, -0.4120],\n",
      "        [-0.0479, -1.1216,  1.7024]], grad_fn=<AddBackward0>)\n",
      "progress: 35 loss= 0.2891470491886139\n",
      "tensor([[ 1.6493, -0.9918, -0.4125],\n",
      "        [-0.4824,  0.4191,  0.3364],\n",
      "        [-2.0025,  0.2374,  2.2682],\n",
      "        [ 1.6493, -0.9918, -0.4125],\n",
      "        [ 1.6493, -0.9918, -0.4125],\n",
      "        [-0.0489, -1.1226,  1.7044]], grad_fn=<AddBackward0>)\n",
      "progress: 36 loss= 0.28869590163230896\n",
      "tensor([[ 1.6502, -0.9917, -0.4134],\n",
      "        [-0.4821,  0.4200,  0.3354],\n",
      "        [-2.0051,  0.2398,  2.2689],\n",
      "        [ 1.6502, -0.9917, -0.4134],\n",
      "        [ 1.6502, -0.9917, -0.4134],\n",
      "        [-0.0492, -1.1225,  1.7049]], grad_fn=<AddBackward0>)\n",
      "progress: 37 loss= 0.2884399890899658\n",
      "tensor([[ 1.6519, -0.9931, -0.4140],\n",
      "        [-0.4835,  0.4209,  0.3357],\n",
      "        [-2.0072,  0.2396,  2.2712],\n",
      "        [ 1.6519, -0.9931, -0.4140],\n",
      "        [ 1.6519, -0.9931, -0.4140],\n",
      "        [-0.0503, -1.1235,  1.7068]], grad_fn=<AddBackward0>)\n",
      "progress: 38 loss= 0.28796902298927307\n",
      "tensor([[ 1.6526, -0.9930, -0.4147],\n",
      "        [-0.4832,  0.4218,  0.3347],\n",
      "        [-2.0099,  0.2420,  2.2719],\n",
      "        [ 1.6526, -0.9930, -0.4147],\n",
      "        [ 1.6526, -0.9930, -0.4147],\n",
      "        [-0.0506, -1.1234,  1.7073]], grad_fn=<AddBackward0>)\n",
      "progress: 39 loss= 0.2877354323863983\n",
      "tensor([[ 1.6544, -0.9943, -0.4154],\n",
      "        [-0.4846,  0.4227,  0.3350],\n",
      "        [-2.0120,  0.2418,  2.2741],\n",
      "        [ 1.6544, -0.9943, -0.4154],\n",
      "        [ 1.6544, -0.9943, -0.4154],\n",
      "        [-0.0516, -1.1244,  1.7093]], grad_fn=<AddBackward0>)\n",
      "progress: 40 loss= 0.2872631847858429\n",
      "tensor([[ 1.6543, -0.9941, -0.4156],\n",
      "        [-0.4862,  0.4239,  0.3354],\n",
      "        [-2.0165,  0.2445,  2.2762],\n",
      "        [ 1.6543, -0.9941, -0.4156],\n",
      "        [ 1.6543, -0.9941, -0.4156],\n",
      "        [-0.0539, -1.1239,  1.7111]], grad_fn=<AddBackward0>)\n",
      "progress: 41 loss= 0.2870151996612549\n",
      "tensor([[ 1.6568, -0.9955, -0.4167],\n",
      "        [-0.4857,  0.4245,  0.3343],\n",
      "        [-2.0167,  0.2440,  2.2771],\n",
      "        [ 1.6568, -0.9955, -0.4167],\n",
      "        [ 1.6568, -0.9955, -0.4167],\n",
      "        [-0.0530, -1.1253,  1.7117]], grad_fn=<AddBackward0>)\n",
      "progress: 42 loss= 0.2865641415119171\n",
      "tensor([[ 1.6569, -0.9954, -0.4171],\n",
      "        [-0.4874,  0.4258,  0.3346],\n",
      "        [-2.0212,  0.2467,  2.2792],\n",
      "        [ 1.6569, -0.9954, -0.4171],\n",
      "        [ 1.6569, -0.9954, -0.4171],\n",
      "        [-0.0552, -1.1248,  1.7136]], grad_fn=<AddBackward0>)\n",
      "progress: 43 loss= 0.28629270195961\n",
      "tensor([[ 1.6592, -0.9968, -0.4180],\n",
      "        [-0.4869,  0.4263,  0.3336],\n",
      "        [-2.0215,  0.2462,  2.2801],\n",
      "        [ 1.6592, -0.9968, -0.4180],\n",
      "        [ 1.6592, -0.9968, -0.4180],\n",
      "        [-0.0544, -1.1261,  1.7141]], grad_fn=<AddBackward0>)\n",
      "progress: 44 loss= 0.28586724400520325\n",
      "tensor([[ 1.6594, -0.9966, -0.4185],\n",
      "        [-0.4885,  0.4276,  0.3339],\n",
      "        [-2.0260,  0.2489,  2.2822],\n",
      "        [ 1.6594, -0.9966, -0.4185],\n",
      "        [ 1.6594, -0.9966, -0.4185],\n",
      "        [-0.0566, -1.1257,  1.7160]], grad_fn=<AddBackward0>)\n",
      "progress: 45 loss= 0.28557294607162476\n",
      "tensor([[ 1.6615, -0.9980, -0.4194],\n",
      "        [-0.4880,  0.4282,  0.3329],\n",
      "        [-2.0262,  0.2484,  2.2831],\n",
      "        [ 1.6615, -0.9980, -0.4194],\n",
      "        [ 1.6615, -0.9980, -0.4194],\n",
      "        [-0.0557, -1.1270,  1.7166]], grad_fn=<AddBackward0>)\n",
      "progress: 46 loss= 0.28517261147499084\n",
      "tensor([[ 1.6620, -0.9979, -0.4200],\n",
      "        [-0.4896,  0.4294,  0.3332],\n",
      "        [-2.0307,  0.2511,  2.2851],\n",
      "        [ 1.6620, -0.9979, -0.4200],\n",
      "        [ 1.6620, -0.9979, -0.4200],\n",
      "        [-0.0579, -1.1266,  1.7184]], grad_fn=<AddBackward0>)\n",
      "progress: 47 loss= 0.28485605120658875\n",
      "tensor([[ 1.6639, -0.9992, -0.4207],\n",
      "        [-0.4891,  0.4300,  0.3322],\n",
      "        [-2.0309,  0.2506,  2.2860],\n",
      "        [ 1.6639, -0.9992, -0.4207],\n",
      "        [ 1.6639, -0.9992, -0.4207],\n",
      "        [-0.0571, -1.1279,  1.7190]], grad_fn=<AddBackward0>)\n",
      "progress: 48 loss= 0.28447994589805603\n",
      "tensor([[ 1.6645, -0.9991, -0.4214],\n",
      "        [-0.4907,  0.4312,  0.3325],\n",
      "        [-2.0354,  0.2533,  2.2881],\n",
      "        [ 1.6645, -0.9991, -0.4214],\n",
      "        [ 1.6645, -0.9991, -0.4214],\n",
      "        [-0.0593, -1.1275,  1.7209]], grad_fn=<AddBackward0>)\n",
      "progress: 49 loss= 0.28414806723594666\n",
      "tensor([[ 1.6655, -1.0003, -0.4215],\n",
      "        [-0.4921,  0.4321,  0.3329],\n",
      "        [-2.0375,  0.2531,  2.2903],\n",
      "        [ 1.6655, -1.0003, -0.4215],\n",
      "        [ 1.6655, -1.0003, -0.4215],\n",
      "        [-0.0603, -1.1284,  1.7228]], grad_fn=<AddBackward0>)\n",
      "progress: 50 loss= 0.2837832272052765\n",
      "tensor([[ 1.6669, -1.0004, -0.4227],\n",
      "        [-0.4919,  0.4330,  0.3318],\n",
      "        [-2.0401,  0.2555,  2.2911],\n",
      "        [ 1.6669, -1.0004, -0.4227],\n",
      "        [ 1.6669, -1.0004, -0.4227],\n",
      "        [-0.0607, -1.1283,  1.7233]], grad_fn=<AddBackward0>)\n",
      "progress: 51 loss= 0.2834590971469879\n",
      "tensor([[ 1.6681, -1.0016, -0.4229],\n",
      "        [-0.4932,  0.4339,  0.3321],\n",
      "        [-2.0422,  0.2553,  2.2933],\n",
      "        [ 1.6681, -1.0016, -0.4229],\n",
      "        [ 1.6681, -1.0016, -0.4229],\n",
      "        [-0.0617, -1.1293,  1.7252]], grad_fn=<AddBackward0>)\n",
      "progress: 52 loss= 0.2830723822116852\n",
      "tensor([[ 1.6693, -1.0016, -0.4241],\n",
      "        [-0.4930,  0.4349,  0.3311],\n",
      "        [-2.0449,  0.2577,  2.2940],\n",
      "        [ 1.6693, -1.0016, -0.4241],\n",
      "        [ 1.6693, -1.0016, -0.4241],\n",
      "        [-0.0620, -1.1292,  1.7257]], grad_fn=<AddBackward0>)\n",
      "progress: 53 loss= 0.28277260065078735\n",
      "tensor([[ 1.6706, -1.0028, -0.4244],\n",
      "        [-0.4943,  0.4358,  0.3314],\n",
      "        [-2.0470,  0.2575,  2.2962],\n",
      "        [ 1.6706, -1.0028, -0.4244],\n",
      "        [ 1.6706, -1.0028, -0.4244],\n",
      "        [-0.0630, -1.1302,  1.7276]], grad_fn=<AddBackward0>)\n",
      "progress: 54 loss= 0.28236380219459534\n",
      "tensor([[ 1.6716, -1.0028, -0.4254],\n",
      "        [-0.4941,  0.4367,  0.3304],\n",
      "        [-2.0496,  0.2599,  2.2970],\n",
      "        [ 1.6716, -1.0028, -0.4254],\n",
      "        [ 1.6716, -1.0028, -0.4254],\n",
      "        [-0.0634, -1.1301,  1.7281]], grad_fn=<AddBackward0>)\n",
      "progress: 55 loss= 0.28208857774734497\n",
      "tensor([[ 1.6732, -1.0041, -0.4259],\n",
      "        [-0.4955,  0.4376,  0.3307],\n",
      "        [-2.0517,  0.2597,  2.2992],\n",
      "        [ 1.6732, -1.0041, -0.4259],\n",
      "        [ 1.6732, -1.0041, -0.4259],\n",
      "        [-0.0644, -1.1311,  1.7300]], grad_fn=<AddBackward0>)\n",
      "progress: 56 loss= 0.28165772557258606\n",
      "tensor([[ 1.6740, -1.0040, -0.4267],\n",
      "        [-0.4952,  0.4385,  0.3297],\n",
      "        [-2.0543,  0.2621,  2.2999],\n",
      "        [ 1.6740, -1.0040, -0.4267],\n",
      "        [ 1.6740, -1.0040, -0.4267],\n",
      "        [-0.0647, -1.1309,  1.7306]], grad_fn=<AddBackward0>)\n",
      "progress: 57 loss= 0.281406968832016\n",
      "tensor([[ 1.6757, -1.0053, -0.4273],\n",
      "        [-0.4966,  0.4394,  0.3300],\n",
      "        [-2.0564,  0.2619,  2.3022],\n",
      "        [ 1.6757, -1.0053, -0.4273],\n",
      "        [ 1.6757, -1.0053, -0.4273],\n",
      "        [-0.0658, -1.1319,  1.7325]], grad_fn=<AddBackward0>)\n",
      "progress: 58 loss= 0.28095391392707825\n",
      "tensor([[ 1.6763, -1.0052, -0.4280],\n",
      "        [-0.4964,  0.4403,  0.3290],\n",
      "        [-2.0590,  0.2643,  2.3029],\n",
      "        [ 1.6763, -1.0052, -0.4280],\n",
      "        [ 1.6763, -1.0052, -0.4280],\n",
      "        [-0.0661, -1.1318,  1.7330]], grad_fn=<AddBackward0>)\n",
      "progress: 59 loss= 0.28072771430015564\n",
      "tensor([[ 1.6781, -1.0065, -0.4287],\n",
      "        [-0.4977,  0.4412,  0.3293],\n",
      "        [-2.0611,  0.2641,  2.3051],\n",
      "        [ 1.6781, -1.0065, -0.4287],\n",
      "        [ 1.6781, -1.0065, -0.4287],\n",
      "        [-0.0671, -1.1328,  1.7349]], grad_fn=<AddBackward0>)\n",
      "progress: 60 loss= 0.28026965260505676\n",
      "tensor([[ 1.6780, -1.0063, -0.4289],\n",
      "        [-0.4993,  0.4424,  0.3296],\n",
      "        [-2.0656,  0.2668,  2.3072],\n",
      "        [ 1.6780, -1.0063, -0.4289],\n",
      "        [ 1.6780, -1.0063, -0.4289],\n",
      "        [-0.0693, -1.1324,  1.7367]], grad_fn=<AddBackward0>)\n",
      "progress: 61 loss= 0.2800339162349701\n",
      "tensor([[ 1.6804, -1.0077, -0.4300],\n",
      "        [-0.4989,  0.4431,  0.3286],\n",
      "        [-2.0658,  0.2663,  2.3081],\n",
      "        [ 1.6804, -1.0077, -0.4300],\n",
      "        [ 1.6804, -1.0077, -0.4300],\n",
      "        [-0.0685, -1.1337,  1.7373]], grad_fn=<AddBackward0>)\n",
      "progress: 62 loss= 0.279592901468277\n",
      "tensor([[ 1.6805, -1.0075, -0.4303],\n",
      "        [-0.5004,  0.4443,  0.3289],\n",
      "        [-2.0703,  0.2690,  2.3101],\n",
      "        [ 1.6805, -1.0075, -0.4303],\n",
      "        [ 1.6805, -1.0075, -0.4303],\n",
      "        [-0.0707, -1.1332,  1.7391]], grad_fn=<AddBackward0>)\n",
      "progress: 63 loss= 0.2793370485305786\n",
      "tensor([[ 1.6828, -1.0089, -0.4313],\n",
      "        [-0.5000,  0.4449,  0.3279],\n",
      "        [-2.0705,  0.2685,  2.3110],\n",
      "        [ 1.6828, -1.0089, -0.4313],\n",
      "        [ 1.6828, -1.0089, -0.4313],\n",
      "        [-0.0698, -1.1345,  1.7397]], grad_fn=<AddBackward0>)\n",
      "progress: 64 loss= 0.2789182662963867\n",
      "tensor([[ 1.6830, -1.0087, -0.4318],\n",
      "        [-0.5016,  0.4461,  0.3282],\n",
      "        [-2.0750,  0.2712,  2.3131],\n",
      "        [ 1.6830, -1.0087, -0.4318],\n",
      "        [ 1.6830, -1.0087, -0.4318],\n",
      "        [-0.0720, -1.1341,  1.7415]], grad_fn=<AddBackward0>)\n",
      "progress: 65 loss= 0.2786428928375244\n",
      "tensor([[ 1.6851, -1.0101, -0.4326],\n",
      "        [-0.5011,  0.4467,  0.3272],\n",
      "        [-2.0752,  0.2707,  2.3140],\n",
      "        [ 1.6851, -1.0101, -0.4326],\n",
      "        [ 1.6851, -1.0101, -0.4326],\n",
      "        [-0.0712, -1.1354,  1.7421]], grad_fn=<AddBackward0>)\n",
      "progress: 66 loss= 0.2782457172870636\n",
      "tensor([[ 1.6856, -1.0100, -0.4332],\n",
      "        [-0.5027,  0.4479,  0.3275],\n",
      "        [-2.0797,  0.2734,  2.3160],\n",
      "        [ 1.6856, -1.0100, -0.4332],\n",
      "        [ 1.6856, -1.0100, -0.4332],\n",
      "        [-0.0734, -1.1350,  1.7440]], grad_fn=<AddBackward0>)\n",
      "progress: 67 loss= 0.2779512405395508\n",
      "tensor([[ 1.6875, -1.0113, -0.4339],\n",
      "        [-0.5023,  0.4486,  0.3265],\n",
      "        [-2.0799,  0.2729,  2.3169],\n",
      "        [ 1.6875, -1.0113, -0.4339],\n",
      "        [ 1.6875, -1.0113, -0.4339],\n",
      "        [-0.0725, -1.1363,  1.7445]], grad_fn=<AddBackward0>)\n",
      "progress: 68 loss= 0.2775751054286957\n",
      "tensor([[ 1.6880, -1.0112, -0.4346],\n",
      "        [-0.5038,  0.4497,  0.3268],\n",
      "        [-2.0844,  0.2756,  2.3189],\n",
      "        [ 1.6880, -1.0112, -0.4346],\n",
      "        [ 1.6880, -1.0112, -0.4346],\n",
      "        [-0.0747, -1.1358,  1.7464]], grad_fn=<AddBackward0>)\n",
      "progress: 69 loss= 0.2772693634033203\n",
      "tensor([[ 1.6890, -1.0124, -0.4347],\n",
      "        [-0.5052,  0.4507,  0.3271],\n",
      "        [-2.0864,  0.2754,  2.3211],\n",
      "        [ 1.6890, -1.0124, -0.4347],\n",
      "        [ 1.6890, -1.0124, -0.4347],\n",
      "        [-0.0757, -1.1368,  1.7483]], grad_fn=<AddBackward0>)\n",
      "progress: 70 loss= 0.2768996059894562\n",
      "tensor([[ 1.6904, -1.0124, -0.4359],\n",
      "        [-0.5049,  0.4515,  0.3261],\n",
      "        [-2.0890,  0.2778,  2.3219],\n",
      "        [ 1.6904, -1.0124, -0.4359],\n",
      "        [ 1.6904, -1.0124, -0.4359],\n",
      "        [-0.0760, -1.1367,  1.7488]], grad_fn=<AddBackward0>)\n",
      "progress: 71 loss= 0.27660495042800903\n",
      "tensor([[ 1.6915, -1.0136, -0.4361],\n",
      "        [-0.5064,  0.4526,  0.3264],\n",
      "        [-2.0911,  0.2776,  2.3241],\n",
      "        [ 1.6915, -1.0136, -0.4361],\n",
      "        [ 1.6915, -1.0136, -0.4361],\n",
      "        [-0.0770, -1.1377,  1.7507]], grad_fn=<AddBackward0>)\n",
      "progress: 72 loss= 0.2762112021446228\n",
      "tensor([[ 1.6927, -1.0136, -0.4372],\n",
      "        [-0.5060,  0.4534,  0.3254],\n",
      "        [-2.0937,  0.2800,  2.3248],\n",
      "        [ 1.6927, -1.0136, -0.4372],\n",
      "        [ 1.6927, -1.0136, -0.4372],\n",
      "        [-0.0774, -1.1376,  1.7512]], grad_fn=<AddBackward0>)\n",
      "progress: 73 loss= 0.2759428322315216\n",
      "tensor([[ 1.6940, -1.0148, -0.4375],\n",
      "        [-0.5075,  0.4544,  0.3257],\n",
      "        [-2.0958,  0.2798,  2.3270],\n",
      "        [ 1.6940, -1.0148, -0.4375],\n",
      "        [ 1.6940, -1.0148, -0.4375],\n",
      "        [-0.0784, -1.1385,  1.7531]], grad_fn=<AddBackward0>)\n",
      "progress: 74 loss= 0.27552545070648193\n",
      "tensor([[ 1.6962, -1.0162, -0.4384],\n",
      "        [-0.5060,  0.4538,  0.3248],\n",
      "        [-2.0960,  0.2793,  2.3279],\n",
      "        [ 1.6962, -1.0162, -0.4384],\n",
      "        [ 1.6962, -1.0162, -0.4384],\n",
      "        [-0.0775, -1.1398,  1.7537]], grad_fn=<AddBackward0>)\n",
      "progress: 75 loss= 0.27528300881385803\n",
      "tensor([[ 1.6965, -1.0160, -0.4390],\n",
      "        [-0.5086,  0.4562,  0.3250],\n",
      "        [-2.1005,  0.2820,  2.3299],\n",
      "        [ 1.6965, -1.0160, -0.4390],\n",
      "        [ 1.6965, -1.0160, -0.4390],\n",
      "        [-0.0797, -1.1394,  1.7555]], grad_fn=<AddBackward0>)\n",
      "progress: 76 loss= 0.2748454809188843\n",
      "tensor([[ 1.6985, -1.0173, -0.4397],\n",
      "        [-0.5071,  0.4556,  0.3241],\n",
      "        [-2.1007,  0.2816,  2.3308],\n",
      "        [ 1.6985, -1.0173, -0.4397],\n",
      "        [ 1.6985, -1.0173, -0.4397],\n",
      "        [-0.0789, -1.1407,  1.7561]], grad_fn=<AddBackward0>)\n",
      "progress: 77 loss= 0.2746218144893646\n",
      "tensor([[ 1.6990, -1.0172, -0.4404],\n",
      "        [-0.5098,  0.4581,  0.3243],\n",
      "        [-2.1051,  0.2843,  2.3328],\n",
      "        [ 1.6990, -1.0172, -0.4404],\n",
      "        [ 1.6990, -1.0172, -0.4404],\n",
      "        [-0.0811, -1.1402,  1.7579]], grad_fn=<AddBackward0>)\n",
      "progress: 78 loss= 0.2741680145263672\n",
      "tensor([[ 1.7008, -1.0185, -0.4410],\n",
      "        [-0.5083,  0.4575,  0.3234],\n",
      "        [-2.1054,  0.2838,  2.3337],\n",
      "        [ 1.7008, -1.0185, -0.4410],\n",
      "        [ 1.7008, -1.0185, -0.4410],\n",
      "        [-0.0802, -1.1415,  1.7585]], grad_fn=<AddBackward0>)\n",
      "progress: 79 loss= 0.2739626169204712\n",
      "tensor([[ 1.7013, -1.0184, -0.4417],\n",
      "        [-0.5109,  0.4599,  0.3236],\n",
      "        [-2.1098,  0.2865,  2.3358],\n",
      "        [ 1.7013, -1.0184, -0.4417],\n",
      "        [ 1.7013, -1.0184, -0.4417],\n",
      "        [-0.0824, -1.1411,  1.7603]], grad_fn=<AddBackward0>)\n",
      "progress: 80 loss= 0.2735123932361603\n",
      "tensor([[ 1.7024, -1.0196, -0.4419],\n",
      "        [-0.5113,  0.4597,  0.3240],\n",
      "        [-2.1119,  0.2863,  2.3380],\n",
      "        [ 1.7024, -1.0196, -0.4419],\n",
      "        [ 1.7024, -1.0196, -0.4419],\n",
      "        [-0.0834, -1.1421,  1.7622]], grad_fn=<AddBackward0>)\n",
      "progress: 81 loss= 0.2732861340045929\n",
      "tensor([[ 1.7036, -1.0195, -0.4430],\n",
      "        [-0.5120,  0.4617,  0.3229],\n",
      "        [-2.1145,  0.2887,  2.3387],\n",
      "        [ 1.7036, -1.0195, -0.4430],\n",
      "        [ 1.7036, -1.0195, -0.4430],\n",
      "        [-0.0838, -1.1419,  1.7627]], grad_fn=<AddBackward0>)\n",
      "progress: 82 loss= 0.27286139130592346\n",
      "tensor([[ 1.7049, -1.0208, -0.4433],\n",
      "        [-0.5124,  0.4615,  0.3232],\n",
      "        [-2.1165,  0.2885,  2.3409],\n",
      "        [ 1.7049, -1.0208, -0.4433],\n",
      "        [ 1.7049, -1.0208, -0.4433],\n",
      "        [-0.0847, -1.1429,  1.7645]], grad_fn=<AddBackward0>)\n",
      "progress: 83 loss= 0.27260956168174744\n",
      "tensor([[ 1.7059, -1.0207, -0.4443],\n",
      "        [-0.5131,  0.4635,  0.3222],\n",
      "        [-2.1192,  0.2909,  2.3416],\n",
      "        [ 1.7059, -1.0207, -0.4443],\n",
      "        [ 1.7059, -1.0207, -0.4443],\n",
      "        [-0.0851, -1.1428,  1.7650]], grad_fn=<AddBackward0>)\n",
      "progress: 84 loss= 0.2722127139568329\n",
      "tensor([[ 1.7074, -1.0219, -0.4447],\n",
      "        [-0.5136,  0.4634,  0.3225],\n",
      "        [-2.1212,  0.2907,  2.3438],\n",
      "        [ 1.7074, -1.0219, -0.4447],\n",
      "        [ 1.7074, -1.0219, -0.4447],\n",
      "        [-0.0861, -1.1437,  1.7669]], grad_fn=<AddBackward0>)\n",
      "progress: 85 loss= 0.27193522453308105\n",
      "tensor([[ 1.7082, -1.0219, -0.4456],\n",
      "        [-0.5142,  0.4653,  0.3215],\n",
      "        [-2.1238,  0.2931,  2.3445],\n",
      "        [ 1.7082, -1.0219, -0.4456],\n",
      "        [ 1.7082, -1.0219, -0.4456],\n",
      "        [-0.0864, -1.1436,  1.7674]], grad_fn=<AddBackward0>)\n",
      "progress: 86 loss= 0.2715663015842438\n",
      "tensor([[ 1.7099, -1.0231, -0.4461],\n",
      "        [-0.5147,  0.4652,  0.3218],\n",
      "        [-2.1259,  0.2929,  2.3467],\n",
      "        [ 1.7099, -1.0231, -0.4461],\n",
      "        [ 1.7099, -1.0231, -0.4461],\n",
      "        [-0.0874, -1.1446,  1.7693]], grad_fn=<AddBackward0>)\n",
      "progress: 87 loss= 0.2712630331516266\n",
      "tensor([[ 1.7105, -1.0230, -0.4469],\n",
      "        [-0.5154,  0.4672,  0.3208],\n",
      "        [-2.1285,  0.2953,  2.3474],\n",
      "        [ 1.7105, -1.0230, -0.4469],\n",
      "        [ 1.7105, -1.0230, -0.4469],\n",
      "        [-0.0878, -1.1445,  1.7698]], grad_fn=<AddBackward0>)\n",
      "progress: 88 loss= 0.27092212438583374\n",
      "tensor([[ 1.7122, -1.0243, -0.4475],\n",
      "        [-0.5159,  0.4671,  0.3211],\n",
      "        [-2.1305,  0.2951,  2.3496],\n",
      "        [ 1.7122, -1.0243, -0.4475],\n",
      "        [ 1.7122, -1.0243, -0.4475],\n",
      "        [-0.0888, -1.1454,  1.7717]], grad_fn=<AddBackward0>)\n",
      "progress: 89 loss= 0.270602822303772\n",
      "tensor([[ 1.7120, -1.0240, -0.4476],\n",
      "        [-0.5183,  0.4693,  0.3214],\n",
      "        [-2.1350,  0.2978,  2.3516],\n",
      "        [ 1.7120, -1.0240, -0.4476],\n",
      "        [ 1.7120, -1.0240, -0.4476],\n",
      "        [-0.0910, -1.1450,  1.7735]], grad_fn=<AddBackward0>)\n",
      "progress: 90 loss= 0.27027055621147156\n",
      "tensor([[ 1.7145, -1.0255, -0.4488],\n",
      "        [-0.5170,  0.4690,  0.3204],\n",
      "        [-2.1352,  0.2973,  2.3525],\n",
      "        [ 1.7145, -1.0255, -0.4488],\n",
      "        [ 1.7145, -1.0255, -0.4488],\n",
      "        [-0.0901, -1.1463,  1.7741]], grad_fn=<AddBackward0>)\n",
      "progress: 91 loss= 0.2699565589427948\n",
      "tensor([[ 1.7145, -1.0252, -0.4491],\n",
      "        [-0.5194,  0.4711,  0.3207],\n",
      "        [-2.1396,  0.3000,  2.3545],\n",
      "        [ 1.7145, -1.0252, -0.4491],\n",
      "        [ 1.7145, -1.0252, -0.4491],\n",
      "        [-0.0923, -1.1458,  1.7759]], grad_fn=<AddBackward0>)\n",
      "progress: 92 loss= 0.2696093022823334\n",
      "tensor([[ 1.7168, -1.0266, -0.4501],\n",
      "        [-0.5182,  0.4708,  0.3197],\n",
      "        [-2.1398,  0.2995,  2.3554],\n",
      "        [ 1.7168, -1.0266, -0.4501],\n",
      "        [ 1.7168, -1.0266, -0.4501],\n",
      "        [-0.0914, -1.1471,  1.7765]], grad_fn=<AddBackward0>)\n",
      "progress: 93 loss= 0.2693122327327728\n",
      "tensor([[ 1.7170, -1.0264, -0.4505],\n",
      "        [-0.5205,  0.4729,  0.3199],\n",
      "        [-2.1442,  0.3022,  2.3574],\n",
      "        [ 1.7170, -1.0264, -0.4505],\n",
      "        [ 1.7170, -1.0264, -0.4505],\n",
      "        [-0.0936, -1.1467,  1.7783]], grad_fn=<AddBackward0>)\n",
      "progress: 94 loss= 0.2689504027366638\n",
      "tensor([[ 1.7191, -1.0277, -0.4513],\n",
      "        [-0.5193,  0.4727,  0.3190],\n",
      "        [-2.1444,  0.3017,  2.3583],\n",
      "        [ 1.7191, -1.0277, -0.4513],\n",
      "        [ 1.7191, -1.0277, -0.4513],\n",
      "        [-0.0928, -1.1480,  1.7788]], grad_fn=<AddBackward0>)\n",
      "progress: 95 loss= 0.26866987347602844\n",
      "tensor([[ 1.7194, -1.0276, -0.4519],\n",
      "        [-0.5216,  0.4747,  0.3192],\n",
      "        [-2.1489,  0.3044,  2.3603],\n",
      "        [ 1.7194, -1.0276, -0.4519],\n",
      "        [ 1.7194, -1.0276, -0.4519],\n",
      "        [-0.0949, -1.1475,  1.7806]], grad_fn=<AddBackward0>)\n",
      "progress: 96 loss= 0.26829400658607483\n",
      "tensor([[ 1.7213, -1.0289, -0.4526],\n",
      "        [-0.5205,  0.4746,  0.3183],\n",
      "        [-2.1491,  0.3039,  2.3612],\n",
      "        [ 1.7213, -1.0289, -0.4526],\n",
      "        [ 1.7213, -1.0289, -0.4526],\n",
      "        [-0.0941, -1.1488,  1.7812]], grad_fn=<AddBackward0>)\n",
      "progress: 97 loss= 0.2680295407772064\n",
      "tensor([[ 1.7218, -1.0287, -0.4533],\n",
      "        [-0.5227,  0.4766,  0.3185],\n",
      "        [-2.1535,  0.3067,  2.3632],\n",
      "        [ 1.7218, -1.0287, -0.4533],\n",
      "        [ 1.7218, -1.0287, -0.4533],\n",
      "        [-0.0963, -1.1483,  1.7830]], grad_fn=<AddBackward0>)\n",
      "progress: 98 loss= 0.2676421105861664\n",
      "tensor([[ 1.7228, -1.0299, -0.4533],\n",
      "        [-0.5235,  0.4768,  0.3189],\n",
      "        [-2.1555,  0.3065,  2.3653],\n",
      "        [ 1.7228, -1.0299, -0.4533],\n",
      "        [ 1.7228, -1.0299, -0.4533],\n",
      "        [-0.0972, -1.1493,  1.7849]], grad_fn=<AddBackward0>)\n",
      "progress: 99 loss= 0.2673889696598053\n",
      "tensor([[ 1.7241, -1.0299, -0.4546],\n",
      "        [-0.5239,  0.4784,  0.3178],\n",
      "        [-2.1581,  0.3088,  2.3661],\n",
      "        [ 1.7241, -1.0299, -0.4546],\n",
      "        [ 1.7241, -1.0299, -0.4546],\n",
      "        [-0.0976, -1.1492,  1.7854]], grad_fn=<AddBackward0>)\n",
      "progress: 100 loss= 0.26701173186302185\n",
      "tensor([[ 1.7252, -1.0311, -0.4547],\n",
      "        [-0.5246,  0.4786,  0.3182],\n",
      "        [-2.1601,  0.3087,  2.3682],\n",
      "        [ 1.7252, -1.0311, -0.4547],\n",
      "        [ 1.7252, -1.0311, -0.4547],\n",
      "        [-0.0985, -1.1502,  1.7873]], grad_fn=<AddBackward0>)\n",
      "progress: 101 loss= 0.26673126220703125\n",
      "tensor([[ 1.7264, -1.0310, -0.4558],\n",
      "        [-0.5250,  0.4802,  0.3171],\n",
      "        [-2.1628,  0.3110,  2.3689],\n",
      "        [ 1.7264, -1.0310, -0.4558],\n",
      "        [ 1.7264, -1.0310, -0.4558],\n",
      "        [-0.0989, -1.1500,  1.7878]], grad_fn=<AddBackward0>)\n",
      "progress: 102 loss= 0.2663835287094116\n",
      "tensor([[ 1.7277, -1.0322, -0.4561],\n",
      "        [-0.5258,  0.4805,  0.3175],\n",
      "        [-2.1648,  0.3109,  2.3711],\n",
      "        [ 1.7277, -1.0322, -0.4561],\n",
      "        [ 1.7277, -1.0322, -0.4561],\n",
      "        [-0.0999, -1.1510,  1.7896]], grad_fn=<AddBackward0>)\n",
      "progress: 103 loss= 0.2660757601261139\n",
      "tensor([[ 1.7286, -1.0321, -0.4571],\n",
      "        [-0.5261,  0.4820,  0.3164],\n",
      "        [-2.1674,  0.3132,  2.3718],\n",
      "        [ 1.7286, -1.0321, -0.4571],\n",
      "        [ 1.7286, -1.0321, -0.4571],\n",
      "        [-0.1002, -1.1509,  1.7901]], grad_fn=<AddBackward0>)\n",
      "progress: 104 loss= 0.2657574415206909\n",
      "tensor([[ 1.7301, -1.0334, -0.4575],\n",
      "        [-0.5270,  0.4824,  0.3168],\n",
      "        [-2.1694,  0.3131,  2.3740],\n",
      "        [ 1.7301, -1.0334, -0.4575],\n",
      "        [ 1.7301, -1.0334, -0.4575],\n",
      "        [-0.1012, -1.1519,  1.7920]], grad_fn=<AddBackward0>)\n",
      "progress: 105 loss= 0.26542234420776367\n",
      "tensor([[ 1.7309, -1.0333, -0.4584],\n",
      "        [-0.5272,  0.4838,  0.3157],\n",
      "        [-2.1720,  0.3154,  2.3747],\n",
      "        [ 1.7309, -1.0333, -0.4584],\n",
      "        [ 1.7309, -1.0333, -0.4584],\n",
      "        [-0.1015, -1.1517,  1.7925]], grad_fn=<AddBackward0>)\n",
      "progress: 106 loss= 0.2651335895061493\n",
      "tensor([[ 1.7325, -1.0345, -0.4589],\n",
      "        [-0.5281,  0.4843,  0.3160],\n",
      "        [-2.1740,  0.3153,  2.3769],\n",
      "        [ 1.7325, -1.0345, -0.4589],\n",
      "        [ 1.7325, -1.0345, -0.4589],\n",
      "        [-0.1025, -1.1527,  1.7944]], grad_fn=<AddBackward0>)\n",
      "progress: 107 loss= 0.264771044254303\n",
      "tensor([[ 1.7331, -1.0344, -0.4596],\n",
      "        [-0.5283,  0.4856,  0.3150],\n",
      "        [-2.1766,  0.3176,  2.3776],\n",
      "        [ 1.7331, -1.0344, -0.4596],\n",
      "        [ 1.7331, -1.0344, -0.4596],\n",
      "        [-0.1029, -1.1526,  1.7949]], grad_fn=<AddBackward0>)\n",
      "progress: 108 loss= 0.2645117938518524\n",
      "tensor([[ 1.7348, -1.0357, -0.4602],\n",
      "        [-0.5293,  0.4862,  0.3153],\n",
      "        [-2.1786,  0.3174,  2.3798],\n",
      "        [ 1.7348, -1.0357, -0.4602],\n",
      "        [ 1.7348, -1.0357, -0.4602],\n",
      "        [-0.1038, -1.1535,  1.7967]], grad_fn=<AddBackward0>)\n",
      "progress: 109 loss= 0.26413795351982117\n",
      "tensor([[ 1.7347, -1.0354, -0.4604],\n",
      "        [-0.5312,  0.4878,  0.3156],\n",
      "        [-2.1830,  0.3202,  2.3817],\n",
      "        [ 1.7347, -1.0354, -0.4604],\n",
      "        [ 1.7347, -1.0354, -0.4604],\n",
      "        [-0.1060, -1.1531,  1.7985]], grad_fn=<AddBackward0>)\n",
      "progress: 110 loss= 0.2638762891292572\n",
      "tensor([[ 1.7371, -1.0368, -0.4615],\n",
      "        [-0.5305,  0.4880,  0.3146],\n",
      "        [-2.1832,  0.3196,  2.3826],\n",
      "        [ 1.7371, -1.0368, -0.4615],\n",
      "        [ 1.7371, -1.0368, -0.4615],\n",
      "        [-0.1051, -1.1544,  1.7991]], grad_fn=<AddBackward0>)\n",
      "progress: 111 loss= 0.26351186633110046\n",
      "tensor([[ 1.7371, -1.0366, -0.4618],\n",
      "        [-0.5323,  0.4896,  0.3149],\n",
      "        [-2.1876,  0.3223,  2.3846],\n",
      "        [ 1.7371, -1.0366, -0.4618],\n",
      "        [ 1.7371, -1.0366, -0.4618],\n",
      "        [-0.1073, -1.1539,  1.8009]], grad_fn=<AddBackward0>)\n",
      "progress: 112 loss= 0.26323768496513367\n",
      "tensor([[ 1.7393, -1.0379, -0.4627],\n",
      "        [-0.5316,  0.4899,  0.3139],\n",
      "        [-2.1878,  0.3218,  2.3855],\n",
      "        [ 1.7393, -1.0379, -0.4627],\n",
      "        [ 1.7393, -1.0379, -0.4627],\n",
      "        [-0.1064, -1.1552,  1.8014]], grad_fn=<AddBackward0>)\n",
      "progress: 113 loss= 0.26288774609565735\n",
      "tensor([[ 1.7395, -1.0377, -0.4632],\n",
      "        [-0.5334,  0.4914,  0.3142],\n",
      "        [-2.1922,  0.3245,  2.3875],\n",
      "        [ 1.7395, -1.0377, -0.4632],\n",
      "        [ 1.7395, -1.0377, -0.4632],\n",
      "        [-0.1086, -1.1547,  1.8032]], grad_fn=<AddBackward0>)\n",
      "progress: 114 loss= 0.26260143518447876\n",
      "tensor([[ 1.7415, -1.0390, -0.4640],\n",
      "        [-0.5328,  0.4918,  0.3132],\n",
      "        [-2.1924,  0.3240,  2.3884],\n",
      "        [ 1.7415, -1.0390, -0.4640],\n",
      "        [ 1.7415, -1.0390, -0.4640],\n",
      "        [-0.1077, -1.1561,  1.8038]], grad_fn=<AddBackward0>)\n",
      "progress: 115 loss= 0.2622654438018799\n",
      "tensor([[ 1.7419, -1.0389, -0.4646],\n",
      "        [-0.5345,  0.4932,  0.3135],\n",
      "        [-2.1968,  0.3267,  2.3903],\n",
      "        [ 1.7419, -1.0389, -0.4646],\n",
      "        [ 1.7419, -1.0389, -0.4646],\n",
      "        [-0.1099, -1.1556,  1.8056]], grad_fn=<AddBackward0>)\n",
      "progress: 116 loss= 0.26196756958961487\n",
      "tensor([[ 1.7437, -1.0402, -0.4652],\n",
      "        [-0.5340,  0.4937,  0.3125],\n",
      "        [-2.1970,  0.3262,  2.3912],\n",
      "        [ 1.7437, -1.0402, -0.4652],\n",
      "        [ 1.7437, -1.0402, -0.4652],\n",
      "        [-0.1090, -1.1569,  1.8062]], grad_fn=<AddBackward0>)\n",
      "progress: 117 loss= 0.26164510846138\n",
      "tensor([[ 1.7442, -1.0400, -0.4659],\n",
      "        [-0.5356,  0.4950,  0.3128],\n",
      "        [-2.2014,  0.3289,  2.3932],\n",
      "        [ 1.7442, -1.0400, -0.4659],\n",
      "        [ 1.7442, -1.0400, -0.4659],\n",
      "        [-0.1112, -1.1564,  1.8079]], grad_fn=<AddBackward0>)\n",
      "progress: 118 loss= 0.2613462209701538\n",
      "tensor([[ 1.7452, -1.0411, -0.4660],\n",
      "        [-0.5369,  0.4959,  0.3131],\n",
      "        [-2.2034,  0.3287,  2.3954],\n",
      "        [ 1.7452, -1.0411, -0.4660],\n",
      "        [ 1.7452, -1.0411, -0.4660],\n",
      "        [-0.1121, -1.1574,  1.8098]], grad_fn=<AddBackward0>)\n",
      "progress: 119 loss= 0.2610161304473877\n",
      "tensor([[ 1.7464, -1.0411, -0.4672],\n",
      "        [-0.5367,  0.4968,  0.3121],\n",
      "        [-2.2060,  0.3311,  2.3961],\n",
      "        [ 1.7464, -1.0411, -0.4672],\n",
      "        [ 1.7464, -1.0411, -0.4672],\n",
      "        [-0.1125, -1.1573,  1.8103]], grad_fn=<AddBackward0>)\n",
      "progress: 120 loss= 0.26073765754699707\n",
      "tensor([[ 1.7476, -1.0423, -0.4674],\n",
      "        [-0.5381,  0.4978,  0.3124],\n",
      "        [-2.2079,  0.3309,  2.3982],\n",
      "        [ 1.7476, -1.0423, -0.4674],\n",
      "        [ 1.7476, -1.0423, -0.4674],\n",
      "        [-0.1134, -1.1583,  1.8121]], grad_fn=<AddBackward0>)\n",
      "progress: 121 loss= 0.26037877798080444\n",
      "tensor([[ 1.7487, -1.0422, -0.4684],\n",
      "        [-0.5378,  0.4986,  0.3114],\n",
      "        [-2.2105,  0.3333,  2.3989],\n",
      "        [ 1.7487, -1.0422, -0.4684],\n",
      "        [ 1.7487, -1.0422, -0.4684],\n",
      "        [-0.1138, -1.1581,  1.8126]], grad_fn=<AddBackward0>)\n",
      "progress: 122 loss= 0.2601311206817627\n",
      "tensor([[ 1.7500, -1.0434, -0.4688],\n",
      "        [-0.5392,  0.4996,  0.3117],\n",
      "        [-2.2125,  0.3331,  2.4011],\n",
      "        [ 1.7500, -1.0434, -0.4688],\n",
      "        [ 1.7500, -1.0434, -0.4688],\n",
      "        [-0.1147, -1.1591,  1.8145]], grad_fn=<AddBackward0>)\n",
      "progress: 123 loss= 0.25974342226982117\n",
      "tensor([[ 1.7509, -1.0433, -0.4697],\n",
      "        [-0.5389,  0.5004,  0.3107],\n",
      "        [-2.2151,  0.3355,  2.4018],\n",
      "        [ 1.7509, -1.0433, -0.4697],\n",
      "        [ 1.7509, -1.0433, -0.4697],\n",
      "        [-0.1151, -1.1590,  1.8150]], grad_fn=<AddBackward0>)\n",
      "progress: 124 loss= 0.25952669978141785\n",
      "tensor([[ 1.7524, -1.0446, -0.4701],\n",
      "        [-0.5404,  0.5015,  0.3110],\n",
      "        [-2.2171,  0.3353,  2.4039],\n",
      "        [ 1.7524, -1.0446, -0.4701],\n",
      "        [ 1.7524, -1.0446, -0.4701],\n",
      "        [-0.1160, -1.1599,  1.8168]], grad_fn=<AddBackward0>)\n",
      "progress: 125 loss= 0.25911474227905273\n",
      "tensor([[ 1.7543, -1.0459, -0.4708],\n",
      "        [-0.5389,  0.5009,  0.3100],\n",
      "        [-2.2172,  0.3347,  2.4048],\n",
      "        [ 1.7543, -1.0459, -0.4708],\n",
      "        [ 1.7543, -1.0459, -0.4708],\n",
      "        [-0.1152, -1.1612,  1.8174]], grad_fn=<AddBackward0>)\n",
      "progress: 126 loss= 0.25891995429992676\n",
      "tensor([[ 1.7548, -1.0457, -0.4715],\n",
      "        [-0.5415,  0.5033,  0.3102],\n",
      "        [-2.2216,  0.3375,  2.4068],\n",
      "        [ 1.7548, -1.0457, -0.4715],\n",
      "        [ 1.7548, -1.0457, -0.4715],\n",
      "        [-0.1173, -1.1608,  1.8192]], grad_fn=<AddBackward0>)\n",
      "progress: 127 loss= 0.2584986388683319\n",
      "tensor([[ 1.7557, -1.0468, -0.4715],\n",
      "        [-0.5419,  0.5031,  0.3106],\n",
      "        [-2.2236,  0.3373,  2.4089],\n",
      "        [ 1.7557, -1.0468, -0.4715],\n",
      "        [ 1.7557, -1.0468, -0.4715],\n",
      "        [-0.1183, -1.1617,  1.8210]], grad_fn=<AddBackward0>)\n",
      "progress: 128 loss= 0.25830450654029846\n",
      "tensor([[ 1.7570, -1.0468, -0.4727],\n",
      "        [-0.5426,  0.5051,  0.3095],\n",
      "        [-2.2262,  0.3397,  2.4096],\n",
      "        [ 1.7570, -1.0468, -0.4727],\n",
      "        [ 1.7570, -1.0468, -0.4727],\n",
      "        [-0.1186, -1.1616,  1.8215]], grad_fn=<AddBackward0>)\n",
      "progress: 129 loss= 0.25789985060691833\n",
      "tensor([[ 1.7581, -1.0479, -0.4729],\n",
      "        [-0.5430,  0.5050,  0.3099],\n",
      "        [-2.2282,  0.3395,  2.4117],\n",
      "        [ 1.7581, -1.0479, -0.4729],\n",
      "        [ 1.7581, -1.0479, -0.4729],\n",
      "        [-0.1195, -1.1626,  1.8234]], grad_fn=<AddBackward0>)\n",
      "progress: 130 loss= 0.25767579674720764\n",
      "tensor([[ 1.7592, -1.0479, -0.4740],\n",
      "        [-0.5437,  0.5069,  0.3088],\n",
      "        [-2.2308,  0.3418,  2.4124],\n",
      "        [ 1.7592, -1.0479, -0.4740],\n",
      "        [ 1.7592, -1.0479, -0.4740],\n",
      "        [-0.1199, -1.1624,  1.8238]], grad_fn=<AddBackward0>)\n",
      "progress: 131 loss= 0.2573031485080719\n",
      "tensor([[ 1.7605, -1.0491, -0.4743],\n",
      "        [-0.5442,  0.5069,  0.3092],\n",
      "        [-2.2327,  0.3416,  2.4146],\n",
      "        [ 1.7605, -1.0491, -0.4743],\n",
      "        [ 1.7605, -1.0491, -0.4743],\n",
      "        [-0.1208, -1.1634,  1.8257]], grad_fn=<AddBackward0>)\n",
      "progress: 132 loss= 0.2570490539073944\n",
      "tensor([[ 1.7613, -1.0489, -0.4752],\n",
      "        [-0.5448,  0.5087,  0.3081],\n",
      "        [-2.2353,  0.3440,  2.4153],\n",
      "        [ 1.7613, -1.0489, -0.4752],\n",
      "        [ 1.7613, -1.0489, -0.4752],\n",
      "        [-0.1212, -1.1632,  1.8262]], grad_fn=<AddBackward0>)\n",
      "progress: 133 loss= 0.2567084729671478\n",
      "tensor([[ 1.7629, -1.0502, -0.4756],\n",
      "        [-0.5454,  0.5088,  0.3085],\n",
      "        [-2.2373,  0.3438,  2.4174],\n",
      "        [ 1.7629, -1.0502, -0.4756],\n",
      "        [ 1.7629, -1.0502, -0.4756],\n",
      "        [-0.1221, -1.1642,  1.8280]], grad_fn=<AddBackward0>)\n",
      "progress: 134 loss= 0.2564243674278259\n",
      "tensor([[ 1.7635, -1.0500, -0.4764],\n",
      "        [-0.5459,  0.5105,  0.3074],\n",
      "        [-2.2399,  0.3462,  2.4181],\n",
      "        [ 1.7635, -1.0500, -0.4764],\n",
      "        [ 1.7635, -1.0500, -0.4764],\n",
      "        [-0.1225, -1.1641,  1.8285]], grad_fn=<AddBackward0>)\n",
      "progress: 135 loss= 0.2561158835887909\n",
      "tensor([[ 1.7652, -1.0513, -0.4770],\n",
      "        [-0.5466,  0.5107,  0.3078],\n",
      "        [-2.2418,  0.3460,  2.4203],\n",
      "        [ 1.7652, -1.0513, -0.4770],\n",
      "        [ 1.7652, -1.0513, -0.4770],\n",
      "        [-0.1234, -1.1651,  1.8304]], grad_fn=<AddBackward0>)\n",
      "progress: 136 loss= 0.25580206513404846\n",
      "tensor([[ 1.7649, -1.0510, -0.4771],\n",
      "        [-0.5488,  0.5127,  0.3080],\n",
      "        [-2.2462,  0.3487,  2.4222],\n",
      "        [ 1.7649, -1.0510, -0.4771],\n",
      "        [ 1.7649, -1.0510, -0.4771],\n",
      "        [-0.1256, -1.1646,  1.8321]], grad_fn=<AddBackward0>)\n",
      "progress: 137 loss= 0.25552499294281006\n",
      "tensor([[ 1.7674, -1.0524, -0.4782],\n",
      "        [-0.5477,  0.5126,  0.3070],\n",
      "        [-2.2463,  0.3482,  2.4231],\n",
      "        [ 1.7674, -1.0524, -0.4782],\n",
      "        [ 1.7674, -1.0524, -0.4782],\n",
      "        [-0.1247, -1.1659,  1.8327]], grad_fn=<AddBackward0>)\n",
      "progress: 138 loss= 0.2552017867565155\n",
      "tensor([[ 1.7673, -1.0521, -0.4785],\n",
      "        [-0.5499,  0.5145,  0.3073],\n",
      "        [-2.2507,  0.3509,  2.4250],\n",
      "        [ 1.7673, -1.0521, -0.4785],\n",
      "        [ 1.7673, -1.0521, -0.4785],\n",
      "        [-0.1268, -1.1654,  1.8344]], grad_fn=<AddBackward0>)\n",
      "progress: 139 loss= 0.25491583347320557\n",
      "tensor([[ 1.7696, -1.0535, -0.4795],\n",
      "        [-0.5489,  0.5145,  0.3063],\n",
      "        [-2.2509,  0.3504,  2.4259],\n",
      "        [ 1.7696, -1.0535, -0.4795],\n",
      "        [ 1.7696, -1.0535, -0.4795],\n",
      "        [-0.1260, -1.1667,  1.8350]], grad_fn=<AddBackward0>)\n",
      "progress: 140 loss= 0.2546033561229706\n",
      "tensor([[ 1.7696, -1.0532, -0.4798],\n",
      "        [-0.5510,  0.5163,  0.3066],\n",
      "        [-2.2553,  0.3531,  2.4279],\n",
      "        [ 1.7696, -1.0532, -0.4798],\n",
      "        [ 1.7696, -1.0532, -0.4798],\n",
      "        [-0.1281, -1.1662,  1.8368]], grad_fn=<AddBackward0>)\n",
      "progress: 141 loss= 0.2543088495731354\n",
      "tensor([[ 1.7717, -1.0545, -0.4807],\n",
      "        [-0.5501,  0.5164,  0.3056],\n",
      "        [-2.2554,  0.3526,  2.4287],\n",
      "        [ 1.7717, -1.0545, -0.4807],\n",
      "        [ 1.7717, -1.0545, -0.4807],\n",
      "        [-0.1273, -1.1675,  1.8373]], grad_fn=<AddBackward0>)\n",
      "progress: 142 loss= 0.25400659441947937\n",
      "tensor([[ 1.7720, -1.0543, -0.4812],\n",
      "        [-0.5521,  0.5181,  0.3059],\n",
      "        [-2.2598,  0.3553,  2.4307],\n",
      "        [ 1.7720, -1.0543, -0.4812],\n",
      "        [ 1.7720, -1.0543, -0.4812],\n",
      "        [-0.1294, -1.1671,  1.8391]], grad_fn=<AddBackward0>)\n",
      "progress: 143 loss= 0.2537040412425995\n",
      "tensor([[ 1.7739, -1.0556, -0.4819],\n",
      "        [-0.5513,  0.5183,  0.3049],\n",
      "        [-2.2599,  0.3547,  2.4316],\n",
      "        [ 1.7739, -1.0556, -0.4819],\n",
      "        [ 1.7739, -1.0556, -0.4819],\n",
      "        [-0.1285, -1.1684,  1.8397]], grad_fn=<AddBackward0>)\n",
      "progress: 144 loss= 0.2534116208553314\n",
      "tensor([[ 1.7743, -1.0554, -0.4825],\n",
      "        [-0.5532,  0.5199,  0.3052],\n",
      "        [-2.2643,  0.3574,  2.4335],\n",
      "        [ 1.7743, -1.0554, -0.4825],\n",
      "        [ 1.7743, -1.0554, -0.4825],\n",
      "        [-0.1307, -1.1679,  1.8414]], grad_fn=<AddBackward0>)\n",
      "progress: 145 loss= 0.25310149788856506\n",
      "tensor([[ 1.7761, -1.0567, -0.4831],\n",
      "        [-0.5525,  0.5202,  0.3042],\n",
      "        [-2.2645,  0.3569,  2.4344],\n",
      "        [ 1.7761, -1.0567, -0.4831],\n",
      "        [ 1.7761, -1.0567, -0.4831],\n",
      "        [-0.1298, -1.1692,  1.8420]], grad_fn=<AddBackward0>)\n",
      "progress: 146 loss= 0.2528184652328491\n",
      "tensor([[ 1.7765, -1.0565, -0.4838],\n",
      "        [-0.5543,  0.5217,  0.3045],\n",
      "        [-2.2689,  0.3596,  2.4363],\n",
      "        [ 1.7765, -1.0565, -0.4838],\n",
      "        [ 1.7765, -1.0565, -0.4838],\n",
      "        [-0.1320, -1.1687,  1.8437]], grad_fn=<AddBackward0>)\n",
      "progress: 147 loss= 0.25251826643943787\n",
      "tensor([[ 1.7776, -1.0576, -0.4839],\n",
      "        [-0.5554,  0.5224,  0.3048],\n",
      "        [-2.2708,  0.3594,  2.4385],\n",
      "        [ 1.7776, -1.0576, -0.4839],\n",
      "        [ 1.7776, -1.0576, -0.4839],\n",
      "        [-0.1329, -1.1697,  1.8456]], grad_fn=<AddBackward0>)\n",
      "progress: 148 loss= 0.2522096633911133\n",
      "tensor([[ 1.7787, -1.0575, -0.4850],\n",
      "        [-0.5554,  0.5235,  0.3038],\n",
      "        [-2.2734,  0.3618,  2.4392],\n",
      "        [ 1.7787, -1.0575, -0.4850],\n",
      "        [ 1.7787, -1.0575, -0.4850],\n",
      "        [-0.1332, -1.1696,  1.8461]], grad_fn=<AddBackward0>)\n",
      "progress: 149 loss= 0.25193989276885986\n",
      "tensor([[ 1.7799, -1.0587, -0.4853],\n",
      "        [-0.5566,  0.5243,  0.3040],\n",
      "        [-2.2753,  0.3616,  2.4413],\n",
      "        [ 1.7799, -1.0587, -0.4853],\n",
      "        [ 1.7799, -1.0587, -0.4853],\n",
      "        [-0.1341, -1.1705,  1.8479]], grad_fn=<AddBackward0>)\n",
      "progress: 150 loss= 0.2516001760959625\n",
      "tensor([[ 1.7808, -1.0586, -0.4862],\n",
      "        [-0.5565,  0.5253,  0.3031],\n",
      "        [-2.2779,  0.3640,  2.4420],\n",
      "        [ 1.7808, -1.0586, -0.4862],\n",
      "        [ 1.7808, -1.0586, -0.4862],\n",
      "        [-0.1345, -1.1704,  1.8484]], grad_fn=<AddBackward0>)\n",
      "progress: 151 loss= 0.25136345624923706\n",
      "tensor([[ 1.7823, -1.0598, -0.4866],\n",
      "        [-0.5578,  0.5263,  0.3033],\n",
      "        [-2.2798,  0.3638,  2.4441],\n",
      "        [ 1.7823, -1.0598, -0.4866],\n",
      "        [ 1.7823, -1.0598, -0.4866],\n",
      "        [-0.1354, -1.1714,  1.8502]], grad_fn=<AddBackward0>)\n",
      "progress: 152 loss= 0.2509925663471222\n",
      "tensor([[ 1.7830, -1.0597, -0.4874],\n",
      "        [-0.5575,  0.5271,  0.3024],\n",
      "        [-2.2824,  0.3661,  2.4448],\n",
      "        [ 1.7830, -1.0597, -0.4874],\n",
      "        [ 1.7830, -1.0597, -0.4874],\n",
      "        [-0.1358, -1.1712,  1.8507]], grad_fn=<AddBackward0>)\n",
      "progress: 153 loss= 0.2507888972759247\n",
      "tensor([[ 1.7846, -1.0609, -0.4880],\n",
      "        [-0.5590,  0.5282,  0.3026],\n",
      "        [-2.2843,  0.3659,  2.4469],\n",
      "        [ 1.7846, -1.0609, -0.4880],\n",
      "        [ 1.7846, -1.0609, -0.4880],\n",
      "        [-0.1367, -1.1722,  1.8525]], grad_fn=<AddBackward0>)\n",
      "progress: 154 loss= 0.25038692355155945\n",
      "tensor([[ 1.7851, -1.0607, -0.4886],\n",
      "        [-0.5586,  0.5289,  0.3017],\n",
      "        [-2.2869,  0.3683,  2.4476],\n",
      "        [ 1.7851, -1.0607, -0.4886],\n",
      "        [ 1.7851, -1.0607, -0.4886],\n",
      "        [-0.1370, -1.1720,  1.8530]], grad_fn=<AddBackward0>)\n",
      "progress: 155 loss= 0.2502162754535675\n",
      "tensor([[ 1.7868, -1.0620, -0.4892],\n",
      "        [-0.5601,  0.5300,  0.3019],\n",
      "        [-2.2888,  0.3681,  2.4497],\n",
      "        [ 1.7868, -1.0620, -0.4892],\n",
      "        [ 1.7868, -1.0620, -0.4892],\n",
      "        [-0.1379, -1.1730,  1.8548]], grad_fn=<AddBackward0>)\n",
      "progress: 156 loss= 0.24980920553207397\n",
      "tensor([[ 1.7878, -1.0631, -0.4893],\n",
      "        [-0.5604,  0.5297,  0.3023],\n",
      "        [-2.2907,  0.3679,  2.4518],\n",
      "        [ 1.7878, -1.0631, -0.4893],\n",
      "        [ 1.7878, -1.0631, -0.4893],\n",
      "        [-0.1388, -1.1740,  1.8566]], grad_fn=<AddBackward0>)\n",
      "progress: 157 loss= 0.2496194690465927\n",
      "tensor([[ 1.7889, -1.0630, -0.4904],\n",
      "        [-0.5612,  0.5318,  0.3012],\n",
      "        [-2.2933,  0.3703,  2.4525],\n",
      "        [ 1.7889, -1.0630, -0.4904],\n",
      "        [ 1.7889, -1.0630, -0.4904],\n",
      "        [-0.1392, -1.1738,  1.8571]], grad_fn=<AddBackward0>)\n",
      "progress: 158 loss= 0.24924004077911377\n",
      "tensor([[ 1.7901, -1.0642, -0.4907],\n",
      "        [-0.5616,  0.5316,  0.3016],\n",
      "        [-2.2952,  0.3700,  2.4546],\n",
      "        [ 1.7901, -1.0642, -0.4907],\n",
      "        [ 1.7901, -1.0642, -0.4907],\n",
      "        [-0.1401, -1.1748,  1.8590]], grad_fn=<AddBackward0>)\n",
      "progress: 159 loss= 0.24901805818080902\n",
      "tensor([[ 1.7910, -1.0641, -0.4916],\n",
      "        [-0.5623,  0.5336,  0.3005],\n",
      "        [-2.2978,  0.3724,  2.4553],\n",
      "        [ 1.7910, -1.0641, -0.4916],\n",
      "        [ 1.7910, -1.0641, -0.4916],\n",
      "        [-0.1404, -1.1747,  1.8594]], grad_fn=<AddBackward0>)\n",
      "progress: 160 loss= 0.24867284297943115\n",
      "tensor([[ 1.7925, -1.0653, -0.4920],\n",
      "        [-0.5628,  0.5336,  0.3009],\n",
      "        [-2.2997,  0.3722,  2.4574],\n",
      "        [ 1.7925, -1.0653, -0.4920],\n",
      "        [ 1.7925, -1.0653, -0.4920],\n",
      "        [-0.1413, -1.1756,  1.8613]], grad_fn=<AddBackward0>)\n",
      "progress: 161 loss= 0.24841852486133575\n",
      "tensor([[ 1.7932, -1.0651, -0.4928],\n",
      "        [-0.5634,  0.5354,  0.2998],\n",
      "        [-2.3023,  0.3746,  2.4581],\n",
      "        [ 1.7932, -1.0651, -0.4928],\n",
      "        [ 1.7932, -1.0651, -0.4928],\n",
      "        [-0.1417, -1.1755,  1.8618]], grad_fn=<AddBackward0>)\n",
      "progress: 162 loss= 0.24810735881328583\n",
      "tensor([[ 1.7948, -1.0664, -0.4933],\n",
      "        [-0.5640,  0.5355,  0.3001],\n",
      "        [-2.3041,  0.3744,  2.4602],\n",
      "        [ 1.7948, -1.0664, -0.4933],\n",
      "        [ 1.7948, -1.0664, -0.4933],\n",
      "        [-0.1426, -1.1765,  1.8636]], grad_fn=<AddBackward0>)\n",
      "progress: 163 loss= 0.24782101809978485\n",
      "tensor([[ 1.7953, -1.0662, -0.4940],\n",
      "        [-0.5644,  0.5372,  0.2991],\n",
      "        [-2.3068,  0.3768,  2.4609],\n",
      "        [ 1.7953, -1.0662, -0.4940],\n",
      "        [ 1.7953, -1.0662, -0.4940],\n",
      "        [-0.1430, -1.1763,  1.8641]], grad_fn=<AddBackward0>)\n",
      "progress: 164 loss= 0.24754385650157928\n",
      "tensor([[ 1.7970, -1.0674, -0.4946],\n",
      "        [-0.5652,  0.5374,  0.2994],\n",
      "        [-2.3086,  0.3766,  2.4630],\n",
      "        [ 1.7970, -1.0674, -0.4946],\n",
      "        [ 1.7970, -1.0674, -0.4946],\n",
      "        [-0.1439, -1.1773,  1.8659]], grad_fn=<AddBackward0>)\n",
      "progress: 165 loss= 0.24723680317401886\n",
      "tensor([[ 1.7967, -1.0671, -0.4948],\n",
      "        [-0.5673,  0.5393,  0.2997],\n",
      "        [-2.3130,  0.3793,  2.4649],\n",
      "        [ 1.7967, -1.0671, -0.4948],\n",
      "        [ 1.7967, -1.0671, -0.4948],\n",
      "        [-0.1460, -1.1768,  1.8676]], grad_fn=<AddBackward0>)\n",
      "progress: 166 loss= 0.2469707876443863\n",
      "tensor([[ 1.7991, -1.0685, -0.4958],\n",
      "        [-0.5664,  0.5393,  0.2987],\n",
      "        [-2.3131,  0.3787,  2.4658],\n",
      "        [ 1.7991, -1.0685, -0.4958],\n",
      "        [ 1.7991, -1.0685, -0.4958],\n",
      "        [-0.1451, -1.1781,  1.8682]], grad_fn=<AddBackward0>)\n",
      "progress: 167 loss= 0.24666257202625275\n",
      "tensor([[ 1.7990, -1.0682, -0.4961],\n",
      "        [-0.5684,  0.5411,  0.2990],\n",
      "        [-2.3175,  0.3814,  2.4677],\n",
      "        [ 1.7990, -1.0682, -0.4961],\n",
      "        [ 1.7990, -1.0682, -0.4961],\n",
      "        [-0.1472, -1.1776,  1.8699]], grad_fn=<AddBackward0>)\n",
      "progress: 168 loss= 0.24639128148555756\n",
      "tensor([[ 1.8012, -1.0695, -0.4970],\n",
      "        [-0.5675,  0.5412,  0.2980],\n",
      "        [-2.3176,  0.3809,  2.4686],\n",
      "        [ 1.8012, -1.0695, -0.4970],\n",
      "        [ 1.8012, -1.0695, -0.4970],\n",
      "        [-0.1464, -1.1789,  1.8705]], grad_fn=<AddBackward0>)\n",
      "progress: 169 loss= 0.24609006941318512\n",
      "tensor([[ 1.8013, -1.0692, -0.4974],\n",
      "        [-0.5695,  0.5429,  0.2983],\n",
      "        [-2.3219,  0.3836,  2.4705],\n",
      "        [ 1.8013, -1.0692, -0.4974],\n",
      "        [ 1.8013, -1.0692, -0.4974],\n",
      "        [-0.1485, -1.1784,  1.8722]], grad_fn=<AddBackward0>)\n",
      "progress: 170 loss= 0.24581378698349\n",
      "tensor([[ 1.8033, -1.0705, -0.4982],\n",
      "        [-0.5687,  0.5432,  0.2973],\n",
      "        [-2.3220,  0.3830,  2.4714],\n",
      "        [ 1.8033, -1.0705, -0.4982],\n",
      "        [ 1.8033, -1.0705, -0.4982],\n",
      "        [-0.1476, -1.1798,  1.8728]], grad_fn=<AddBackward0>)\n",
      "progress: 171 loss= 0.24551932513713837\n",
      "tensor([[ 1.8036, -1.0703, -0.4988],\n",
      "        [-0.5705,  0.5447,  0.2976],\n",
      "        [-2.3264,  0.3858,  2.4733],\n",
      "        [ 1.8036, -1.0703, -0.4988],\n",
      "        [ 1.8036, -1.0703, -0.4988],\n",
      "        [-0.1497, -1.1793,  1.8745]], grad_fn=<AddBackward0>)\n",
      "progress: 172 loss= 0.2452382892370224\n",
      "tensor([[ 1.8054, -1.0716, -0.4994],\n",
      "        [-0.5699,  0.5451,  0.2966],\n",
      "        [-2.3265,  0.3852,  2.4742],\n",
      "        [ 1.8054, -1.0716, -0.4994],\n",
      "        [ 1.8054, -1.0716, -0.4994],\n",
      "        [-0.1489, -1.1806,  1.8751]], grad_fn=<AddBackward0>)\n",
      "progress: 173 loss= 0.24495021998882294\n",
      "tensor([[ 1.8058, -1.0713, -0.5000],\n",
      "        [-0.5716,  0.5465,  0.2969],\n",
      "        [-2.3308,  0.3879,  2.4761],\n",
      "        [ 1.8058, -1.0713, -0.5000],\n",
      "        [ 1.8058, -1.0713, -0.5000],\n",
      "        [-0.1510, -1.1801,  1.8768]], grad_fn=<AddBackward0>)\n",
      "progress: 174 loss= 0.24467511475086212\n",
      "tensor([[ 1.8068, -1.0725, -0.5001],\n",
      "        [-0.5729,  0.5473,  0.2971],\n",
      "        [-2.3327,  0.3877,  2.4782],\n",
      "        [ 1.8068, -1.0725, -0.5001],\n",
      "        [ 1.8068, -1.0725, -0.5001],\n",
      "        [-0.1518, -1.1811,  1.8786]], grad_fn=<AddBackward0>)\n",
      "progress: 175 loss= 0.2443724423646927\n",
      "tensor([[ 1.8079, -1.0724, -0.5012],\n",
      "        [-0.5727,  0.5483,  0.2961],\n",
      "        [-2.3353,  0.3901,  2.4789],\n",
      "        [ 1.8079, -1.0724, -0.5012],\n",
      "        [ 1.8079, -1.0724, -0.5012],\n",
      "        [-0.1522, -1.1809,  1.8791]], grad_fn=<AddBackward0>)\n",
      "progress: 176 loss= 0.24412304162979126\n",
      "tensor([[ 1.8091, -1.0735, -0.5014],\n",
      "        [-0.5741,  0.5493,  0.2964],\n",
      "        [-2.3371,  0.3898,  2.4809],\n",
      "        [ 1.8091, -1.0735, -0.5014],\n",
      "        [ 1.8091, -1.0735, -0.5014],\n",
      "        [-0.1531, -1.1819,  1.8809]], grad_fn=<AddBackward0>)\n",
      "progress: 177 loss= 0.24378733336925507\n",
      "tensor([[ 1.8100, -1.0734, -0.5024],\n",
      "        [-0.5738,  0.5501,  0.2954],\n",
      "        [-2.3397,  0.3922,  2.4816],\n",
      "        [ 1.8100, -1.0734, -0.5024],\n",
      "        [ 1.8100, -1.0734, -0.5024],\n",
      "        [-0.1534, -1.1818,  1.8814]], grad_fn=<AddBackward0>)\n",
      "progress: 178 loss= 0.24357278645038605\n",
      "tensor([[ 1.8114, -1.0746, -0.5027],\n",
      "        [-0.5752,  0.5511,  0.2957],\n",
      "        [-2.3416,  0.3920,  2.4837],\n",
      "        [ 1.8114, -1.0746, -0.5027],\n",
      "        [ 1.8114, -1.0746, -0.5027],\n",
      "        [-0.1543, -1.1827,  1.8831]], grad_fn=<AddBackward0>)\n",
      "progress: 179 loss= 0.2432095855474472\n",
      "tensor([[ 1.8133, -1.0759, -0.5035],\n",
      "        [-0.5737,  0.5505,  0.2948],\n",
      "        [-2.3417,  0.3914,  2.4846],\n",
      "        [ 1.8133, -1.0759, -0.5035],\n",
      "        [ 1.8133, -1.0759, -0.5035],\n",
      "        [-0.1534, -1.1840,  1.8837]], grad_fn=<AddBackward0>)\n",
      "progress: 180 loss= 0.24301892518997192\n",
      "tensor([[ 1.8137, -1.0756, -0.5040],\n",
      "        [-0.5763,  0.5529,  0.2950],\n",
      "        [-2.3460,  0.3941,  2.4865],\n",
      "        [ 1.8137, -1.0756, -0.5040],\n",
      "        [ 1.8137, -1.0756, -0.5040],\n",
      "        [-0.1555, -1.1835,  1.8854]], grad_fn=<AddBackward0>)\n",
      "progress: 181 loss= 0.24264311790466309\n",
      "tensor([[ 1.8154, -1.0769, -0.5047],\n",
      "        [-0.5749,  0.5524,  0.2941],\n",
      "        [-2.3461,  0.3936,  2.4873],\n",
      "        [ 1.8154, -1.0769, -0.5047],\n",
      "        [ 1.8154, -1.0769, -0.5047],\n",
      "        [-0.1547, -1.1849,  1.8860]], grad_fn=<AddBackward0>)\n",
      "progress: 182 loss= 0.242457315325737\n",
      "tensor([[ 1.8158, -1.0767, -0.5053],\n",
      "        [-0.5774,  0.5547,  0.2943],\n",
      "        [-2.3505,  0.3963,  2.4893],\n",
      "        [ 1.8158, -1.0767, -0.5053],\n",
      "        [ 1.8158, -1.0767, -0.5053],\n",
      "        [-0.1568, -1.1844,  1.8877]], grad_fn=<AddBackward0>)\n",
      "progress: 183 loss= 0.2420881986618042\n",
      "tensor([[ 1.8168, -1.0778, -0.5054],\n",
      "        [-0.5779,  0.5547,  0.2946],\n",
      "        [-2.3523,  0.3961,  2.4913],\n",
      "        [ 1.8168, -1.0778, -0.5054],\n",
      "        [ 1.8168, -1.0778, -0.5054],\n",
      "        [-0.1577, -1.1853,  1.8895]], grad_fn=<AddBackward0>)\n",
      "progress: 184 loss= 0.24188782274723053\n",
      "tensor([[ 1.8179, -1.0777, -0.5065],\n",
      "        [-0.5785,  0.5565,  0.2936],\n",
      "        [-2.3549,  0.3985,  2.4920],\n",
      "        [ 1.8179, -1.0777, -0.5065],\n",
      "        [ 1.8179, -1.0777, -0.5065],\n",
      "        [-0.1580, -1.1852,  1.8900]], grad_fn=<AddBackward0>)\n",
      "progress: 185 loss= 0.24154478311538696\n",
      "tensor([[ 1.8191, -1.0788, -0.5067],\n",
      "        [-0.5791,  0.5566,  0.2939],\n",
      "        [-2.3567,  0.3982,  2.4941],\n",
      "        [ 1.8191, -1.0788, -0.5067],\n",
      "        [ 1.8191, -1.0788, -0.5067],\n",
      "        [-0.1589, -1.1862,  1.8918]], grad_fn=<AddBackward0>)\n",
      "progress: 186 loss= 0.24131040275096893\n",
      "tensor([[ 1.8200, -1.0787, -0.5077],\n",
      "        [-0.5795,  0.5583,  0.2929],\n",
      "        [-2.3593,  0.4006,  2.4948],\n",
      "        [ 1.8200, -1.0787, -0.5077],\n",
      "        [ 1.8200, -1.0787, -0.5077],\n",
      "        [-0.1593, -1.1860,  1.8923]], grad_fn=<AddBackward0>)\n",
      "progress: 187 loss= 0.241003155708313\n",
      "tensor([[ 1.8213, -1.0799, -0.5080],\n",
      "        [-0.5803,  0.5586,  0.2932],\n",
      "        [-2.3612,  0.4004,  2.4969],\n",
      "        [ 1.8213, -1.0799, -0.5080],\n",
      "        [ 1.8213, -1.0799, -0.5080],\n",
      "        [-0.1601, -1.1870,  1.8941]], grad_fn=<AddBackward0>)\n",
      "progress: 188 loss= 0.2407347559928894\n",
      "tensor([[ 1.8220, -1.0797, -0.5088],\n",
      "        [-0.5806,  0.5601,  0.2922],\n",
      "        [-2.3638,  0.4028,  2.4975],\n",
      "        [ 1.8220, -1.0797, -0.5088],\n",
      "        [ 1.8220, -1.0797, -0.5088],\n",
      "        [-0.1605, -1.1868,  1.8946]], grad_fn=<AddBackward0>)\n",
      "progress: 189 loss= 0.2404632568359375\n",
      "tensor([[ 1.8236, -1.0809, -0.5093],\n",
      "        [-0.5815,  0.5605,  0.2925],\n",
      "        [-2.3656,  0.4025,  2.4996],\n",
      "        [ 1.8236, -1.0809, -0.5093],\n",
      "        [ 1.8236, -1.0809, -0.5093],\n",
      "        [-0.1613, -1.1878,  1.8963]], grad_fn=<AddBackward0>)\n",
      "progress: 190 loss= 0.24016094207763672\n",
      "tensor([[ 1.8241, -1.0807, -0.5100],\n",
      "        [-0.5817,  0.5619,  0.2915],\n",
      "        [-2.3682,  0.4049,  2.5003],\n",
      "        [ 1.8241, -1.0807, -0.5100],\n",
      "        [ 1.8241, -1.0807, -0.5100],\n",
      "        [-0.1617, -1.1876,  1.8968]], grad_fn=<AddBackward0>)\n",
      "progress: 191 loss= 0.2399251013994217\n",
      "tensor([[ 1.8258, -1.0819, -0.5105],\n",
      "        [-0.5827,  0.5624,  0.2918],\n",
      "        [-2.3700,  0.4047,  2.5024],\n",
      "        [ 1.8258, -1.0819, -0.5105],\n",
      "        [ 1.8258, -1.0819, -0.5105],\n",
      "        [-0.1626, -1.1886,  1.8986]], grad_fn=<AddBackward0>)\n",
      "progress: 192 loss= 0.23959793150424957\n",
      "tensor([[ 1.8255, -1.0816, -0.5107],\n",
      "        [-0.5845,  0.5640,  0.2920],\n",
      "        [-2.3744,  0.4074,  2.5043],\n",
      "        [ 1.8255, -1.0816, -0.5107],\n",
      "        [ 1.8255, -1.0816, -0.5107],\n",
      "        [-0.1647, -1.1881,  1.9003]], grad_fn=<AddBackward0>)\n",
      "progress: 193 loss= 0.2393789440393448\n",
      "tensor([[ 1.8278, -1.0830, -0.5117],\n",
      "        [-0.5839,  0.5644,  0.2911],\n",
      "        [-2.3746,  0.4069,  2.5053],\n",
      "        [ 1.8278, -1.0830, -0.5117],\n",
      "        [ 1.8278, -1.0830, -0.5117],\n",
      "        [-0.1638, -1.1894,  1.9009]], grad_fn=<AddBackward0>)\n",
      "progress: 194 loss= 0.23904286324977875\n",
      "tensor([[ 1.8277, -1.0826, -0.5120],\n",
      "        [-0.5856,  0.5658,  0.2913],\n",
      "        [-2.3790,  0.4096,  2.5073],\n",
      "        [ 1.8277, -1.0826, -0.5120],\n",
      "        [ 1.8277, -1.0826, -0.5120],\n",
      "        [-0.1659, -1.1889,  1.9026]], grad_fn=<AddBackward0>)\n",
      "progress: 195 loss= 0.23881889879703522\n",
      "tensor([[ 1.8299, -1.0840, -0.5129],\n",
      "        [-0.5851,  0.5663,  0.2904],\n",
      "        [-2.3793,  0.4091,  2.5083],\n",
      "        [ 1.8299, -1.0840, -0.5129],\n",
      "        [ 1.8299, -1.0840, -0.5129],\n",
      "        [-0.1651, -1.1902,  1.9032]], grad_fn=<AddBackward0>)\n",
      "progress: 196 loss= 0.2384871244430542\n",
      "tensor([[ 1.8300, -1.0837, -0.5133],\n",
      "        [-0.5867,  0.5676,  0.2906],\n",
      "        [-2.3837,  0.4118,  2.5103],\n",
      "        [ 1.8300, -1.0837, -0.5133],\n",
      "        [ 1.8300, -1.0837, -0.5133],\n",
      "        [-0.1672, -1.1897,  1.9050]], grad_fn=<AddBackward0>)\n",
      "progress: 197 loss= 0.23826086521148682\n",
      "tensor([[ 1.8319, -1.0850, -0.5140],\n",
      "        [-0.5863,  0.5682,  0.2897],\n",
      "        [-2.3839,  0.4113,  2.5113],\n",
      "        [ 1.8319, -1.0850, -0.5140],\n",
      "        [ 1.8319, -1.0850, -0.5140],\n",
      "        [-0.1664, -1.1910,  1.9056]], grad_fn=<AddBackward0>)\n",
      "progress: 198 loss= 0.23793305456638336\n",
      "tensor([[ 1.8322, -1.0847, -0.5146],\n",
      "        [-0.5877,  0.5694,  0.2899],\n",
      "        [-2.3884,  0.4140,  2.5133],\n",
      "        [ 1.8322, -1.0847, -0.5146],\n",
      "        [ 1.8322, -1.0847, -0.5146],\n",
      "        [-0.1685, -1.1905,  1.9073]], grad_fn=<AddBackward0>)\n",
      "progress: 199 loss= 0.23770463466644287\n",
      "tensor([[ 1.8340, -1.0859, -0.5152],\n",
      "        [-0.5874,  0.5701,  0.2890],\n",
      "        [-2.3886,  0.4135,  2.5143],\n",
      "        [ 1.8340, -1.0859, -0.5152],\n",
      "        [ 1.8340, -1.0859, -0.5152],\n",
      "        [-0.1676, -1.1918,  1.9079]], grad_fn=<AddBackward0>)\n",
      "progress: 200 loss= 0.23738788068294525\n",
      "tensor([[ 1.8356, -1.0872, -0.5157],\n",
      "        [-0.5877,  0.5698,  0.2893],\n",
      "        [-2.3905,  0.4133,  2.5165],\n",
      "        [ 1.8356, -1.0872, -0.5157],\n",
      "        [ 1.8356, -1.0872, -0.5157],\n",
      "        [-0.1685, -1.1928,  1.9097]], grad_fn=<AddBackward0>)\n",
      "progress: 201 loss= 0.23715324699878693\n",
      "tensor([[ 1.8354, -1.0868, -0.5159],\n",
      "        [-0.5902,  0.5722,  0.2895],\n",
      "        [-2.3950,  0.4160,  2.5185],\n",
      "        [ 1.8354, -1.0868, -0.5159],\n",
      "        [ 1.8354, -1.0868, -0.5159],\n",
      "        [-0.1706, -1.1923,  1.9114]], grad_fn=<AddBackward0>)\n",
      "progress: 202 loss= 0.23684380948543549\n",
      "tensor([[ 1.8377, -1.0882, -0.5169],\n",
      "        [-0.5889,  0.5718,  0.2886],\n",
      "        [-2.3952,  0.4155,  2.5194],\n",
      "        [ 1.8377, -1.0882, -0.5169],\n",
      "        [ 1.8377, -1.0882, -0.5169],\n",
      "        [-0.1698, -1.1936,  1.9120]], grad_fn=<AddBackward0>)\n",
      "progress: 203 loss= 0.23660312592983246\n",
      "tensor([[ 1.8376, -1.0878, -0.5172],\n",
      "        [-0.5913,  0.5740,  0.2887],\n",
      "        [-2.3996,  0.4182,  2.5215],\n",
      "        [ 1.8376, -1.0878, -0.5172],\n",
      "        [ 1.8376, -1.0878, -0.5172],\n",
      "        [-0.1719, -1.1931,  1.9137]], grad_fn=<AddBackward0>)\n",
      "progress: 204 loss= 0.23629246652126312\n",
      "tensor([[ 1.8397, -1.0892, -0.5181],\n",
      "        [-0.5901,  0.5737,  0.2879],\n",
      "        [-2.3998,  0.4177,  2.5224],\n",
      "        [ 1.8397, -1.0892, -0.5181],\n",
      "        [ 1.8397, -1.0892, -0.5181],\n",
      "        [-0.1711, -1.1944,  1.9143]], grad_fn=<AddBackward0>)\n",
      "progress: 205 loss= 0.2360546588897705\n",
      "tensor([[ 1.8398, -1.0889, -0.5185],\n",
      "        [-0.5924,  0.5758,  0.2880],\n",
      "        [-2.4042,  0.4205,  2.5244],\n",
      "        [ 1.8398, -1.0889, -0.5185],\n",
      "        [ 1.8398, -1.0889, -0.5185],\n",
      "        [-0.1732, -1.1939,  1.9160]], grad_fn=<AddBackward0>)\n",
      "progress: 206 loss= 0.23574303090572357\n",
      "tensor([[ 1.8417, -1.0901, -0.5192],\n",
      "        [-0.5913,  0.5757,  0.2871],\n",
      "        [-2.4045,  0.4199,  2.5254],\n",
      "        [ 1.8417, -1.0901, -0.5192],\n",
      "        [ 1.8417, -1.0901, -0.5192],\n",
      "        [-0.1723, -1.1952,  1.9166]], grad_fn=<AddBackward0>)\n",
      "progress: 207 loss= 0.2355077713727951\n",
      "tensor([[ 1.8420, -1.0899, -0.5198],\n",
      "        [-0.5934,  0.5776,  0.2873],\n",
      "        [-2.4089,  0.4227,  2.5274],\n",
      "        [ 1.8420, -1.0899, -0.5198],\n",
      "        [ 1.8420, -1.0899, -0.5198],\n",
      "        [-0.1744, -1.1947,  1.9183]], grad_fn=<AddBackward0>)\n",
      "progress: 208 loss= 0.23519544303417206\n",
      "tensor([[ 1.8438, -1.0911, -0.5204],\n",
      "        [-0.5925,  0.5776,  0.2864],\n",
      "        [-2.4091,  0.4221,  2.5284],\n",
      "        [ 1.8438, -1.0911, -0.5204],\n",
      "        [ 1.8438, -1.0911, -0.5204],\n",
      "        [-0.1736, -1.1960,  1.9189]], grad_fn=<AddBackward0>)\n",
      "progress: 209 loss= 0.23496241867542267\n",
      "tensor([[ 1.8441, -1.0909, -0.5210],\n",
      "        [-0.5945,  0.5794,  0.2866],\n",
      "        [-2.4135,  0.4249,  2.5304],\n",
      "        [ 1.8441, -1.0909, -0.5210],\n",
      "        [ 1.8441, -1.0909, -0.5210],\n",
      "        [-0.1757, -1.1955,  1.9206]], grad_fn=<AddBackward0>)\n",
      "progress: 210 loss= 0.2346612960100174\n",
      "tensor([[ 1.8451, -1.0920, -0.5211],\n",
      "        [-0.5954,  0.5799,  0.2869],\n",
      "        [-2.4154,  0.4247,  2.5325],\n",
      "        [ 1.8451, -1.0920, -0.5211],\n",
      "        [ 1.8451, -1.0920, -0.5211],\n",
      "        [-0.1766, -1.1965,  1.9224]], grad_fn=<AddBackward0>)\n",
      "progress: 211 loss= 0.23440705239772797\n",
      "tensor([[ 1.8462, -1.0918, -0.5222],\n",
      "        [-0.5956,  0.5812,  0.2859],\n",
      "        [-2.4181,  0.4271,  2.5333],\n",
      "        [ 1.8462, -1.0918, -0.5222],\n",
      "        [ 1.8462, -1.0918, -0.5222],\n",
      "        [-0.1770, -1.1963,  1.9229]], grad_fn=<AddBackward0>)\n",
      "progress: 212 loss= 0.23413611948490143\n",
      "tensor([[ 1.8474, -1.0930, -0.5224],\n",
      "        [-0.5966,  0.5818,  0.2862],\n",
      "        [-2.4200,  0.4269,  2.5355],\n",
      "        [ 1.8474, -1.0930, -0.5224],\n",
      "        [ 1.8474, -1.0930, -0.5224],\n",
      "        [-0.1778, -1.1973,  1.9247]], grad_fn=<AddBackward0>)\n",
      "progress: 213 loss= 0.23384636640548706\n",
      "tensor([[ 1.8482, -1.0928, -0.5233],\n",
      "        [-0.5966,  0.5830,  0.2852],\n",
      "        [-2.4227,  0.4293,  2.5363],\n",
      "        [ 1.8482, -1.0928, -0.5233],\n",
      "        [ 1.8482, -1.0928, -0.5233],\n",
      "        [-0.1782, -1.1971,  1.9252]], grad_fn=<AddBackward0>)\n",
      "progress: 214 loss= 0.23361261188983917\n",
      "tensor([[ 1.8496, -1.0940, -0.5237],\n",
      "        [-0.5978,  0.5838,  0.2855],\n",
      "        [-2.4247,  0.4291,  2.5385],\n",
      "        [ 1.8496, -1.0940, -0.5237],\n",
      "        [ 1.8496, -1.0940, -0.5237],\n",
      "        [-0.1791, -1.1981,  1.9270]], grad_fn=<AddBackward0>)\n",
      "progress: 215 loss= 0.2332872897386551\n",
      "tensor([[ 1.8502, -1.0938, -0.5245],\n",
      "        [-0.5977,  0.5847,  0.2845],\n",
      "        [-2.4274,  0.4315,  2.5393],\n",
      "        [ 1.8502, -1.0938, -0.5245],\n",
      "        [ 1.8502, -1.0938, -0.5245],\n",
      "        [-0.1795, -1.1979,  1.9275]], grad_fn=<AddBackward0>)\n",
      "progress: 216 loss= 0.2330908179283142\n",
      "tensor([[ 1.8518, -1.0950, -0.5250],\n",
      "        [-0.5990,  0.5857,  0.2848],\n",
      "        [-2.4293,  0.4313,  2.5414],\n",
      "        [ 1.8518, -1.0950, -0.5250],\n",
      "        [ 1.8518, -1.0950, -0.5250],\n",
      "        [-0.1803, -1.1989,  1.9293]], grad_fn=<AddBackward0>)\n",
      "progress: 217 loss= 0.232729971408844\n",
      "tensor([[ 1.8522, -1.0948, -0.5256],\n",
      "        [-0.5988,  0.5865,  0.2838],\n",
      "        [-2.4320,  0.4337,  2.5422],\n",
      "        [ 1.8522, -1.0948, -0.5256],\n",
      "        [ 1.8522, -1.0948, -0.5256],\n",
      "        [-0.1807, -1.1987,  1.9298]], grad_fn=<AddBackward0>)\n",
      "progress: 218 loss= 0.23257063329219818\n",
      "tensor([[ 1.8539, -1.0960, -0.5261],\n",
      "        [-0.6002,  0.5876,  0.2841],\n",
      "        [-2.4339,  0.4334,  2.5444],\n",
      "        [ 1.8539, -1.0960, -0.5261],\n",
      "        [ 1.8539, -1.0960, -0.5261],\n",
      "        [-0.1816, -1.1997,  1.9316]], grad_fn=<AddBackward0>)\n",
      "progress: 219 loss= 0.2321987748146057\n",
      "tensor([[ 1.8549, -1.0971, -0.5262],\n",
      "        [-0.6004,  0.5873,  0.2844],\n",
      "        [-2.4358,  0.4332,  2.5465],\n",
      "        [ 1.8549, -1.0971, -0.5262],\n",
      "        [ 1.8549, -1.0971, -0.5262],\n",
      "        [-0.1824, -1.2007,  1.9334]], grad_fn=<AddBackward0>)\n",
      "progress: 220 loss= 0.2320278137922287\n",
      "tensor([[ 1.8559, -1.0969, -0.5273],\n",
      "        [-0.6012,  0.5894,  0.2834],\n",
      "        [-2.4385,  0.4356,  2.5473],\n",
      "        [ 1.8559, -1.0969, -0.5273],\n",
      "        [ 1.8559, -1.0969, -0.5273],\n",
      "        [-0.1828, -1.2005,  1.9339]], grad_fn=<AddBackward0>)\n",
      "progress: 221 loss= 0.23168174922466278\n",
      "tensor([[ 1.8571, -1.0981, -0.5275],\n",
      "        [-0.6016,  0.5893,  0.2837],\n",
      "        [-2.4404,  0.4354,  2.5495],\n",
      "        [ 1.8571, -1.0981, -0.5275],\n",
      "        [ 1.8571, -1.0981, -0.5275],\n",
      "        [-0.1837, -1.2015,  1.9357]], grad_fn=<AddBackward0>)\n",
      "progress: 222 loss= 0.23147428035736084\n",
      "tensor([[ 1.8579, -1.0979, -0.5284],\n",
      "        [-0.6023,  0.5911,  0.2826],\n",
      "        [-2.4431,  0.4378,  2.5503],\n",
      "        [ 1.8579, -1.0979, -0.5284],\n",
      "        [ 1.8579, -1.0979, -0.5284],\n",
      "        [-0.1841, -1.2013,  1.9362]], grad_fn=<AddBackward0>)\n",
      "progress: 223 loss= 0.2311662882566452\n",
      "tensor([[ 1.8593, -1.0991, -0.5288],\n",
      "        [-0.6028,  0.5912,  0.2829],\n",
      "        [-2.4449,  0.4376,  2.5524],\n",
      "        [ 1.8593, -1.0991, -0.5288],\n",
      "        [ 1.8593, -1.0991, -0.5288],\n",
      "        [-0.1849, -1.2022,  1.9380]], grad_fn=<AddBackward0>)\n",
      "progress: 224 loss= 0.23092246055603027\n",
      "tensor([[ 1.8599, -1.0989, -0.5296],\n",
      "        [-0.6033,  0.5929,  0.2819],\n",
      "        [-2.4477,  0.4400,  2.5532],\n",
      "        [ 1.8599, -1.0989, -0.5296],\n",
      "        [ 1.8599, -1.0989, -0.5296],\n",
      "        [-0.1853, -1.2021,  1.9385]], grad_fn=<AddBackward0>)\n",
      "progress: 225 loss= 0.23065251111984253\n",
      "tensor([[ 1.8615, -1.1001, -0.5301],\n",
      "        [-0.6041,  0.5932,  0.2822],\n",
      "        [-2.4495,  0.4398,  2.5554],\n",
      "        [ 1.8615, -1.1001, -0.5301],\n",
      "        [ 1.8615, -1.1001, -0.5301],\n",
      "        [-0.1861, -1.2030,  1.9403]], grad_fn=<AddBackward0>)\n",
      "progress: 226 loss= 0.23037230968475342\n",
      "tensor([[ 1.8618, -1.0998, -0.5307],\n",
      "        [-0.6044,  0.5947,  0.2812],\n",
      "        [-2.4522,  0.4422,  2.5561],\n",
      "        [ 1.8618, -1.0998, -0.5307],\n",
      "        [ 1.8618, -1.0998, -0.5307],\n",
      "        [-0.1865, -1.2029,  1.9408]], grad_fn=<AddBackward0>)\n",
      "progress: 227 loss= 0.23014037311077118\n",
      "tensor([[ 1.8635, -1.1010, -0.5312],\n",
      "        [-0.6053,  0.5952,  0.2815],\n",
      "        [-2.4541,  0.4420,  2.5583],\n",
      "        [ 1.8635, -1.1010, -0.5312],\n",
      "        [ 1.8635, -1.1010, -0.5312],\n",
      "        [-0.1874, -1.2038,  1.9425]], grad_fn=<AddBackward0>)\n",
      "progress: 228 loss= 0.2298406958580017\n",
      "tensor([[ 1.8633, -1.1007, -0.5314],\n",
      "        [-0.6072,  0.5968,  0.2817],\n",
      "        [-2.4585,  0.4448,  2.5603],\n",
      "        [ 1.8633, -1.1007, -0.5314],\n",
      "        [ 1.8633, -1.1007, -0.5314],\n",
      "        [-0.1895, -1.2033,  1.9442]], grad_fn=<AddBackward0>)\n",
      "progress: 229 loss= 0.2296130508184433\n",
      "tensor([[ 1.8655, -1.1020, -0.5324],\n",
      "        [-0.6065,  0.5971,  0.2808],\n",
      "        [-2.4587,  0.4442,  2.5612],\n",
      "        [ 1.8655, -1.1020, -0.5324],\n",
      "        [ 1.8655, -1.1020, -0.5324],\n",
      "        [-0.1886, -1.2046,  1.9448]], grad_fn=<AddBackward0>)\n",
      "progress: 230 loss= 0.22931240499019623\n",
      "tensor([[ 1.8655, -1.1017, -0.5327],\n",
      "        [-0.6082,  0.5986,  0.2810],\n",
      "        [-2.4631,  0.4469,  2.5632],\n",
      "        [ 1.8655, -1.1017, -0.5327],\n",
      "        [ 1.8655, -1.1017, -0.5327],\n",
      "        [-0.1907, -1.2041,  1.9465]], grad_fn=<AddBackward0>)\n",
      "progress: 231 loss= 0.22908556461334229\n",
      "tensor([[ 1.8675, -1.1029, -0.5335],\n",
      "        [-0.6077,  0.5991,  0.2801],\n",
      "        [-2.4633,  0.4464,  2.5641],\n",
      "        [ 1.8675, -1.1029, -0.5335],\n",
      "        [ 1.8675, -1.1029, -0.5335],\n",
      "        [-0.1898, -1.2054,  1.9471]], grad_fn=<AddBackward0>)\n",
      "progress: 232 loss= 0.2287856936454773\n",
      "tensor([[ 1.8676, -1.1026, -0.5340],\n",
      "        [-0.6093,  0.6004,  0.2803],\n",
      "        [-2.4676,  0.4491,  2.5661],\n",
      "        [ 1.8676, -1.1026, -0.5340],\n",
      "        [ 1.8676, -1.1026, -0.5340],\n",
      "        [-0.1919, -1.2049,  1.9488]], grad_fn=<AddBackward0>)\n",
      "progress: 233 loss= 0.22855983674526215\n",
      "tensor([[ 1.8694, -1.1039, -0.5346],\n",
      "        [-0.6089,  0.6010,  0.2794],\n",
      "        [-2.4678,  0.4486,  2.5671],\n",
      "        [ 1.8694, -1.1039, -0.5346],\n",
      "        [ 1.8694, -1.1039, -0.5346],\n",
      "        [-0.1911, -1.2062,  1.9494]], grad_fn=<AddBackward0>)\n",
      "progress: 234 loss= 0.2282605618238449\n",
      "tensor([[ 1.8698, -1.1036, -0.5352],\n",
      "        [-0.6103,  0.6022,  0.2796],\n",
      "        [-2.4722,  0.4513,  2.5690],\n",
      "        [ 1.8698, -1.1036, -0.5352],\n",
      "        [ 1.8698, -1.1036, -0.5352],\n",
      "        [-0.1931, -1.2057,  1.9511]], grad_fn=<AddBackward0>)\n",
      "progress: 235 loss= 0.22803859412670135\n",
      "tensor([[ 1.8707, -1.1047, -0.5353],\n",
      "        [-0.6117,  0.6032,  0.2798],\n",
      "        [-2.4741,  0.4511,  2.5712],\n",
      "        [ 1.8707, -1.1047, -0.5353],\n",
      "        [ 1.8707, -1.1047, -0.5353],\n",
      "        [-0.1940, -1.2067,  1.9528]], grad_fn=<AddBackward0>)\n",
      "progress: 236 loss= 0.2277432680130005\n",
      "tensor([[ 1.8730, -1.1061, -0.5363],\n",
      "        [-0.6103,  0.6026,  0.2789],\n",
      "        [-2.4742,  0.4505,  2.5721],\n",
      "        [ 1.8730, -1.1061, -0.5363],\n",
      "        [ 1.8730, -1.1061, -0.5363],\n",
      "        [-0.1931, -1.2080,  1.9534]], grad_fn=<AddBackward0>)\n",
      "progress: 237 loss= 0.22752588987350464\n",
      "tensor([[ 1.8729, -1.1057, -0.5365],\n",
      "        [-0.6127,  0.6050,  0.2791],\n",
      "        [-2.4786,  0.4533,  2.5741],\n",
      "        [ 1.8729, -1.1057, -0.5365],\n",
      "        [ 1.8729, -1.1057, -0.5365],\n",
      "        [-0.1952, -1.2075,  1.9551]], grad_fn=<AddBackward0>)\n",
      "progress: 238 loss= 0.22722209990024567\n",
      "tensor([[ 1.8750, -1.1070, -0.5374],\n",
      "        [-0.6115,  0.6046,  0.2782],\n",
      "        [-2.4788,  0.4527,  2.5750],\n",
      "        [ 1.8750, -1.1070, -0.5374],\n",
      "        [ 1.8750, -1.1070, -0.5374],\n",
      "        [-0.1943, -1.2088,  1.9557]], grad_fn=<AddBackward0>)\n",
      "progress: 239 loss= 0.22700433433055878\n",
      "tensor([[ 1.8750, -1.1067, -0.5378],\n",
      "        [-0.6138,  0.6068,  0.2784],\n",
      "        [-2.4832,  0.4555,  2.5770],\n",
      "        [ 1.8750, -1.1067, -0.5378],\n",
      "        [ 1.8750, -1.1067, -0.5378],\n",
      "        [-0.1964, -1.2083,  1.9573]], grad_fn=<AddBackward0>)\n",
      "progress: 240 loss= 0.22670263051986694\n",
      "tensor([[ 1.8770, -1.1079, -0.5385],\n",
      "        [-0.6127,  0.6066,  0.2775],\n",
      "        [-2.4833,  0.4549,  2.5779],\n",
      "        [ 1.8770, -1.1079, -0.5385],\n",
      "        [ 1.8770, -1.1079, -0.5385],\n",
      "        [-0.1955, -1.2096,  1.9579]], grad_fn=<AddBackward0>)\n",
      "progress: 241 loss= 0.22648434340953827\n",
      "tensor([[ 1.8772, -1.1076, -0.5391],\n",
      "        [-0.6149,  0.6086,  0.2777],\n",
      "        [-2.4877,  0.4576,  2.5799],\n",
      "        [ 1.8772, -1.1076, -0.5391],\n",
      "        [ 1.8772, -1.1076, -0.5391],\n",
      "        [-0.1976, -1.2091,  1.9596]], grad_fn=<AddBackward0>)\n",
      "progress: 242 loss= 0.22618478536605835\n",
      "tensor([[ 1.8789, -1.1089, -0.5397],\n",
      "        [-0.6139,  0.6085,  0.2768],\n",
      "        [-2.4879,  0.4571,  2.5809],\n",
      "        [ 1.8789, -1.1089, -0.5397],\n",
      "        [ 1.8789, -1.1089, -0.5397],\n",
      "        [-0.1968, -1.2104,  1.9602]], grad_fn=<AddBackward0>)\n",
      "progress: 243 loss= 0.22596579790115356\n",
      "tensor([[ 1.8793, -1.1086, -0.5403],\n",
      "        [-0.6159,  0.6103,  0.2770],\n",
      "        [-2.4922,  0.4598,  2.5828],\n",
      "        [ 1.8793, -1.1086, -0.5403],\n",
      "        [ 1.8793, -1.1086, -0.5403],\n",
      "        [-0.1988, -1.2099,  1.9619]], grad_fn=<AddBackward0>)\n",
      "progress: 244 loss= 0.2256765514612198\n",
      "tensor([[ 1.8802, -1.1097, -0.5403],\n",
      "        [-0.6168,  0.6108,  0.2772],\n",
      "        [-2.4941,  0.4596,  2.5849],\n",
      "        [ 1.8802, -1.1097, -0.5403],\n",
      "        [ 1.8802, -1.1097, -0.5403],\n",
      "        [-0.1996, -1.2109,  1.9636]], grad_fn=<AddBackward0>)\n",
      "progress: 245 loss= 0.22544091939926147\n",
      "tensor([[ 1.8812, -1.1095, -0.5414],\n",
      "        [-0.6170,  0.6121,  0.2763],\n",
      "        [-2.4968,  0.4620,  2.5857],\n",
      "        [ 1.8812, -1.1095, -0.5414],\n",
      "        [ 1.8812, -1.1095, -0.5414],\n",
      "        [-0.2000, -1.2107,  1.9641]], grad_fn=<AddBackward0>)\n",
      "progress: 246 loss= 0.22518043220043182\n",
      "tensor([[ 1.8824, -1.1106, -0.5416],\n",
      "        [-0.6180,  0.6128,  0.2765],\n",
      "        [-2.4986,  0.4618,  2.5878],\n",
      "        [ 1.8824, -1.1106, -0.5416],\n",
      "        [ 1.8824, -1.1106, -0.5416],\n",
      "        [-0.2009, -1.2116,  1.9659]], grad_fn=<AddBackward0>)\n",
      "progress: 247 loss= 0.22490720450878143\n",
      "tensor([[ 1.8832, -1.1105, -0.5425],\n",
      "        [-0.6180,  0.6139,  0.2755],\n",
      "        [-2.5013,  0.4642,  2.5886],\n",
      "        [ 1.8832, -1.1105, -0.5425],\n",
      "        [ 1.8832, -1.1105, -0.5425],\n",
      "        [-0.2012, -1.2115,  1.9664]], grad_fn=<AddBackward0>)\n",
      "progress: 248 loss= 0.22468583285808563\n",
      "tensor([[ 1.8846, -1.1116, -0.5429],\n",
      "        [-0.6192,  0.6148,  0.2758],\n",
      "        [-2.5031,  0.4639,  2.5907],\n",
      "        [ 1.8846, -1.1116, -0.5429],\n",
      "        [ 1.8846, -1.1116, -0.5429],\n",
      "        [-0.2021, -1.2124,  1.9681]], grad_fn=<AddBackward0>)\n",
      "progress: 249 loss= 0.2243751883506775\n",
      "tensor([[ 1.8852, -1.1114, -0.5436],\n",
      "        [-0.6190,  0.6157,  0.2748],\n",
      "        [-2.5058,  0.4663,  2.5915],\n",
      "        [ 1.8852, -1.1114, -0.5436],\n",
      "        [ 1.8852, -1.1114, -0.5436],\n",
      "        [-0.2025, -1.2123,  1.9686]], grad_fn=<AddBackward0>)\n",
      "progress: 250 loss= 0.22419290244579315\n",
      "tensor([[ 1.8867, -1.1126, -0.5441],\n",
      "        [-0.6204,  0.6167,  0.2751],\n",
      "        [-2.5076,  0.4661,  2.5936],\n",
      "        [ 1.8867, -1.1126, -0.5441],\n",
      "        [ 1.8867, -1.1126, -0.5441],\n",
      "        [-0.2033, -1.2132,  1.9704]], grad_fn=<AddBackward0>)\n",
      "progress: 251 loss= 0.2238447070121765\n",
      "tensor([[ 1.8871, -1.1123, -0.5447],\n",
      "        [-0.6201,  0.6175,  0.2741],\n",
      "        [-2.5103,  0.4685,  2.5944],\n",
      "        [ 1.8871, -1.1123, -0.5447],\n",
      "        [ 1.8871, -1.1123, -0.5447],\n",
      "        [-0.2037, -1.2131,  1.9709]], grad_fn=<AddBackward0>)\n",
      "progress: 252 loss= 0.2237013429403305\n",
      "tensor([[ 1.8887, -1.1135, -0.5453],\n",
      "        [-0.6215,  0.6185,  0.2744],\n",
      "        [-2.5121,  0.4683,  2.5965],\n",
      "        [ 1.8887, -1.1135, -0.5453],\n",
      "        [ 1.8887, -1.1135, -0.5453],\n",
      "        [-0.2045, -1.2140,  1.9726]], grad_fn=<AddBackward0>)\n",
      "progress: 253 loss= 0.2233484387397766\n",
      "tensor([[ 1.8897, -1.1146, -0.5454],\n",
      "        [-0.6218,  0.6183,  0.2746],\n",
      "        [-2.5140,  0.4680,  2.5986],\n",
      "        [ 1.8897, -1.1146, -0.5454],\n",
      "        [ 1.8897, -1.1146, -0.5454],\n",
      "        [-0.2053, -1.2150,  1.9744]], grad_fn=<AddBackward0>)\n",
      "progress: 254 loss= 0.22317886352539062\n",
      "tensor([[ 1.8906, -1.1144, -0.5464],\n",
      "        [-0.6225,  0.6203,  0.2736],\n",
      "        [-2.5166,  0.4704,  2.5994],\n",
      "        [ 1.8906, -1.1144, -0.5464],\n",
      "        [ 1.8906, -1.1144, -0.5464],\n",
      "        [-0.2057, -1.2148,  1.9749]], grad_fn=<AddBackward0>)\n",
      "progress: 255 loss= 0.22285981476306915\n",
      "tensor([[ 1.8919, -1.1156, -0.5466],\n",
      "        [-0.6230,  0.6203,  0.2739],\n",
      "        [-2.5185,  0.4702,  2.6015],\n",
      "        [ 1.8919, -1.1156, -0.5466],\n",
      "        [ 1.8919, -1.1156, -0.5466],\n",
      "        [-0.2064, -1.2158,  1.9766]], grad_fn=<AddBackward0>)\n",
      "progress: 256 loss= 0.22265183925628662\n",
      "tensor([[ 1.8926, -1.1153, -0.5475],\n",
      "        [-0.6235,  0.6221,  0.2729],\n",
      "        [-2.5211,  0.4726,  2.6023],\n",
      "        [ 1.8926, -1.1153, -0.5475],\n",
      "        [ 1.8926, -1.1153, -0.5475],\n",
      "        [-0.2068, -1.2156,  1.9771]], grad_fn=<AddBackward0>)\n",
      "progress: 257 loss= 0.2223726511001587\n",
      "tensor([[ 1.8940, -1.1165, -0.5479],\n",
      "        [-0.6242,  0.6223,  0.2732],\n",
      "        [-2.5230,  0.4724,  2.6044],\n",
      "        [ 1.8940, -1.1165, -0.5479],\n",
      "        [ 1.8940, -1.1165, -0.5479],\n",
      "        [-0.2076, -1.2166,  1.9788]], grad_fn=<AddBackward0>)\n",
      "progress: 258 loss= 0.22212648391723633\n",
      "tensor([[ 1.8945, -1.1163, -0.5486],\n",
      "        [-0.6246,  0.6238,  0.2722],\n",
      "        [-2.5256,  0.4748,  2.6052],\n",
      "        [ 1.8945, -1.1163, -0.5486],\n",
      "        [ 1.8945, -1.1163, -0.5486],\n",
      "        [-0.2080, -1.2164,  1.9793]], grad_fn=<AddBackward0>)\n",
      "progress: 259 loss= 0.22188706696033478\n",
      "tensor([[ 1.8961, -1.1175, -0.5491],\n",
      "        [-0.6254,  0.6243,  0.2725],\n",
      "        [-2.5274,  0.4746,  2.6073],\n",
      "        [ 1.8961, -1.1175, -0.5491],\n",
      "        [ 1.8961, -1.1175, -0.5491],\n",
      "        [-0.2088, -1.2174,  1.9811]], grad_fn=<AddBackward0>)\n",
      "progress: 260 loss= 0.22160391509532928\n",
      "tensor([[ 1.8957, -1.1170, -0.5492],\n",
      "        [-0.6273,  0.6259,  0.2727],\n",
      "        [-2.5318,  0.4773,  2.6092],\n",
      "        [ 1.8957, -1.1170, -0.5492],\n",
      "        [ 1.8957, -1.1170, -0.5492],\n",
      "        [-0.2109, -1.2169,  1.9827]], grad_fn=<AddBackward0>)\n",
      "progress: 261 loss= 0.2214018702507019\n",
      "tensor([[ 1.8980, -1.1184, -0.5502],\n",
      "        [-0.6266,  0.6262,  0.2717],\n",
      "        [-2.5319,  0.4767,  2.6101],\n",
      "        [ 1.8980, -1.1184, -0.5502],\n",
      "        [ 1.8980, -1.1184, -0.5502],\n",
      "        [-0.2100, -1.2182,  1.9833]], grad_fn=<AddBackward0>)\n",
      "progress: 262 loss= 0.22109998762607574\n",
      "tensor([[ 1.8979, -1.1180, -0.5505],\n",
      "        [-0.6283,  0.6277,  0.2719],\n",
      "        [-2.5363,  0.4794,  2.6121],\n",
      "        [ 1.8979, -1.1180, -0.5505],\n",
      "        [ 1.8979, -1.1180, -0.5505],\n",
      "        [-0.2121, -1.2177,  1.9850]], grad_fn=<AddBackward0>)\n",
      "progress: 263 loss= 0.2209010273218155\n",
      "tensor([[ 1.9000, -1.1193, -0.5513],\n",
      "        [-0.6278,  0.6282,  0.2710],\n",
      "        [-2.5364,  0.4789,  2.6130],\n",
      "        [ 1.9000, -1.1193, -0.5513],\n",
      "        [ 1.9000, -1.1193, -0.5513],\n",
      "        [-0.2112, -1.2190,  1.9855]], grad_fn=<AddBackward0>)\n",
      "progress: 264 loss= 0.22059737145900726\n",
      "tensor([[ 1.9000, -1.1189, -0.5517],\n",
      "        [-0.6294,  0.6295,  0.2712],\n",
      "        [-2.5407,  0.4816,  2.6149],\n",
      "        [ 1.9000, -1.1189, -0.5517],\n",
      "        [ 1.9000, -1.1189, -0.5517],\n",
      "        [-0.2132, -1.2185,  1.9872]], grad_fn=<AddBackward0>)\n",
      "progress: 265 loss= 0.22040188312530518\n",
      "tensor([[ 1.9019, -1.1202, -0.5524],\n",
      "        [-0.6290,  0.6302,  0.2703],\n",
      "        [-2.5409,  0.4810,  2.6159],\n",
      "        [ 1.9019, -1.1202, -0.5524],\n",
      "        [ 1.9019, -1.1202, -0.5524],\n",
      "        [-0.2124, -1.2198,  1.9878]], grad_fn=<AddBackward0>)\n",
      "progress: 266 loss= 0.22009623050689697\n",
      "tensor([[ 1.9021, -1.1199, -0.5529],\n",
      "        [-0.6304,  0.6312,  0.2705],\n",
      "        [-2.5452,  0.4838,  2.6178],\n",
      "        [ 1.9021, -1.1199, -0.5529],\n",
      "        [ 1.9021, -1.1199, -0.5529],\n",
      "        [-0.2144, -1.2193,  1.9894]], grad_fn=<AddBackward0>)\n",
      "progress: 267 loss= 0.2199043184518814\n",
      "tensor([[ 1.9038, -1.1211, -0.5535],\n",
      "        [-0.6301,  0.6320,  0.2696],\n",
      "        [-2.5453,  0.4832,  2.6187],\n",
      "        [ 1.9038, -1.1211, -0.5535],\n",
      "        [ 1.9038, -1.1211, -0.5535],\n",
      "        [-0.2136, -1.2206,  1.9900]], grad_fn=<AddBackward0>)\n",
      "progress: 268 loss= 0.2196149080991745\n",
      "tensor([[ 1.9054, -1.1223, -0.5540],\n",
      "        [-0.6304,  0.6318,  0.2699],\n",
      "        [-2.5471,  0.4829,  2.6208],\n",
      "        [ 1.9054, -1.1223, -0.5540],\n",
      "        [ 1.9054, -1.1223, -0.5540],\n",
      "        [-0.2143, -1.2216,  1.9917]], grad_fn=<AddBackward0>)\n",
      "progress: 269 loss= 0.21939872205257416\n",
      "tensor([[ 1.9051, -1.1219, -0.5542],\n",
      "        [-0.6328,  0.6341,  0.2700],\n",
      "        [-2.5515,  0.4857,  2.6228],\n",
      "        [ 1.9051, -1.1219, -0.5542],\n",
      "        [ 1.9051, -1.1219, -0.5542],\n",
      "        [-0.2164, -1.2210,  1.9934]], grad_fn=<AddBackward0>)\n",
      "progress: 270 loss= 0.2191295623779297\n",
      "tensor([[ 1.9073, -1.1232, -0.5551],\n",
      "        [-0.6316,  0.6338,  0.2691],\n",
      "        [-2.5516,  0.4851,  2.6237],\n",
      "        [ 1.9073, -1.1232, -0.5551],\n",
      "        [ 1.9073, -1.1232, -0.5551],\n",
      "        [-0.2155, -1.2224,  1.9939]], grad_fn=<AddBackward0>)\n",
      "progress: 271 loss= 0.21890102326869965\n",
      "tensor([[ 1.9072, -1.1228, -0.5554],\n",
      "        [-0.6338,  0.6358,  0.2693],\n",
      "        [-2.5559,  0.4878,  2.6256],\n",
      "        [ 1.9072, -1.1228, -0.5554],\n",
      "        [ 1.9072, -1.1228, -0.5554],\n",
      "        [-0.2176, -1.2218,  1.9956]], grad_fn=<AddBackward0>)\n",
      "progress: 272 loss= 0.2186361700296402\n",
      "tensor([[ 1.9092, -1.1241, -0.5562],\n",
      "        [-0.6328,  0.6358,  0.2684],\n",
      "        [-2.5560,  0.4873,  2.6265],\n",
      "        [ 1.9092, -1.1241, -0.5562],\n",
      "        [ 1.9092, -1.1241, -0.5562],\n",
      "        [-0.2167, -1.2231,  1.9962]], grad_fn=<AddBackward0>)\n",
      "progress: 273 loss= 0.21840466558933258\n",
      "tensor([[ 1.9093, -1.1237, -0.5567],\n",
      "        [-0.6348,  0.6376,  0.2686],\n",
      "        [-2.5604,  0.4900,  2.6285],\n",
      "        [ 1.9093, -1.1237, -0.5567],\n",
      "        [ 1.9093, -1.1237, -0.5567],\n",
      "        [-0.2187, -1.2226,  1.9978]], grad_fn=<AddBackward0>)\n",
      "progress: 274 loss= 0.2181444615125656\n",
      "tensor([[ 1.9111, -1.1250, -0.5573],\n",
      "        [-0.6340,  0.6377,  0.2677],\n",
      "        [-2.5605,  0.4894,  2.6294],\n",
      "        [ 1.9111, -1.1250, -0.5573],\n",
      "        [ 1.9111, -1.1250, -0.5573],\n",
      "        [-0.2179, -1.2239,  1.9984]], grad_fn=<AddBackward0>)\n",
      "progress: 275 loss= 0.2179098129272461\n",
      "tensor([[ 1.9114, -1.1247, -0.5579],\n",
      "        [-0.6359,  0.6394,  0.2679],\n",
      "        [-2.5648,  0.4921,  2.6313],\n",
      "        [ 1.9114, -1.1247, -0.5579],\n",
      "        [ 1.9114, -1.1247, -0.5579],\n",
      "        [-0.2199, -1.2234,  2.0000]], grad_fn=<AddBackward0>)\n",
      "progress: 276 loss= 0.2176542729139328\n",
      "tensor([[ 1.9130, -1.1259, -0.5584],\n",
      "        [-0.6353,  0.6397,  0.2670],\n",
      "        [-2.5649,  0.4916,  2.6322],\n",
      "        [ 1.9130, -1.1259, -0.5584],\n",
      "        [ 1.9130, -1.1259, -0.5584],\n",
      "        [-0.2190, -1.2247,  2.0006]], grad_fn=<AddBackward0>)\n",
      "progress: 277 loss= 0.21741628646850586\n",
      "tensor([[ 1.9134, -1.1256, -0.5590],\n",
      "        [-0.6369,  0.6411,  0.2672],\n",
      "        [-2.5693,  0.4943,  2.6342],\n",
      "        [ 1.9134, -1.1256, -0.5590],\n",
      "        [ 1.9134, -1.1256, -0.5590],\n",
      "        [-0.2211, -1.2242,  2.0022]], grad_fn=<AddBackward0>)\n",
      "progress: 278 loss= 0.21718186140060425\n",
      "tensor([[ 1.9144, -1.1267, -0.5591],\n",
      "        [-0.6381,  0.6420,  0.2674],\n",
      "        [-2.5710,  0.4940,  2.6362],\n",
      "        [ 1.9144, -1.1267, -0.5591],\n",
      "        [ 1.9144, -1.1267, -0.5591],\n",
      "        [-0.2218, -1.2252,  2.0040]], grad_fn=<AddBackward0>)\n",
      "progress: 279 loss= 0.21690815687179565\n",
      "tensor([[ 1.9153, -1.1265, -0.5601],\n",
      "        [-0.6380,  0.6429,  0.2664],\n",
      "        [-2.5737,  0.4964,  2.6370],\n",
      "        [ 1.9153, -1.1265, -0.5601],\n",
      "        [ 1.9153, -1.1265, -0.5601],\n",
      "        [-0.2222, -1.2250,  2.0045]], grad_fn=<AddBackward0>)\n",
      "progress: 280 loss= 0.21671247482299805\n",
      "tensor([[ 1.9165, -1.1276, -0.5604],\n",
      "        [-0.6393,  0.6440,  0.2667],\n",
      "        [-2.5754,  0.4962,  2.6391],\n",
      "        [ 1.9165, -1.1276, -0.5604],\n",
      "        [ 1.9165, -1.1276, -0.5604],\n",
      "        [-0.2230, -1.2260,  2.0062]], grad_fn=<AddBackward0>)\n",
      "progress: 281 loss= 0.21640360355377197\n",
      "tensor([[ 1.9184, -1.1288, -0.5611],\n",
      "        [-0.6378,  0.6433,  0.2658],\n",
      "        [-2.5756,  0.4956,  2.6400],\n",
      "        [ 1.9184, -1.1288, -0.5611],\n",
      "        [ 1.9184, -1.1288, -0.5611],\n",
      "        [-0.2221, -1.2273,  2.0067]], grad_fn=<AddBackward0>)\n",
      "progress: 282 loss= 0.2162410467863083\n",
      "tensor([[ 1.9186, -1.1285, -0.5616],\n",
      "        [-0.6403,  0.6457,  0.2659],\n",
      "        [-2.5799,  0.4983,  2.6419],\n",
      "        [ 1.9186, -1.1285, -0.5616],\n",
      "        [ 1.9186, -1.1285, -0.5616],\n",
      "        [-0.2241, -1.2268,  2.0084]], grad_fn=<AddBackward0>)\n",
      "progress: 283 loss= 0.21591906249523163\n",
      "tensor([[ 1.9203, -1.1297, -0.5622],\n",
      "        [-0.6391,  0.6453,  0.2651],\n",
      "        [-2.5800,  0.4977,  2.6429],\n",
      "        [ 1.9203, -1.1297, -0.5622],\n",
      "        [ 1.9203, -1.1297, -0.5622],\n",
      "        [-0.2233, -1.2281,  2.0090]], grad_fn=<AddBackward0>)\n",
      "progress: 284 loss= 0.21575234830379486\n",
      "tensor([[ 1.9206, -1.1294, -0.5628],\n",
      "        [-0.6413,  0.6475,  0.2652],\n",
      "        [-2.5843,  0.5005,  2.6448],\n",
      "        [ 1.9206, -1.1294, -0.5628],\n",
      "        [ 1.9206, -1.1294, -0.5628],\n",
      "        [-0.2253, -1.2276,  2.0106]], grad_fn=<AddBackward0>)\n",
      "progress: 285 loss= 0.21544241905212402\n",
      "tensor([[ 1.9215, -1.1305, -0.5628],\n",
      "        [-0.6419,  0.6476,  0.2655],\n",
      "        [-2.5861,  0.5002,  2.6468],\n",
      "        [ 1.9215, -1.1305, -0.5628],\n",
      "        [ 1.9215, -1.1305, -0.5628],\n",
      "        [-0.2261, -1.2286,  2.0123]], grad_fn=<AddBackward0>)\n",
      "progress: 286 loss= 0.21525858342647552\n",
      "tensor([[ 1.9225, -1.1303, -0.5639],\n",
      "        [-0.6424,  0.6493,  0.2645],\n",
      "        [-2.5887,  0.5026,  2.6476],\n",
      "        [ 1.9225, -1.1303, -0.5639],\n",
      "        [ 1.9225, -1.1303, -0.5639],\n",
      "        [-0.2265, -1.2284,  2.0128]], grad_fn=<AddBackward0>)\n",
      "progress: 287 loss= 0.21497851610183716\n",
      "tensor([[ 1.9236, -1.1314, -0.5641],\n",
      "        [-0.6431,  0.6496,  0.2648],\n",
      "        [-2.5905,  0.5024,  2.6497],\n",
      "        [ 1.9236, -1.1314, -0.5641],\n",
      "        [ 1.9236, -1.1314, -0.5641],\n",
      "        [-0.2272, -1.2293,  2.0145]], grad_fn=<AddBackward0>)\n",
      "progress: 288 loss= 0.2147551327943802\n",
      "tensor([[ 1.9244, -1.1312, -0.5649],\n",
      "        [-0.6434,  0.6510,  0.2638],\n",
      "        [-2.5931,  0.5048,  2.6504],\n",
      "        [ 1.9244, -1.1312, -0.5649],\n",
      "        [ 1.9244, -1.1312, -0.5649],\n",
      "        [-0.2276, -1.2292,  2.0150]], grad_fn=<AddBackward0>)\n",
      "progress: 289 loss= 0.21451608836650848\n",
      "tensor([[ 1.9257, -1.1323, -0.5653],\n",
      "        [-0.6443,  0.6516,  0.2640],\n",
      "        [-2.5949,  0.5045,  2.6525],\n",
      "        [ 1.9257, -1.1323, -0.5653],\n",
      "        [ 1.9257, -1.1323, -0.5653],\n",
      "        [-0.2284, -1.2301,  2.0167]], grad_fn=<AddBackward0>)\n",
      "progress: 290 loss= 0.214253231883049\n",
      "tensor([[ 1.9263, -1.1321, -0.5660],\n",
      "        [-0.6444,  0.6528,  0.2631],\n",
      "        [-2.5975,  0.5069,  2.6532],\n",
      "        [ 1.9263, -1.1321, -0.5660],\n",
      "        [ 1.9263, -1.1321, -0.5660],\n",
      "        [-0.2288, -1.2300,  2.0172]], grad_fn=<AddBackward0>)\n",
      "progress: 291 loss= 0.21405501663684845\n",
      "tensor([[ 1.9278, -1.1332, -0.5665],\n",
      "        [-0.6455,  0.6536,  0.2633],\n",
      "        [-2.5993,  0.5066,  2.6553],\n",
      "        [ 1.9278, -1.1332, -0.5665],\n",
      "        [ 1.9278, -1.1332, -0.5665],\n",
      "        [-0.2295, -1.2309,  2.0189]], grad_fn=<AddBackward0>)\n",
      "progress: 292 loss= 0.21375282108783722\n",
      "tensor([[ 1.9281, -1.1329, -0.5671],\n",
      "        [-0.6455,  0.6546,  0.2624],\n",
      "        [-2.6019,  0.5090,  2.6561],\n",
      "        [ 1.9281, -1.1329, -0.5671],\n",
      "        [ 1.9281, -1.1329, -0.5671],\n",
      "        [-0.2299, -1.2308,  2.0194]], grad_fn=<AddBackward0>)\n",
      "progress: 293 loss= 0.21359537541866302\n",
      "tensor([[ 1.9297, -1.1341, -0.5676],\n",
      "        [-0.6468,  0.6555,  0.2626],\n",
      "        [-2.6037,  0.5088,  2.6581],\n",
      "        [ 1.9297, -1.1341, -0.5676],\n",
      "        [ 1.9297, -1.1341, -0.5676],\n",
      "        [-0.2307, -1.2317,  2.0211]], grad_fn=<AddBackward0>)\n",
      "progress: 294 loss= 0.21327008306980133\n",
      "tensor([[ 1.9296, -1.1337, -0.5682],\n",
      "        [-0.6481,  0.6566,  0.2628],\n",
      "        [-2.6078,  0.5116,  2.6591],\n",
      "        [ 1.9296, -1.1337, -0.5682],\n",
      "        [ 1.9296, -1.1337, -0.5682],\n",
      "        [-0.2326, -1.2312,  2.0223]], grad_fn=<AddBackward0>)\n",
      "progress: 295 loss= 0.21313084661960602\n",
      "tensor([[ 1.9317, -1.1349, -0.5691],\n",
      "        [-0.6478,  0.6574,  0.2619],\n",
      "        [-2.6079,  0.5110,  2.6601],\n",
      "        [ 1.9317, -1.1349, -0.5691],\n",
      "        [ 1.9317, -1.1349, -0.5691],\n",
      "        [-0.2317, -1.2325,  2.0229]], grad_fn=<AddBackward0>)\n",
      "progress: 296 loss= 0.2128148227930069\n",
      "tensor([[ 1.9329, -1.1361, -0.5694],\n",
      "        [-0.6481,  0.6572,  0.2621],\n",
      "        [-2.6096,  0.5107,  2.6621],\n",
      "        [ 1.9329, -1.1361, -0.5694],\n",
      "        [ 1.9329, -1.1361, -0.5694],\n",
      "        [-0.2325, -1.2335,  2.0246]], grad_fn=<AddBackward0>)\n",
      "progress: 297 loss= 0.21263892948627472\n",
      "tensor([[ 1.9335, -1.1358, -0.5702],\n",
      "        [-0.6488,  0.6591,  0.2611],\n",
      "        [-2.6123,  0.5131,  2.6629],\n",
      "        [ 1.9335, -1.1358, -0.5702],\n",
      "        [ 1.9335, -1.1358, -0.5702],\n",
      "        [-0.2329, -1.2333,  2.0251]], grad_fn=<AddBackward0>)\n",
      "progress: 298 loss= 0.21235907077789307\n",
      "tensor([[ 1.9350, -1.1370, -0.5706],\n",
      "        [-0.6493,  0.6592,  0.2614],\n",
      "        [-2.6140,  0.5128,  2.6650],\n",
      "        [ 1.9350, -1.1370, -0.5706],\n",
      "        [ 1.9350, -1.1370, -0.5706],\n",
      "        [-0.2336, -1.2343,  2.0268]], grad_fn=<AddBackward0>)\n",
      "progress: 299 loss= 0.2121434360742569\n",
      "tensor([[ 1.9354, -1.1367, -0.5713],\n",
      "        [-0.6499,  0.6609,  0.2604],\n",
      "        [-2.6167,  0.5152,  2.6657],\n",
      "        [ 1.9354, -1.1367, -0.5713],\n",
      "        [ 1.9354, -1.1367, -0.5713],\n",
      "        [-0.2340, -1.2341,  2.0273]], grad_fn=<AddBackward0>)\n",
      "progress: 300 loss= 0.21190476417541504\n",
      "tensor([[ 1.9369, -1.1379, -0.5718],\n",
      "        [-0.6506,  0.6612,  0.2608],\n",
      "        [-2.6184,  0.5150,  2.6678],\n",
      "        [ 1.9369, -1.1379, -0.5718],\n",
      "        [ 1.9369, -1.1379, -0.5718],\n",
      "        [-0.2347, -1.2351,  2.0290]], grad_fn=<AddBackward0>)\n",
      "progress: 301 loss= 0.2116617113351822\n",
      "tensor([[ 1.9367, -1.1374, -0.5723],\n",
      "        [-0.6525,  0.6630,  0.2608],\n",
      "        [-2.6225,  0.5178,  2.6688],\n",
      "        [ 1.9367, -1.1374, -0.5723],\n",
      "        [ 1.9367, -1.1374, -0.5723],\n",
      "        [-0.2367, -1.2345,  2.0301]], grad_fn=<AddBackward0>)\n",
      "progress: 302 loss= 0.21145446598529816\n",
      "tensor([[ 1.9389, -1.1387, -0.5733],\n",
      "        [-0.6518,  0.6632,  0.2600],\n",
      "        [-2.6226,  0.5172,  2.6697],\n",
      "        [ 1.9389, -1.1387, -0.5733],\n",
      "        [ 1.9389, -1.1387, -0.5733],\n",
      "        [-0.2358, -1.2358,  2.0307]], grad_fn=<AddBackward0>)\n",
      "progress: 303 loss= 0.21118848025798798\n",
      "tensor([[ 1.9387, -1.1383, -0.5735],\n",
      "        [-0.6535,  0.6647,  0.2601],\n",
      "        [-2.6269,  0.5199,  2.6716],\n",
      "        [ 1.9387, -1.1383, -0.5735],\n",
      "        [ 1.9387, -1.1383, -0.5735],\n",
      "        [-0.2378, -1.2353,  2.0323]], grad_fn=<AddBackward0>)\n",
      "progress: 304 loss= 0.21098558604717255\n",
      "tensor([[ 1.9407, -1.1395, -0.5743],\n",
      "        [-0.6530,  0.6651,  0.2592],\n",
      "        [-2.6270,  0.5193,  2.6725],\n",
      "        [ 1.9407, -1.1395, -0.5743],\n",
      "        [ 1.9407, -1.1395, -0.5743],\n",
      "        [-0.2369, -1.2366,  2.0329]], grad_fn=<AddBackward0>)\n",
      "progress: 305 loss= 0.21071456372737885\n",
      "tensor([[ 1.9408, -1.1392, -0.5747],\n",
      "        [-0.6545,  0.6665,  0.2594],\n",
      "        [-2.6313,  0.5220,  2.6744],\n",
      "        [ 1.9408, -1.1392, -0.5747],\n",
      "        [ 1.9408, -1.1392, -0.5747],\n",
      "        [-0.2389, -1.2361,  2.0345]], grad_fn=<AddBackward0>)\n",
      "progress: 306 loss= 0.21051812171936035\n",
      "tensor([[ 1.9426, -1.1404, -0.5754],\n",
      "        [-0.6542,  0.6671,  0.2586],\n",
      "        [-2.6314,  0.5214,  2.6753],\n",
      "        [ 1.9426, -1.1404, -0.5754],\n",
      "        [ 1.9426, -1.1404, -0.5754],\n",
      "        [-0.2381, -1.2374,  2.0351]], grad_fn=<AddBackward0>)\n",
      "progress: 307 loss= 0.2102455049753189\n",
      "tensor([[ 1.9429, -1.1400, -0.5764],\n",
      "        [-0.6556,  0.6682,  0.2587],\n",
      "        [-2.6355,  0.5242,  2.6763],\n",
      "        [ 1.9429, -1.1400, -0.5764],\n",
      "        [ 1.9429, -1.1400, -0.5764],\n",
      "        [-0.2400, -1.2369,  2.0363]], grad_fn=<AddBackward0>)\n",
      "progress: 308 loss= 0.21006077527999878\n",
      "tensor([[ 1.9445, -1.1412, -0.5769],\n",
      "        [-0.6553,  0.6690,  0.2578],\n",
      "        [-2.6356,  0.5236,  2.6773],\n",
      "        [ 1.9445, -1.1412, -0.5769],\n",
      "        [ 1.9445, -1.1412, -0.5769],\n",
      "        [-0.2391, -1.2382,  2.0368]], grad_fn=<AddBackward0>)\n",
      "progress: 309 loss= 0.20979370176792145\n",
      "tensor([[ 1.9461, -1.1424, -0.5774],\n",
      "        [-0.6555,  0.6688,  0.2581],\n",
      "        [-2.6373,  0.5233,  2.6793],\n",
      "        [ 1.9461, -1.1424, -0.5774],\n",
      "        [ 1.9461, -1.1424, -0.5774],\n",
      "        [-0.2399, -1.2392,  2.0386]], grad_fn=<AddBackward0>)\n",
      "progress: 310 loss= 0.2095968872308731\n",
      "tensor([[ 1.9458, -1.1420, -0.5776],\n",
      "        [-0.6579,  0.6710,  0.2582],\n",
      "        [-2.6415,  0.5260,  2.6812],\n",
      "        [ 1.9458, -1.1420, -0.5776],\n",
      "        [ 1.9458, -1.1420, -0.5776],\n",
      "        [-0.2419, -1.2386,  2.0402]], grad_fn=<AddBackward0>)\n",
      "progress: 311 loss= 0.20933254063129425\n",
      "tensor([[ 1.9479, -1.1432, -0.5784],\n",
      "        [-0.6568,  0.6707,  0.2574],\n",
      "        [-2.6417,  0.5255,  2.6821],\n",
      "        [ 1.9479, -1.1432, -0.5784],\n",
      "        [ 1.9479, -1.1432, -0.5784],\n",
      "        [-0.2410, -1.2400,  2.0407]], grad_fn=<AddBackward0>)\n",
      "progress: 312 loss= 0.20912741124629974\n",
      "tensor([[ 1.9479, -1.1429, -0.5788],\n",
      "        [-0.6589,  0.6728,  0.2575],\n",
      "        [-2.6459,  0.5282,  2.6840],\n",
      "        [ 1.9479, -1.1429, -0.5788],\n",
      "        [ 1.9479, -1.1429, -0.5788],\n",
      "        [-0.2430, -1.2394,  2.0424]], grad_fn=<AddBackward0>)\n",
      "progress: 313 loss= 0.20887140929698944\n",
      "tensor([[ 1.9498, -1.1440, -0.5799],\n",
      "        [-0.6580,  0.6727,  0.2566],\n",
      "        [-2.6458,  0.5277,  2.6841],\n",
      "        [ 1.9498, -1.1440, -0.5799],\n",
      "        [ 1.9498, -1.1440, -0.5799],\n",
      "        [-0.2420, -1.2407,  2.0425]], grad_fn=<AddBackward0>)\n",
      "progress: 314 loss= 0.2086680680513382\n",
      "tensor([[ 1.9500, -1.1437, -0.5804],\n",
      "        [-0.6600,  0.6745,  0.2568],\n",
      "        [-2.6501,  0.5304,  2.6859],\n",
      "        [ 1.9500, -1.1437, -0.5804],\n",
      "        [ 1.9500, -1.1437, -0.5804],\n",
      "        [-0.2440, -1.2402,  2.0441]], grad_fn=<AddBackward0>)\n",
      "progress: 315 loss= 0.20841865241527557\n",
      "tensor([[ 1.9517, -1.1449, -0.5810],\n",
      "        [-0.6592,  0.6747,  0.2559],\n",
      "        [-2.6502,  0.5298,  2.6869],\n",
      "        [ 1.9517, -1.1449, -0.5810],\n",
      "        [ 1.9517, -1.1449, -0.5810],\n",
      "        [-0.2432, -1.2415,  2.0447]], grad_fn=<AddBackward0>)\n",
      "progress: 316 loss= 0.2082013338804245\n",
      "tensor([[ 1.9519, -1.1446, -0.5815],\n",
      "        [-0.6610,  0.6763,  0.2561],\n",
      "        [-2.6544,  0.5325,  2.6888],\n",
      "        [ 1.9519, -1.1446, -0.5815],\n",
      "        [ 1.9519, -1.1446, -0.5815],\n",
      "        [-0.2452, -1.2410,  2.0463]], grad_fn=<AddBackward0>)\n",
      "progress: 317 loss= 0.2079659104347229\n",
      "tensor([[ 1.9529, -1.1456, -0.5816],\n",
      "        [-0.6620,  0.6770,  0.2563],\n",
      "        [-2.6561,  0.5322,  2.6908],\n",
      "        [ 1.9529, -1.1456, -0.5816],\n",
      "        [ 1.9529, -1.1456, -0.5816],\n",
      "        [-0.2459, -1.2420,  2.0480]], grad_fn=<AddBackward0>)\n",
      "progress: 318 loss= 0.20772947371006012\n",
      "tensor([[ 1.9538, -1.1454, -0.5826],\n",
      "        [-0.6620,  0.6780,  0.2554],\n",
      "        [-2.6588,  0.5345,  2.6916],\n",
      "        [ 1.9538, -1.1454, -0.5826],\n",
      "        [ 1.9538, -1.1454, -0.5826],\n",
      "        [-0.2463, -1.2418,  2.0485]], grad_fn=<AddBackward0>)\n",
      "progress: 319 loss= 0.20752489566802979\n",
      "tensor([[ 1.9549, -1.1465, -0.5828],\n",
      "        [-0.6633,  0.6790,  0.2557],\n",
      "        [-2.6605,  0.5343,  2.6936],\n",
      "        [ 1.9549, -1.1465, -0.5828],\n",
      "        [ 1.9549, -1.1465, -0.5828],\n",
      "        [-0.2470, -1.2428,  2.0502]], grad_fn=<AddBackward0>)\n",
      "progress: 320 loss= 0.20725619792938232\n",
      "tensor([[ 1.9557, -1.1462, -0.5841],\n",
      "        [-0.6630,  0.6798,  0.2547],\n",
      "        [-2.6629,  0.5367,  2.6935],\n",
      "        [ 1.9557, -1.1462, -0.5841],\n",
      "        [ 1.9557, -1.1462, -0.5841],\n",
      "        [-0.2473, -1.2426,  2.0502]], grad_fn=<AddBackward0>)\n",
      "progress: 321 loss= 0.20709402859210968\n",
      "tensor([[ 1.9570, -1.1473, -0.5844],\n",
      "        [-0.6643,  0.6808,  0.2549],\n",
      "        [-2.6646,  0.5364,  2.6955],\n",
      "        [ 1.9570, -1.1473, -0.5844],\n",
      "        [ 1.9570, -1.1473, -0.5844],\n",
      "        [-0.2480, -1.2436,  2.0519]], grad_fn=<AddBackward0>)\n",
      "progress: 322 loss= 0.20679396390914917\n",
      "tensor([[ 1.9588, -1.1486, -0.5850],\n",
      "        [-0.6630,  0.6803,  0.2540],\n",
      "        [-2.6647,  0.5358,  2.6965],\n",
      "        [ 1.9588, -1.1486, -0.5850],\n",
      "        [ 1.9588, -1.1486, -0.5850],\n",
      "        [-0.2472, -1.2449,  2.0525]], grad_fn=<AddBackward0>)\n",
      "progress: 323 loss= 0.20664004981517792\n",
      "tensor([[ 1.9590, -1.1482, -0.5856],\n",
      "        [-0.6654,  0.6826,  0.2542],\n",
      "        [-2.6690,  0.5385,  2.6983],\n",
      "        [ 1.9590, -1.1482, -0.5856],\n",
      "        [ 1.9590, -1.1482, -0.5856],\n",
      "        [-0.2492, -1.2444,  2.0541]], grad_fn=<AddBackward0>)\n",
      "progress: 324 loss= 0.20634013414382935\n",
      "tensor([[ 1.9606, -1.1494, -0.5861],\n",
      "        [-0.6642,  0.6823,  0.2533],\n",
      "        [-2.6691,  0.5379,  2.6993],\n",
      "        [ 1.9606, -1.1494, -0.5861],\n",
      "        [ 1.9606, -1.1494, -0.5861],\n",
      "        [-0.2483, -1.2457,  2.0547]], grad_fn=<AddBackward0>)\n",
      "progress: 325 loss= 0.20617902278900146\n",
      "tensor([[ 1.9608, -1.1491, -0.5866],\n",
      "        [-0.6664,  0.6843,  0.2536],\n",
      "        [-2.6733,  0.5406,  2.7012],\n",
      "        [ 1.9608, -1.1491, -0.5866],\n",
      "        [ 1.9608, -1.1491, -0.5866],\n",
      "        [-0.2503, -1.2452,  2.0563]], grad_fn=<AddBackward0>)\n",
      "progress: 326 loss= 0.20590822398662567\n",
      "tensor([[ 1.9619, -1.1501, -0.5872],\n",
      "        [-0.6670,  0.6846,  0.2537],\n",
      "        [-2.6748,  0.5404,  2.7023],\n",
      "        [ 1.9619, -1.1501, -0.5872],\n",
      "        [ 1.9619, -1.1501, -0.5872],\n",
      "        [-0.2509, -1.2461,  2.0576]], grad_fn=<AddBackward0>)\n",
      "progress: 327 loss= 0.20571325719356537\n",
      "tensor([[ 1.9627, -1.1499, -0.5881],\n",
      "        [-0.6674,  0.6861,  0.2528],\n",
      "        [-2.6775,  0.5428,  2.7031],\n",
      "        [ 1.9627, -1.1499, -0.5881],\n",
      "        [ 1.9627, -1.1499, -0.5881],\n",
      "        [-0.2513, -1.2459,  2.0581]], grad_fn=<AddBackward0>)\n",
      "progress: 328 loss= 0.20547665655612946\n",
      "tensor([[ 1.9639, -1.1510, -0.5884],\n",
      "        [-0.6683,  0.6866,  0.2530],\n",
      "        [-2.6791,  0.5425,  2.7051],\n",
      "        [ 1.9639, -1.1510, -0.5884],\n",
      "        [ 1.9639, -1.1510, -0.5884],\n",
      "        [-0.2521, -1.2469,  2.0598]], grad_fn=<AddBackward0>)\n",
      "progress: 329 loss= 0.20523862540721893\n",
      "tensor([[ 1.9645, -1.1507, -0.5892],\n",
      "        [-0.6684,  0.6878,  0.2521],\n",
      "        [-2.6818,  0.5449,  2.7059],\n",
      "        [ 1.9645, -1.1507, -0.5892],\n",
      "        [ 1.9645, -1.1507, -0.5892],\n",
      "        [-0.2525, -1.2467,  2.0603]], grad_fn=<AddBackward0>)\n",
      "progress: 330 loss= 0.20504318177700043\n",
      "tensor([[ 1.9660, -1.1518, -0.5896],\n",
      "        [-0.6695,  0.6886,  0.2523],\n",
      "        [-2.6835,  0.5446,  2.7079],\n",
      "        [ 1.9660, -1.1518, -0.5896],\n",
      "        [ 1.9660, -1.1518, -0.5896],\n",
      "        [-0.2532, -1.2477,  2.0620]], grad_fn=<AddBackward0>)\n",
      "progress: 331 loss= 0.20476539433002472\n",
      "tensor([[ 1.9663, -1.1515, -0.5902],\n",
      "        [-0.6695,  0.6896,  0.2515],\n",
      "        [-2.6861,  0.5470,  2.7087],\n",
      "        [ 1.9663, -1.1515, -0.5902],\n",
      "        [ 1.9663, -1.1515, -0.5902],\n",
      "        [-0.2536, -1.2475,  2.0625]], grad_fn=<AddBackward0>)\n",
      "progress: 332 loss= 0.2046152800321579\n",
      "tensor([[ 1.9680, -1.1526, -0.5911],\n",
      "        [-0.6707,  0.6906,  0.2516],\n",
      "        [-2.6876,  0.5468,  2.7098],\n",
      "        [ 1.9680, -1.1526, -0.5911],\n",
      "        [ 1.9680, -1.1526, -0.5911],\n",
      "        [-0.2542, -1.2485,  2.0637]], grad_fn=<AddBackward0>)\n",
      "progress: 333 loss= 0.2043093591928482\n",
      "tensor([[ 1.9676, -1.1522, -0.5912],\n",
      "        [-0.6720,  0.6916,  0.2518],\n",
      "        [-2.6918,  0.5495,  2.7117],\n",
      "        [ 1.9676, -1.1522, -0.5912],\n",
      "        [ 1.9676, -1.1522, -0.5912],\n",
      "        [-0.2562, -1.2480,  2.0653]], grad_fn=<AddBackward0>)\n",
      "progress: 334 loss= 0.2041822224855423\n",
      "tensor([[ 1.9698, -1.1535, -0.5921],\n",
      "        [-0.6718,  0.6923,  0.2509],\n",
      "        [-2.6919,  0.5488,  2.7126],\n",
      "        [ 1.9698, -1.1535, -0.5921],\n",
      "        [ 1.9698, -1.1535, -0.5921],\n",
      "        [-0.2553, -1.2493,  2.0659]], grad_fn=<AddBackward0>)\n",
      "progress: 335 loss= 0.20387662947177887\n",
      "tensor([[ 1.9709, -1.1545, -0.5923],\n",
      "        [-0.6721,  0.6922,  0.2511],\n",
      "        [-2.6936,  0.5485,  2.7147],\n",
      "        [ 1.9709, -1.1545, -0.5923],\n",
      "        [ 1.9709, -1.1545, -0.5923],\n",
      "        [-0.2560, -1.2503,  2.0676]], grad_fn=<AddBackward0>)\n",
      "progress: 336 loss= 0.20371492207050323\n",
      "tensor([[ 1.9715, -1.1543, -0.5932],\n",
      "        [-0.6728,  0.6941,  0.2502],\n",
      "        [-2.6962,  0.5509,  2.7154],\n",
      "        [ 1.9715, -1.1543, -0.5932],\n",
      "        [ 1.9715, -1.1543, -0.5932],\n",
      "        [-0.2564, -1.2501,  2.0681]], grad_fn=<AddBackward0>)\n",
      "progress: 337 loss= 0.20344801247119904\n",
      "tensor([[ 1.9729, -1.1554, -0.5935],\n",
      "        [-0.6733,  0.6942,  0.2505],\n",
      "        [-2.6979,  0.5506,  2.7175],\n",
      "        [ 1.9729, -1.1554, -0.5935],\n",
      "        [ 1.9729, -1.1554, -0.5935],\n",
      "        [-0.2571, -1.2511,  2.0698]], grad_fn=<AddBackward0>)\n",
      "progress: 338 loss= 0.2032494693994522\n",
      "tensor([[ 1.9734, -1.1551, -0.5946],\n",
      "        [-0.6738,  0.6958,  0.2495],\n",
      "        [-2.7003,  0.5531,  2.7173],\n",
      "        [ 1.9734, -1.1551, -0.5946],\n",
      "        [ 1.9734, -1.1551, -0.5946],\n",
      "        [-0.2575, -1.2509,  2.0698]], grad_fn=<AddBackward0>)\n",
      "progress: 339 loss= 0.20302973687648773\n",
      "tensor([[ 1.9749, -1.1562, -0.5951],\n",
      "        [-0.6745,  0.6962,  0.2497],\n",
      "        [-2.7020,  0.5528,  2.7194],\n",
      "        [ 1.9749, -1.1562, -0.5951],\n",
      "        [ 1.9749, -1.1562, -0.5951],\n",
      "        [-0.2582, -1.2519,  2.0715]], grad_fn=<AddBackward0>)\n",
      "progress: 340 loss= 0.20278798043727875\n",
      "tensor([[ 1.9752, -1.1559, -0.5957],\n",
      "        [-0.6748,  0.6976,  0.2488],\n",
      "        [-2.7046,  0.5552,  2.7201],\n",
      "        [ 1.9752, -1.1559, -0.5957],\n",
      "        [ 1.9752, -1.1559, -0.5957],\n",
      "        [-0.2586, -1.2517,  2.0720]], grad_fn=<AddBackward0>)\n",
      "progress: 341 loss= 0.2026035636663437\n",
      "tensor([[ 1.9767, -1.1571, -0.5961],\n",
      "        [-0.6758,  0.6982,  0.2490],\n",
      "        [-2.7063,  0.5548,  2.7222],\n",
      "        [ 1.9767, -1.1571, -0.5961],\n",
      "        [ 1.9767, -1.1571, -0.5961],\n",
      "        [-0.2593, -1.2527,  2.0737]], grad_fn=<AddBackward0>)\n",
      "progress: 342 loss= 0.20233719050884247\n",
      "tensor([[ 1.9765, -1.1566, -0.5963],\n",
      "        [-0.6774,  0.6996,  0.2492],\n",
      "        [-2.7105,  0.5575,  2.7240],\n",
      "        [ 1.9765, -1.1566, -0.5963],\n",
      "        [ 1.9765, -1.1566, -0.5963],\n",
      "        [-0.2613, -1.2522,  2.0753]], grad_fn=<AddBackward0>)\n",
      "progress: 343 loss= 0.20216374099254608\n",
      "tensor([[ 1.9785, -1.1579, -0.5971],\n",
      "        [-0.6770,  0.7002,  0.2484],\n",
      "        [-2.7106,  0.5569,  2.7250],\n",
      "        [ 1.9785, -1.1579, -0.5971],\n",
      "        [ 1.9785, -1.1579, -0.5971],\n",
      "        [-0.2604, -1.2535,  2.0759]], grad_fn=<AddBackward0>)\n",
      "progress: 344 loss= 0.20189130306243896\n",
      "tensor([[ 1.9785, -1.1574, -0.5979],\n",
      "        [-0.6784,  0.7014,  0.2485],\n",
      "        [-2.7146,  0.5597,  2.7259],\n",
      "        [ 1.9785, -1.1574, -0.5979],\n",
      "        [ 1.9785, -1.1574, -0.5979],\n",
      "        [-0.2623, -1.2529,  2.0770]], grad_fn=<AddBackward0>)\n",
      "progress: 345 loss= 0.20173312723636627\n",
      "tensor([[ 1.9804, -1.1586, -0.5986],\n",
      "        [-0.6781,  0.7021,  0.2476],\n",
      "        [-2.7147,  0.5591,  2.7269],\n",
      "        [ 1.9804, -1.1586, -0.5986],\n",
      "        [ 1.9804, -1.1586, -0.5986],\n",
      "        [-0.2614, -1.2543,  2.0776]], grad_fn=<AddBackward0>)\n",
      "progress: 346 loss= 0.20145688951015472\n",
      "tensor([[ 1.9818, -1.1598, -0.5990],\n",
      "        [-0.6783,  0.7018,  0.2479],\n",
      "        [-2.7164,  0.5588,  2.7289],\n",
      "        [ 1.9818, -1.1598, -0.5990],\n",
      "        [ 1.9818, -1.1598, -0.5990],\n",
      "        [-0.2621, -1.2552,  2.0793]], grad_fn=<AddBackward0>)\n",
      "progress: 347 loss= 0.2012886255979538\n",
      "tensor([[ 1.9821, -1.1595, -0.5996],\n",
      "        [-0.6792,  0.7038,  0.2469],\n",
      "        [-2.7190,  0.5611,  2.7297],\n",
      "        [ 1.9821, -1.1595, -0.5996],\n",
      "        [ 1.9821, -1.1595, -0.5996],\n",
      "        [-0.2625, -1.2551,  2.0798]], grad_fn=<AddBackward0>)\n",
      "progress: 348 loss= 0.2010354995727539\n",
      "tensor([[ 1.9837, -1.1606, -0.6001],\n",
      "        [-0.6796,  0.7038,  0.2472],\n",
      "        [-2.7207,  0.5608,  2.7317],\n",
      "        [ 1.9837, -1.1606, -0.6001],\n",
      "        [ 1.9837, -1.1606, -0.6001],\n",
      "        [-0.2632, -1.2561,  2.0815]], grad_fn=<AddBackward0>)\n",
      "progress: 349 loss= 0.20083479583263397\n",
      "tensor([[ 1.9833, -1.1602, -0.6002],\n",
      "        [-0.6818,  0.7059,  0.2474],\n",
      "        [-2.7248,  0.5635,  2.7336],\n",
      "        [ 1.9833, -1.1602, -0.6002],\n",
      "        [ 1.9833, -1.1602, -0.6002],\n",
      "        [-0.2652, -1.2556,  2.0831]], grad_fn=<AddBackward0>)\n",
      "progress: 350 loss= 0.2006102204322815\n",
      "tensor([[ 1.9855, -1.1614, -0.6015],\n",
      "        [-0.6808,  0.7058,  0.2465],\n",
      "        [-2.7247,  0.5630,  2.7336],\n",
      "        [ 1.9855, -1.1614, -0.6015],\n",
      "        [ 1.9855, -1.1614, -0.6015],\n",
      "        [-0.2642, -1.2568,  2.0832]], grad_fn=<AddBackward0>)\n",
      "progress: 351 loss= 0.20039959251880646\n",
      "tensor([[ 1.9854, -1.1610, -0.6018],\n",
      "        [-0.6828,  0.7076,  0.2466],\n",
      "        [-2.7289,  0.5656,  2.7354],\n",
      "        [ 1.9854, -1.1610, -0.6018],\n",
      "        [ 1.9854, -1.1610, -0.6018],\n",
      "        [-0.2662, -1.2563,  2.0848]], grad_fn=<AddBackward0>)\n",
      "progress: 352 loss= 0.20018213987350464\n",
      "tensor([[ 1.9873, -1.1622, -0.6026],\n",
      "        [-0.6820,  0.7078,  0.2458],\n",
      "        [-2.7290,  0.5650,  2.7364],\n",
      "        [ 1.9873, -1.1622, -0.6026],\n",
      "        [ 1.9873, -1.1622, -0.6026],\n",
      "        [-0.2653, -1.2576,  2.0854]], grad_fn=<AddBackward0>)\n",
      "progress: 353 loss= 0.19995658099651337\n",
      "tensor([[ 1.9873, -1.1618, -0.6030],\n",
      "        [-0.6838,  0.7093,  0.2459],\n",
      "        [-2.7332,  0.5677,  2.7382],\n",
      "        [ 1.9873, -1.1618, -0.6030],\n",
      "        [ 1.9873, -1.1618, -0.6030],\n",
      "        [-0.2673, -1.2571,  2.0870]], grad_fn=<AddBackward0>)\n",
      "progress: 354 loss= 0.19974885880947113\n",
      "tensor([[ 1.9890, -1.1630, -0.6036],\n",
      "        [-0.6832,  0.7097,  0.2451],\n",
      "        [-2.7333,  0.5671,  2.7392],\n",
      "        [ 1.9890, -1.1630, -0.6036],\n",
      "        [ 1.9890, -1.1630, -0.6036],\n",
      "        [-0.2664, -1.2585,  2.0876]], grad_fn=<AddBackward0>)\n",
      "progress: 355 loss= 0.19951479136943817\n",
      "tensor([[ 1.9893, -1.1627, -0.6041],\n",
      "        [-0.6848,  0.7111,  0.2453],\n",
      "        [-2.7375,  0.5697,  2.7410],\n",
      "        [ 1.9893, -1.1627, -0.6041],\n",
      "        [ 1.9893, -1.1627, -0.6041],\n",
      "        [-0.2684, -1.2580,  2.0892]], grad_fn=<AddBackward0>)\n",
      "progress: 356 loss= 0.1993199735879898\n",
      "tensor([[ 1.9902, -1.1636, -0.6045],\n",
      "        [-0.6860,  0.7120,  0.2454],\n",
      "        [-2.7389,  0.5695,  2.7421],\n",
      "        [ 1.9902, -1.1636, -0.6045],\n",
      "        [ 1.9902, -1.1636, -0.6045],\n",
      "        [-0.2690, -1.2589,  2.0904]], grad_fn=<AddBackward0>)\n",
      "progress: 357 loss= 0.19908268749713898\n",
      "tensor([[ 1.9911, -1.1634, -0.6056],\n",
      "        [-0.6858,  0.7128,  0.2445],\n",
      "        [-2.7415,  0.5719,  2.7429],\n",
      "        [ 1.9911, -1.1634, -0.6056],\n",
      "        [ 1.9911, -1.1634, -0.6056],\n",
      "        [-0.2694, -1.2587,  2.0910]], grad_fn=<AddBackward0>)\n",
      "progress: 358 loss= 0.19891154766082764\n",
      "tensor([[ 1.9922, -1.1645, -0.6057],\n",
      "        [-0.6871,  0.7138,  0.2447],\n",
      "        [-2.7432,  0.5715,  2.7449],\n",
      "        [ 1.9922, -1.1645, -0.6057],\n",
      "        [ 1.9922, -1.1645, -0.6057],\n",
      "        [-0.2701, -1.2597,  2.0926]], grad_fn=<AddBackward0>)\n",
      "progress: 359 loss= 0.19864727556705475\n",
      "tensor([[ 1.9941, -1.1657, -0.6065],\n",
      "        [-0.6858,  0.7134,  0.2439],\n",
      "        [-2.7432,  0.5709,  2.7459],\n",
      "        [ 1.9941, -1.1657, -0.6065],\n",
      "        [ 1.9941, -1.1657, -0.6065],\n",
      "        [-0.2692, -1.2610,  2.0932]], grad_fn=<AddBackward0>)\n",
      "progress: 360 loss= 0.1984783262014389\n",
      "tensor([[ 1.9941, -1.1653, -0.6068],\n",
      "        [-0.6881,  0.7156,  0.2440],\n",
      "        [-2.7474,  0.5736,  2.7477],\n",
      "        [ 1.9941, -1.1653, -0.6068],\n",
      "        [ 1.9941, -1.1653, -0.6068],\n",
      "        [-0.2712, -1.2606,  2.0948]], grad_fn=<AddBackward0>)\n",
      "progress: 361 loss= 0.1982186883687973\n",
      "tensor([[ 1.9959, -1.1665, -0.6075],\n",
      "        [-0.6871,  0.7153,  0.2433],\n",
      "        [-2.7475,  0.5730,  2.7487],\n",
      "        [ 1.9959, -1.1665, -0.6075],\n",
      "        [ 1.9959, -1.1665, -0.6075],\n",
      "        [-0.2703, -1.2619,  2.0954]], grad_fn=<AddBackward0>)\n",
      "progress: 362 loss= 0.19804354012012482\n",
      "tensor([[ 1.9961, -1.1661, -0.6084],\n",
      "        [-0.6891,  0.7173,  0.2434],\n",
      "        [-2.7515,  0.5757,  2.7496],\n",
      "        [ 1.9961, -1.1661, -0.6084],\n",
      "        [ 1.9961, -1.1661, -0.6084],\n",
      "        [-0.2722, -1.2613,  2.0965]], grad_fn=<AddBackward0>)\n",
      "progress: 363 loss= 0.19780071079730988\n",
      "tensor([[ 1.9977, -1.1673, -0.6089],\n",
      "        [-0.6883,  0.7173,  0.2425],\n",
      "        [-2.7516,  0.5751,  2.7505],\n",
      "        [ 1.9977, -1.1673, -0.6089],\n",
      "        [ 1.9977, -1.1673, -0.6089],\n",
      "        [-0.2713, -1.2626,  2.0971]], grad_fn=<AddBackward0>)\n",
      "progress: 364 loss= 0.1976134181022644\n",
      "tensor([[ 1.9979, -1.1669, -0.6094],\n",
      "        [-0.6901,  0.7190,  0.2427],\n",
      "        [-2.7557,  0.5778,  2.7524],\n",
      "        [ 1.9979, -1.1669, -0.6094],\n",
      "        [ 1.9979, -1.1669, -0.6094],\n",
      "        [-0.2733, -1.2621,  2.0987]], grad_fn=<AddBackward0>)\n",
      "progress: 365 loss= 0.19738423824310303\n",
      "tensor([[ 1.9989, -1.1680, -0.6095],\n",
      "        [-0.6911,  0.7196,  0.2429],\n",
      "        [-2.7574,  0.5774,  2.7544],\n",
      "        [ 1.9989, -1.1680, -0.6095],\n",
      "        [ 1.9989, -1.1680, -0.6095],\n",
      "        [-0.2740, -1.2631,  2.1004]], grad_fn=<AddBackward0>)\n",
      "progress: 366 loss= 0.19716882705688477\n",
      "tensor([[ 1.9997, -1.1677, -0.6104],\n",
      "        [-0.6911,  0.7207,  0.2420],\n",
      "        [-2.7600,  0.5798,  2.7552],\n",
      "        [ 1.9997, -1.1677, -0.6104],\n",
      "        [ 1.9997, -1.1677, -0.6104],\n",
      "        [-0.2744, -1.2630,  2.1009]], grad_fn=<AddBackward0>)\n",
      "progress: 367 loss= 0.1969749480485916\n",
      "tensor([[ 2.0008, -1.1688, -0.6106],\n",
      "        [-0.6923,  0.7216,  0.2422],\n",
      "        [-2.7616,  0.5795,  2.7572],\n",
      "        [ 2.0008, -1.1688, -0.6106],\n",
      "        [ 2.0008, -1.1688, -0.6106],\n",
      "        [-0.2751, -1.2640,  2.1026]], grad_fn=<AddBackward0>)\n",
      "progress: 368 loss= 0.19672316312789917\n",
      "tensor([[ 2.0015, -1.1685, -0.6119],\n",
      "        [-0.6921,  0.7225,  0.2413],\n",
      "        [-2.7640,  0.5819,  2.7570],\n",
      "        [ 2.0015, -1.1685, -0.6119],\n",
      "        [ 2.0015, -1.1685, -0.6119],\n",
      "        [-0.2754, -1.2637,  2.1026]], grad_fn=<AddBackward0>)\n",
      "progress: 369 loss= 0.1965760439634323\n",
      "tensor([[ 2.0029, -1.1696, -0.6122],\n",
      "        [-0.6934,  0.7235,  0.2415],\n",
      "        [-2.7656,  0.5816,  2.7591],\n",
      "        [ 2.0029, -1.1696, -0.6122],\n",
      "        [ 2.0029, -1.1696, -0.6122],\n",
      "        [-0.2761, -1.2647,  2.1043]], grad_fn=<AddBackward0>)\n",
      "progress: 370 loss= 0.19629161059856415\n",
      "tensor([[ 2.0045, -1.1708, -0.6128],\n",
      "        [-0.6921,  0.7229,  0.2407],\n",
      "        [-2.7657,  0.5809,  2.7600],\n",
      "        [ 2.0045, -1.1708, -0.6128],\n",
      "        [ 2.0045, -1.1708, -0.6128],\n",
      "        [-0.2752, -1.2661,  2.1049]], grad_fn=<AddBackward0>)\n",
      "progress: 371 loss= 0.19615845382213593\n",
      "tensor([[ 2.0047, -1.1704, -0.6133],\n",
      "        [-0.6944,  0.7252,  0.2408],\n",
      "        [-2.7699,  0.5836,  2.7618],\n",
      "        [ 2.0047, -1.1704, -0.6133],\n",
      "        [ 2.0047, -1.1704, -0.6133],\n",
      "        [-0.2771, -1.2656,  2.1065]], grad_fn=<AddBackward0>)\n",
      "progress: 372 loss= 0.19587315618991852\n",
      "tensor([[ 2.0056, -1.1714, -0.6133],\n",
      "        [-0.6949,  0.7252,  0.2410],\n",
      "        [-2.7715,  0.5833,  2.7639],\n",
      "        [ 2.0056, -1.1714, -0.6133],\n",
      "        [ 2.0056, -1.1714, -0.6133],\n",
      "        [-0.2778, -1.2666,  2.1082]], grad_fn=<AddBackward0>)\n",
      "progress: 373 loss= 0.1957244724035263\n",
      "tensor([[ 2.0065, -1.1712, -0.6143],\n",
      "        [-0.6954,  0.7269,  0.2402],\n",
      "        [-2.7741,  0.5856,  2.7646],\n",
      "        [ 2.0065, -1.1712, -0.6143],\n",
      "        [ 2.0065, -1.1712, -0.6143],\n",
      "        [-0.2782, -1.2664,  2.1087]], grad_fn=<AddBackward0>)\n",
      "progress: 374 loss= 0.1954730749130249\n",
      "tensor([[ 2.0076, -1.1722, -0.6149],\n",
      "        [-0.6961,  0.7272,  0.2403],\n",
      "        [-2.7755,  0.5854,  2.7657],\n",
      "        [ 2.0076, -1.1722, -0.6149],\n",
      "        [ 2.0076, -1.1722, -0.6149],\n",
      "        [-0.2788, -1.2673,  2.1099]], grad_fn=<AddBackward0>)\n",
      "progress: 375 loss= 0.1952887624502182\n",
      "tensor([[ 2.0083, -1.1719, -0.6157],\n",
      "        [-0.6964,  0.7287,  0.2394],\n",
      "        [-2.7781,  0.5877,  2.7665],\n",
      "        [ 2.0083, -1.1719, -0.6157],\n",
      "        [ 2.0083, -1.1719, -0.6157],\n",
      "        [-0.2792, -1.2672,  2.1104]], grad_fn=<AddBackward0>)\n",
      "progress: 376 loss= 0.19507403671741486\n",
      "tensor([[ 2.0095, -1.1730, -0.6160],\n",
      "        [-0.6973,  0.7292,  0.2396],\n",
      "        [-2.7797,  0.5874,  2.7685],\n",
      "        [ 2.0095, -1.1730, -0.6160],\n",
      "        [ 2.0095, -1.1730, -0.6160],\n",
      "        [-0.2799, -1.2682,  2.1121]], grad_fn=<AddBackward0>)\n",
      "progress: 377 loss= 0.1948450803756714\n",
      "tensor([[ 2.0100, -1.1727, -0.6167],\n",
      "        [-0.6975,  0.7304,  0.2387],\n",
      "        [-2.7823,  0.5897,  2.7693],\n",
      "        [ 2.0100, -1.1727, -0.6167],\n",
      "        [ 2.0100, -1.1727, -0.6167],\n",
      "        [-0.2803, -1.2680,  2.1126]], grad_fn=<AddBackward0>)\n",
      "progress: 378 loss= 0.19467149674892426\n",
      "tensor([[ 2.0114, -1.1739, -0.6171],\n",
      "        [-0.6985,  0.7312,  0.2389],\n",
      "        [-2.7839,  0.5894,  2.7713],\n",
      "        [ 2.0114, -1.1739, -0.6171],\n",
      "        [ 2.0114, -1.1739, -0.6171],\n",
      "        [-0.2810, -1.2690,  2.1143]], grad_fn=<AddBackward0>)\n",
      "progress: 379 loss= 0.19440267980098724\n",
      "tensor([[ 2.0117, -1.1735, -0.6177],\n",
      "        [-0.6985,  0.7321,  0.2382],\n",
      "        [-2.7865,  0.5917,  2.7721],\n",
      "        [ 2.0117, -1.1735, -0.6177],\n",
      "        [ 2.0117, -1.1735, -0.6177],\n",
      "        [-0.2814, -1.2688,  2.1148]], grad_fn=<AddBackward0>)\n",
      "progress: 380 loss= 0.19427628815174103\n",
      "tensor([[ 2.0133, -1.1746, -0.6186],\n",
      "        [-0.6997,  0.7331,  0.2383],\n",
      "        [-2.7880,  0.5915,  2.7731],\n",
      "        [ 2.0133, -1.1746, -0.6186],\n",
      "        [ 2.0133, -1.1746, -0.6186],\n",
      "        [-0.2820, -1.2698,  2.1160]], grad_fn=<AddBackward0>)\n",
      "progress: 381 loss= 0.1939871460199356\n",
      "tensor([[ 2.0143, -1.1756, -0.6187],\n",
      "        [-0.6999,  0.7328,  0.2385],\n",
      "        [-2.7896,  0.5912,  2.7751],\n",
      "        [ 2.0143, -1.1756, -0.6187],\n",
      "        [ 2.0143, -1.1756, -0.6187],\n",
      "        [-0.2826, -1.2708,  2.1176]], grad_fn=<AddBackward0>)\n",
      "progress: 382 loss= 0.1938631683588028\n",
      "tensor([[ 2.0150, -1.1754, -0.6196],\n",
      "        [-0.7007,  0.7348,  0.2376],\n",
      "        [-2.7922,  0.5935,  2.7759],\n",
      "        [ 2.0150, -1.1754, -0.6196],\n",
      "        [ 2.0150, -1.1754, -0.6196],\n",
      "        [-0.2830, -1.2706,  2.1182]], grad_fn=<AddBackward0>)\n",
      "progress: 383 loss= 0.1935877799987793\n",
      "tensor([[ 2.0162, -1.1764, -0.6198],\n",
      "        [-0.7011,  0.7348,  0.2378],\n",
      "        [-2.7938,  0.5932,  2.7779],\n",
      "        [ 2.0162, -1.1764, -0.6198],\n",
      "        [ 2.0162, -1.1764, -0.6198],\n",
      "        [-0.2837, -1.2716,  2.1198]], grad_fn=<AddBackward0>)\n",
      "progress: 384 loss= 0.19342367351055145\n",
      "tensor([[ 2.0167, -1.1762, -0.6205],\n",
      "        [-0.7017,  0.7366,  0.2369],\n",
      "        [-2.7964,  0.5955,  2.7787],\n",
      "        [ 2.0167, -1.1762, -0.6205],\n",
      "        [ 2.0167, -1.1762, -0.6205],\n",
      "        [-0.2841, -1.2714,  2.1203]], grad_fn=<AddBackward0>)\n",
      "progress: 385 loss= 0.19318969547748566\n",
      "tensor([[ 2.0181, -1.1773, -0.6209],\n",
      "        [-0.7024,  0.7368,  0.2373],\n",
      "        [-2.7980,  0.5952,  2.7807],\n",
      "        [ 2.0181, -1.1773, -0.6209],\n",
      "        [ 2.0181, -1.1773, -0.6209],\n",
      "        [-0.2848, -1.2724,  2.1220]], grad_fn=<AddBackward0>)\n",
      "progress: 386 loss= 0.1929933875799179\n",
      "tensor([[ 2.0185, -1.1769, -0.6220],\n",
      "        [-0.7028,  0.7383,  0.2362],\n",
      "        [-2.8004,  0.5976,  2.7805],\n",
      "        [ 2.0185, -1.1769, -0.6220],\n",
      "        [ 2.0185, -1.1769, -0.6220],\n",
      "        [-0.2851, -1.2722,  2.1221]], grad_fn=<AddBackward0>)\n",
      "progress: 387 loss= 0.19280225038528442\n",
      "tensor([[ 2.0200, -1.1780, -0.6224],\n",
      "        [-0.7036,  0.7388,  0.2364],\n",
      "        [-2.8020,  0.5973,  2.7826],\n",
      "        [ 2.0200, -1.1780, -0.6224],\n",
      "        [ 2.0200, -1.1780, -0.6224],\n",
      "        [-0.2858, -1.2732,  2.1237]], grad_fn=<AddBackward0>)\n",
      "progress: 388 loss= 0.1925629824399948\n",
      "tensor([[ 2.0196, -1.1775, -0.6225],\n",
      "        [-0.7053,  0.7403,  0.2366],\n",
      "        [-2.8061,  0.5999,  2.7844],\n",
      "        [ 2.0196, -1.1775, -0.6225],\n",
      "        [ 2.0196, -1.1775, -0.6225],\n",
      "        [-0.2877, -1.2727,  2.1253]], grad_fn=<AddBackward0>)\n",
      "progress: 389 loss= 0.19240112602710724\n",
      "tensor([[ 2.0217, -1.1788, -0.6234],\n",
      "        [-0.7048,  0.7408,  0.2357],\n",
      "        [-2.8061,  0.5993,  2.7853],\n",
      "        [ 2.0217, -1.1788, -0.6234],\n",
      "        [ 2.0217, -1.1788, -0.6234],\n",
      "        [-0.2868, -1.2740,  2.1259]], grad_fn=<AddBackward0>)\n",
      "progress: 390 loss= 0.19214223325252533\n",
      "tensor([[ 2.0215, -1.1784, -0.6236],\n",
      "        [-0.7063,  0.7420,  0.2359],\n",
      "        [-2.8103,  0.6019,  2.7872],\n",
      "        [ 2.0215, -1.1784, -0.6236],\n",
      "        [ 2.0215, -1.1784, -0.6236],\n",
      "        [-0.2888, -1.2735,  2.1275]], grad_fn=<AddBackward0>)\n",
      "progress: 391 loss= 0.1919921189546585\n",
      "tensor([[ 2.0235, -1.1795, -0.6248],\n",
      "        [-0.7060,  0.7427,  0.2350],\n",
      "        [-2.8101,  0.6014,  2.7872],\n",
      "        [ 2.0235, -1.1795, -0.6248],\n",
      "        [ 2.0235, -1.1795, -0.6248],\n",
      "        [-0.2878, -1.2748,  2.1276]], grad_fn=<AddBackward0>)\n",
      "progress: 392 loss= 0.19173330068588257\n",
      "tensor([[ 2.0248, -1.1806, -0.6251],\n",
      "        [-0.7061,  0.7424,  0.2353],\n",
      "        [-2.8117,  0.6010,  2.7892],\n",
      "        [ 2.0248, -1.1806, -0.6251],\n",
      "        [ 2.0248, -1.1806, -0.6251],\n",
      "        [-0.2885, -1.2758,  2.1293]], grad_fn=<AddBackward0>)\n",
      "progress: 393 loss= 0.19159136712551117\n",
      "tensor([[ 2.0252, -1.1803, -0.6258],\n",
      "        [-0.7070,  0.7444,  0.2344],\n",
      "        [-2.8143,  0.6034,  2.7899],\n",
      "        [ 2.0252, -1.1803, -0.6258],\n",
      "        [ 2.0252, -1.1803, -0.6258],\n",
      "        [-0.2889, -1.2756,  2.1298]], grad_fn=<AddBackward0>)\n",
      "progress: 394 loss= 0.19134050607681274\n",
      "tensor([[ 2.0266, -1.1814, -0.6262],\n",
      "        [-0.7074,  0.7444,  0.2346],\n",
      "        [-2.8159,  0.6030,  2.7919],\n",
      "        [ 2.0266, -1.1814, -0.6262],\n",
      "        [ 2.0266, -1.1814, -0.6262],\n",
      "        [-0.2895, -1.2766,  2.1315]], grad_fn=<AddBackward0>)\n",
      "progress: 395 loss= 0.1911584734916687\n",
      "tensor([[ 2.0268, -1.1811, -0.6267],\n",
      "        [-0.7080,  0.7462,  0.2337],\n",
      "        [-2.8185,  0.6054,  2.7927],\n",
      "        [ 2.0268, -1.1811, -0.6267],\n",
      "        [ 2.0268, -1.1811, -0.6267],\n",
      "        [-0.2900, -1.2765,  2.1320]], grad_fn=<AddBackward0>)\n",
      "progress: 396 loss= 0.19094885885715485\n",
      "tensor([[ 2.0283, -1.1822, -0.6272],\n",
      "        [-0.7086,  0.7464,  0.2340],\n",
      "        [-2.8201,  0.6050,  2.7947],\n",
      "        [ 2.0283, -1.1822, -0.6272],\n",
      "        [ 2.0283, -1.1822, -0.6272],\n",
      "        [-0.2906, -1.2775,  2.1336]], grad_fn=<AddBackward0>)\n",
      "progress: 397 loss= 0.19074399769306183\n",
      "tensor([[ 2.0282, -1.1817, -0.6278],\n",
      "        [-0.7106,  0.7482,  0.2340],\n",
      "        [-2.8240,  0.6078,  2.7956],\n",
      "        [ 2.0282, -1.1817, -0.6278],\n",
      "        [ 2.0282, -1.1817, -0.6278],\n",
      "        [-0.2924, -1.2769,  2.1347]], grad_fn=<AddBackward0>)\n",
      "progress: 398 loss= 0.1905539184808731\n",
      "tensor([[ 2.0301, -1.1829, -0.6286],\n",
      "        [-0.7098,  0.7483,  0.2332],\n",
      "        [-2.8240,  0.6071,  2.7966],\n",
      "        [ 2.0301, -1.1829, -0.6286],\n",
      "        [ 2.0301, -1.1829, -0.6286],\n",
      "        [-0.2916, -1.2783,  2.1354]], grad_fn=<AddBackward0>)\n",
      "progress: 399 loss= 0.19033466279506683\n",
      "tensor([[ 2.0300, -1.1825, -0.6289],\n",
      "        [-0.7116,  0.7499,  0.2334],\n",
      "        [-2.8282,  0.6097,  2.7984],\n",
      "        [ 2.0300, -1.1825, -0.6289],\n",
      "        [ 2.0300, -1.1825, -0.6289],\n",
      "        [-0.2935, -1.2778,  2.1369]], grad_fn=<AddBackward0>)\n",
      "progress: 400 loss= 0.19014988839626312\n",
      "tensor([[ 2.0318, -1.1837, -0.6295],\n",
      "        [-0.7111,  0.7503,  0.2325],\n",
      "        [-2.8282,  0.6091,  2.7993],\n",
      "        [ 2.0318, -1.1837, -0.6295],\n",
      "        [ 2.0318, -1.1837, -0.6295],\n",
      "        [-0.2926, -1.2791,  2.1375]], grad_fn=<AddBackward0>)\n",
      "progress: 401 loss= 0.1899200677871704\n",
      "tensor([[ 2.0319, -1.1833, -0.6300],\n",
      "        [-0.7126,  0.7516,  0.2327],\n",
      "        [-2.8323,  0.6117,  2.8011],\n",
      "        [ 2.0319, -1.1833, -0.6300],\n",
      "        [ 2.0319, -1.1833, -0.6300],\n",
      "        [-0.2946, -1.2786,  2.1391]], grad_fn=<AddBackward0>)\n",
      "progress: 402 loss= 0.18974699079990387\n",
      "tensor([[ 2.0335, -1.1844, -0.6305],\n",
      "        [-0.7123,  0.7523,  0.2319],\n",
      "        [-2.8324,  0.6110,  2.8021],\n",
      "        [ 2.0335, -1.1844, -0.6305],\n",
      "        [ 2.0335, -1.1844, -0.6305],\n",
      "        [-0.2937, -1.2799,  2.1397]], grad_fn=<AddBackward0>)\n",
      "progress: 403 loss= 0.1895127147436142\n",
      "tensor([[ 2.0350, -1.1855, -0.6314],\n",
      "        [-0.7124,  0.7520,  0.2321],\n",
      "        [-2.8337,  0.6108,  2.8032],\n",
      "        [ 2.0350, -1.1855, -0.6314],\n",
      "        [ 2.0350, -1.1855, -0.6314],\n",
      "        [-0.2943, -1.2809,  2.1409]], grad_fn=<AddBackward0>)\n",
      "progress: 404 loss= 0.18936346471309662\n",
      "tensor([[ 2.0347, -1.1850, -0.6315],\n",
      "        [-0.7148,  0.7543,  0.2322],\n",
      "        [-2.8378,  0.6134,  2.8050],\n",
      "        [ 2.0347, -1.1850, -0.6315],\n",
      "        [ 2.0347, -1.1850, -0.6315],\n",
      "        [-0.2962, -1.2804,  2.1425]], grad_fn=<AddBackward0>)\n",
      "progress: 405 loss= 0.18912161886692047\n",
      "tensor([[ 2.0367, -1.1863, -0.6323],\n",
      "        [-0.7136,  0.7539,  0.2314],\n",
      "        [-2.8379,  0.6128,  2.8059],\n",
      "        [ 2.0367, -1.1863, -0.6323],\n",
      "        [ 2.0367, -1.1863, -0.6323],\n",
      "        [-0.2953, -1.2817,  2.1431]], grad_fn=<AddBackward0>)\n",
      "progress: 406 loss= 0.18895147740840912\n",
      "tensor([[ 2.0365, -1.1858, -0.6326],\n",
      "        [-0.7158,  0.7560,  0.2315],\n",
      "        [-2.8420,  0.6154,  2.8077],\n",
      "        [ 2.0365, -1.1858, -0.6326],\n",
      "        [ 2.0365, -1.1858, -0.6326],\n",
      "        [-0.2972, -1.2812,  2.1446]], grad_fn=<AddBackward0>)\n",
      "progress: 407 loss= 0.18872185051441193\n",
      "tensor([[ 2.0384, -1.1870, -0.6333],\n",
      "        [-0.7149,  0.7559,  0.2307],\n",
      "        [-2.8420,  0.6147,  2.8087],\n",
      "        [ 2.0384, -1.1870, -0.6333],\n",
      "        [ 2.0384, -1.1870, -0.6333],\n",
      "        [-0.2964, -1.2826,  2.1452]], grad_fn=<AddBackward0>)\n",
      "progress: 408 loss= 0.1885407418012619\n",
      "tensor([[ 2.0384, -1.1866, -0.6337],\n",
      "        [-0.7168,  0.7577,  0.2310],\n",
      "        [-2.8461,  0.6174,  2.8105],\n",
      "        [ 2.0384, -1.1866, -0.6337],\n",
      "        [ 2.0384, -1.1866, -0.6337],\n",
      "        [-0.2983, -1.2821,  2.1468]], grad_fn=<AddBackward0>)\n",
      "progress: 409 loss= 0.188332200050354\n",
      "tensor([[ 2.0401, -1.1877, -0.6347],\n",
      "        [-0.7161,  0.7579,  0.2300],\n",
      "        [-2.8460,  0.6168,  2.8105],\n",
      "        [ 2.0401, -1.1877, -0.6347],\n",
      "        [ 2.0401, -1.1877, -0.6347],\n",
      "        [-0.2973, -1.2833,  2.1469]], grad_fn=<AddBackward0>)\n",
      "progress: 410 loss= 0.18814073503017426\n",
      "tensor([[ 2.0403, -1.1874, -0.6352],\n",
      "        [-0.7178,  0.7594,  0.2302],\n",
      "        [-2.8501,  0.6194,  2.8123],\n",
      "        [ 2.0403, -1.1874, -0.6352],\n",
      "        [ 2.0403, -1.1874, -0.6352],\n",
      "        [-0.2992, -1.2829,  2.1485]], grad_fn=<AddBackward0>)\n",
      "progress: 411 loss= 0.1879391074180603\n",
      "tensor([[ 2.0412, -1.1884, -0.6352],\n",
      "        [-0.7188,  0.7602,  0.2304],\n",
      "        [-2.8516,  0.6191,  2.8143],\n",
      "        [ 2.0412, -1.1884, -0.6352],\n",
      "        [ 2.0412, -1.1884, -0.6352],\n",
      "        [-0.2999, -1.2839,  2.1502]], grad_fn=<AddBackward0>)\n",
      "progress: 412 loss= 0.1877286583185196\n",
      "tensor([[ 2.0420, -1.1881, -0.6361],\n",
      "        [-0.7188,  0.7611,  0.2295],\n",
      "        [-2.8542,  0.6214,  2.8151],\n",
      "        [ 2.0420, -1.1881, -0.6361],\n",
      "        [ 2.0420, -1.1881, -0.6361],\n",
      "        [-0.3003, -1.2837,  2.1507]], grad_fn=<AddBackward0>)\n",
      "progress: 413 loss= 0.18755723536014557\n",
      "tensor([[ 2.0430, -1.1892, -0.6363],\n",
      "        [-0.7200,  0.7621,  0.2297],\n",
      "        [-2.8557,  0.6210,  2.8171],\n",
      "        [ 2.0430, -1.1892, -0.6363],\n",
      "        [ 2.0430, -1.1892, -0.6363],\n",
      "        [-0.3009, -1.2847,  2.1523]], grad_fn=<AddBackward0>)\n",
      "progress: 414 loss= 0.18731093406677246\n",
      "tensor([[ 2.0450, -1.1903, -0.6374],\n",
      "        [-0.7186,  0.7615,  0.2289],\n",
      "        [-2.8556,  0.6205,  2.8171],\n",
      "        [ 2.0450, -1.1903, -0.6374],\n",
      "        [ 2.0450, -1.1903, -0.6374],\n",
      "        [-0.3000, -1.2860,  2.1525]], grad_fn=<AddBackward0>)\n",
      "progress: 415 loss= 0.18718494474887848\n",
      "tensor([[ 2.0450, -1.1899, -0.6378],\n",
      "        [-0.7210,  0.7638,  0.2290],\n",
      "        [-2.8597,  0.6231,  2.8189],\n",
      "        [ 2.0450, -1.1899, -0.6378],\n",
      "        [ 2.0450, -1.1899, -0.6378],\n",
      "        [-0.3019, -1.2855,  2.1540]], grad_fn=<AddBackward0>)\n",
      "progress: 416 loss= 0.1869238018989563\n",
      "tensor([[ 2.0467, -1.1911, -0.6384],\n",
      "        [-0.7199,  0.7635,  0.2282],\n",
      "        [-2.8597,  0.6224,  2.8198],\n",
      "        [ 2.0467, -1.1911, -0.6384],\n",
      "        [ 2.0467, -1.1911, -0.6384],\n",
      "        [-0.3010, -1.2868,  2.1546]], grad_fn=<AddBackward0>)\n",
      "progress: 417 loss= 0.18677902221679688\n",
      "tensor([[ 2.0468, -1.1907, -0.6389],\n",
      "        [-0.7220,  0.7656,  0.2283],\n",
      "        [-2.8638,  0.6251,  2.8216],\n",
      "        [ 2.0468, -1.1907, -0.6389],\n",
      "        [ 2.0468, -1.1907, -0.6389],\n",
      "        [-0.3029, -1.2863,  2.1562]], grad_fn=<AddBackward0>)\n",
      "progress: 418 loss= 0.1865306943655014\n",
      "tensor([[ 2.0483, -1.1918, -0.6393],\n",
      "        [-0.7211,  0.7655,  0.2275],\n",
      "        [-2.8638,  0.6244,  2.8226],\n",
      "        [ 2.0483, -1.1918, -0.6393],\n",
      "        [ 2.0483, -1.1918, -0.6393],\n",
      "        [-0.3021, -1.2877,  2.1568]], grad_fn=<AddBackward0>)\n",
      "progress: 419 loss= 0.18637418746948242\n",
      "tensor([[ 2.0485, -1.1914, -0.6398],\n",
      "        [-0.7230,  0.7672,  0.2278],\n",
      "        [-2.8679,  0.6270,  2.8244],\n",
      "        [ 2.0485, -1.1914, -0.6398],\n",
      "        [ 2.0485, -1.1914, -0.6398],\n",
      "        [-0.3040, -1.2872,  2.1584]], grad_fn=<AddBackward0>)\n",
      "progress: 420 loss= 0.18615783751010895\n",
      "tensor([[ 2.0496, -1.1924, -0.6404],\n",
      "        [-0.7238,  0.7678,  0.2279],\n",
      "        [-2.8693,  0.6268,  2.8254],\n",
      "        [ 2.0496, -1.1924, -0.6404],\n",
      "        [ 2.0496, -1.1924, -0.6404],\n",
      "        [-0.3045, -1.2881,  2.1596]], grad_fn=<AddBackward0>)\n",
      "progress: 421 loss= 0.18596740067005157\n",
      "tensor([[ 2.0502, -1.1921, -0.6412],\n",
      "        [-0.7240,  0.7690,  0.2270],\n",
      "        [-2.8718,  0.6291,  2.8262],\n",
      "        [ 2.0502, -1.1921, -0.6412],\n",
      "        [ 2.0502, -1.1921, -0.6412],\n",
      "        [-0.3049, -1.2880,  2.1601]], grad_fn=<AddBackward0>)\n",
      "progress: 422 loss= 0.18578459322452545\n",
      "tensor([[ 2.0514, -1.1932, -0.6414],\n",
      "        [-0.7251,  0.7697,  0.2272],\n",
      "        [-2.8734,  0.6287,  2.8282],\n",
      "        [ 2.0514, -1.1932, -0.6414],\n",
      "        [ 2.0514, -1.1932, -0.6414],\n",
      "        [-0.3055, -1.2890,  2.1617]], grad_fn=<AddBackward0>)\n",
      "progress: 423 loss= 0.18555088341236115\n",
      "tensor([[ 2.0519, -1.1929, -0.6421],\n",
      "        [-0.7250,  0.7706,  0.2263],\n",
      "        [-2.8759,  0.6310,  2.8290],\n",
      "        [ 2.0519, -1.1929, -0.6421],\n",
      "        [ 2.0519, -1.1929, -0.6421],\n",
      "        [-0.3060, -1.2888,  2.1623]], grad_fn=<AddBackward0>)\n",
      "progress: 424 loss= 0.18540889024734497\n",
      "tensor([[ 2.0532, -1.1940, -0.6425],\n",
      "        [-0.7262,  0.7717,  0.2265],\n",
      "        [-2.8775,  0.6306,  2.8309],\n",
      "        [ 2.0532, -1.1940, -0.6425],\n",
      "        [ 2.0532, -1.1940, -0.6425],\n",
      "        [-0.3066, -1.2898,  2.1639]], grad_fn=<AddBackward0>)\n",
      "progress: 425 loss= 0.18514050543308258\n",
      "tensor([[ 2.0549, -1.1951, -0.6435],\n",
      "        [-0.7249,  0.7710,  0.2257],\n",
      "        [-2.8773,  0.6301,  2.8310],\n",
      "        [ 2.0549, -1.1951, -0.6435],\n",
      "        [ 2.0549, -1.1951, -0.6435],\n",
      "        [-0.3056, -1.2911,  2.1640]], grad_fn=<AddBackward0>)\n",
      "progress: 426 loss= 0.18503962457180023\n",
      "tensor([[ 2.0551, -1.1947, -0.6440],\n",
      "        [-0.7272,  0.7734,  0.2258],\n",
      "        [-2.8814,  0.6327,  2.8328],\n",
      "        [ 2.0551, -1.1947, -0.6440],\n",
      "        [ 2.0551, -1.1947, -0.6440],\n",
      "        [-0.3075, -1.2906,  2.1656]], grad_fn=<AddBackward0>)\n",
      "progress: 427 loss= 0.18477024137973785\n",
      "tensor([[ 2.0560, -1.1957, -0.6440],\n",
      "        [-0.7276,  0.7733,  0.2260],\n",
      "        [-2.8829,  0.6323,  2.8347],\n",
      "        [ 2.0560, -1.1957, -0.6440],\n",
      "        [ 2.0560, -1.1957, -0.6440],\n",
      "        [-0.3082, -1.2916,  2.1672]], grad_fn=<AddBackward0>)\n",
      "progress: 428 loss= 0.18463148176670074\n",
      "tensor([[ 2.0567, -1.1954, -0.6449],\n",
      "        [-0.7282,  0.7750,  0.2251],\n",
      "        [-2.8855,  0.6346,  2.8355],\n",
      "        [ 2.0567, -1.1954, -0.6449],\n",
      "        [ 2.0567, -1.1954, -0.6449],\n",
      "        [-0.3086, -1.2915,  2.1678]], grad_fn=<AddBackward0>)\n",
      "progress: 429 loss= 0.18439750373363495\n",
      "tensor([[ 2.0578, -1.1965, -0.6451],\n",
      "        [-0.7288,  0.7753,  0.2254],\n",
      "        [-2.8870,  0.6342,  2.8375],\n",
      "        [ 2.0578, -1.1965, -0.6451],\n",
      "        [ 2.0578, -1.1965, -0.6451],\n",
      "        [-0.3092, -1.2925,  2.1694]], grad_fn=<AddBackward0>)\n",
      "progress: 430 loss= 0.18421870470046997\n",
      "tensor([[ 2.0583, -1.1962, -0.6458],\n",
      "        [-0.7292,  0.7767,  0.2245],\n",
      "        [-2.8895,  0.6365,  2.8383],\n",
      "        [ 2.0583, -1.1962, -0.6458],\n",
      "        [ 2.0583, -1.1962, -0.6458],\n",
      "        [-0.3096, -1.2923,  2.1699]], grad_fn=<AddBackward0>)\n",
      "progress: 431 loss= 0.18403035402297974\n",
      "tensor([[ 2.0597, -1.1972, -0.6466],\n",
      "        [-0.7301,  0.7773,  0.2247],\n",
      "        [-2.8909,  0.6363,  2.8393],\n",
      "        [ 2.0597, -1.1972, -0.6466],\n",
      "        [ 2.0597, -1.1972, -0.6466],\n",
      "        [-0.3101, -1.2933,  2.1711]], grad_fn=<AddBackward0>)\n",
      "progress: 432 loss= 0.18381696939468384\n",
      "tensor([[ 2.0600, -1.1969, -0.6472],\n",
      "        [-0.7302,  0.7784,  0.2238],\n",
      "        [-2.8934,  0.6386,  2.8401],\n",
      "        [ 2.0600, -1.1969, -0.6472],\n",
      "        [ 2.0600, -1.1969, -0.6472],\n",
      "        [-0.3105, -1.2931,  2.1716]], grad_fn=<AddBackward0>)\n",
      "progress: 433 loss= 0.18366487324237823\n",
      "tensor([[ 2.0615, -1.1980, -0.6476],\n",
      "        [-0.7313,  0.7793,  0.2240],\n",
      "        [-2.8949,  0.6382,  2.8420],\n",
      "        [ 2.0615, -1.1980, -0.6476],\n",
      "        [ 2.0615, -1.1980, -0.6476],\n",
      "        [-0.3112, -1.2941,  2.1733]], grad_fn=<AddBackward0>)\n",
      "progress: 434 loss= 0.18341034650802612\n",
      "tensor([[ 2.0611, -1.1975, -0.6477],\n",
      "        [-0.7327,  0.7804,  0.2241],\n",
      "        [-2.8990,  0.6408,  2.8438],\n",
      "        [ 2.0611, -1.1975, -0.6477],\n",
      "        [ 2.0611, -1.1975, -0.6477],\n",
      "        [-0.3130, -1.2937,  2.1748]], grad_fn=<AddBackward0>)\n",
      "progress: 435 loss= 0.1832915097475052\n",
      "tensor([[ 2.0631, -1.1987, -0.6485],\n",
      "        [-0.7324,  0.7811,  0.2233],\n",
      "        [-2.8990,  0.6401,  2.8448],\n",
      "        [ 2.0631, -1.1987, -0.6485],\n",
      "        [ 2.0631, -1.1987, -0.6485],\n",
      "        [-0.3122, -1.2950,  2.1754]], grad_fn=<AddBackward0>)\n",
      "progress: 436 loss= 0.1830245852470398\n",
      "tensor([[ 2.0642, -1.1997, -0.6487],\n",
      "        [-0.7326,  0.7809,  0.2237],\n",
      "        [-2.9005,  0.6397,  2.8467],\n",
      "        [ 2.0642, -1.1997, -0.6487],\n",
      "        [ 2.0642, -1.1997, -0.6487],\n",
      "        [-0.3128, -1.2960,  2.1771]], grad_fn=<AddBackward0>)\n",
      "progress: 437 loss= 0.18290859460830688\n",
      "tensor([[ 2.0648, -1.1994, -0.6499],\n",
      "        [-0.7334,  0.7828,  0.2226],\n",
      "        [-2.9029,  0.6422,  2.8466],\n",
      "        [ 2.0648, -1.1994, -0.6499],\n",
      "        [ 2.0648, -1.1994, -0.6499],\n",
      "        [-0.3131, -1.2958,  2.1771]], grad_fn=<AddBackward0>)\n",
      "progress: 438 loss= 0.18266679346561432\n",
      "tensor([[ 2.0661, -1.2004, -0.6502],\n",
      "        [-0.7338,  0.7829,  0.2229],\n",
      "        [-2.9044,  0.6418,  2.8485],\n",
      "        [ 2.0661, -1.2004, -0.6502],\n",
      "        [ 2.0661, -1.2004, -0.6502],\n",
      "        [-0.3137, -1.2968,  2.1787]], grad_fn=<AddBackward0>)\n",
      "progress: 439 loss= 0.18250145018100739\n",
      "tensor([[ 2.0665, -1.2001, -0.6508],\n",
      "        [-0.7344,  0.7845,  0.2220],\n",
      "        [-2.9070,  0.6441,  2.8493],\n",
      "        [ 2.0665, -1.2001, -0.6508],\n",
      "        [ 2.0665, -1.2001, -0.6508],\n",
      "        [-0.3141, -1.2966,  2.1793]], grad_fn=<AddBackward0>)\n",
      "progress: 440 loss= 0.1822998970746994\n",
      "tensor([[ 2.0679, -1.2012, -0.6512],\n",
      "        [-0.7351,  0.7848,  0.2222],\n",
      "        [-2.9085,  0.6437,  2.8513],\n",
      "        [ 2.0679, -1.2012, -0.6512],\n",
      "        [ 2.0679, -1.2012, -0.6512],\n",
      "        [-0.3147, -1.2976,  2.1809]], grad_fn=<AddBackward0>)\n",
      "progress: 441 loss= 0.18209494650363922\n",
      "tensor([[ 2.0681, -1.2008, -0.6517],\n",
      "        [-0.7354,  0.7862,  0.2214],\n",
      "        [-2.9110,  0.6460,  2.8521],\n",
      "        [ 2.0681, -1.2008, -0.6517],\n",
      "        [ 2.0681, -1.2008, -0.6517],\n",
      "        [-0.3152, -1.2975,  2.1814]], grad_fn=<AddBackward0>)\n",
      "progress: 442 loss= 0.18193800747394562\n",
      "tensor([[ 2.0696, -1.2019, -0.6526],\n",
      "        [-0.7363,  0.7868,  0.2215],\n",
      "        [-2.9123,  0.6457,  2.8531],\n",
      "        [ 2.0696, -1.2019, -0.6526],\n",
      "        [ 2.0696, -1.2019, -0.6526],\n",
      "        [-0.3157, -1.2984,  2.1826]], grad_fn=<AddBackward0>)\n",
      "progress: 443 loss= 0.18171286582946777\n",
      "tensor([[ 2.0693, -1.2014, -0.6528],\n",
      "        [-0.7378,  0.7882,  0.2216],\n",
      "        [-2.9164,  0.6483,  2.8549],\n",
      "        [ 2.0693, -1.2014, -0.6528],\n",
      "        [ 2.0693, -1.2014, -0.6528],\n",
      "        [-0.3176, -1.2980,  2.1842]], grad_fn=<AddBackward0>)\n",
      "progress: 444 loss= 0.18156586587429047\n",
      "tensor([[ 2.0712, -1.2026, -0.6535],\n",
      "        [-0.7375,  0.7888,  0.2208],\n",
      "        [-2.9164,  0.6476,  2.8558],\n",
      "        [ 2.0712, -1.2026, -0.6535],\n",
      "        [ 2.0712, -1.2026, -0.6535],\n",
      "        [-0.3167, -1.2993,  2.1848]], grad_fn=<AddBackward0>)\n",
      "progress: 445 loss= 0.1813223510980606\n",
      "tensor([[ 2.0711, -1.2022, -0.6538],\n",
      "        [-0.7388,  0.7899,  0.2210],\n",
      "        [-2.9204,  0.6502,  2.8576],\n",
      "        [ 2.0711, -1.2022, -0.6538],\n",
      "        [ 2.0711, -1.2022, -0.6538],\n",
      "        [-0.3186, -1.2988,  2.1863]], grad_fn=<AddBackward0>)\n",
      "progress: 446 loss= 0.18118827044963837\n",
      "tensor([[ 2.0728, -1.2034, -0.6544],\n",
      "        [-0.7386,  0.7906,  0.2201],\n",
      "        [-2.9204,  0.6495,  2.8586],\n",
      "        [ 2.0728, -1.2034, -0.6544],\n",
      "        [ 2.0728, -1.2034, -0.6544],\n",
      "        [-0.3177, -1.3002,  2.1869]], grad_fn=<AddBackward0>)\n",
      "progress: 447 loss= 0.1809489130973816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0742, -1.2044, -0.6548],\n",
      "        [-0.7388,  0.7904,  0.2205],\n",
      "        [-2.9219,  0.6491,  2.8605],\n",
      "        [ 2.0742, -1.2044, -0.6548],\n",
      "        [ 2.0742, -1.2044, -0.6548],\n",
      "        [-0.3183, -1.3012,  2.1886]], grad_fn=<AddBackward0>)\n",
      "progress: 448 loss= 0.18080486357212067\n",
      "tensor([[ 2.0745, -1.2040, -0.6558],\n",
      "        [-0.7396,  0.7923,  0.2195],\n",
      "        [-2.9243,  0.6515,  2.8603],\n",
      "        [ 2.0745, -1.2040, -0.6558],\n",
      "        [ 2.0745, -1.2040, -0.6558],\n",
      "        [-0.3186, -1.3010,  2.1886]], grad_fn=<AddBackward0>)\n",
      "progress: 449 loss= 0.18059693276882172\n",
      "tensor([[ 2.0760, -1.2051, -0.6562],\n",
      "        [-0.7400,  0.7924,  0.2197],\n",
      "        [-2.9258,  0.6512,  2.8623],\n",
      "        [ 2.0760, -1.2051, -0.6562],\n",
      "        [ 2.0760, -1.2051, -0.6562],\n",
      "        [-0.3192, -1.3020,  2.1902]], grad_fn=<AddBackward0>)\n",
      "progress: 450 loss= 0.18041370809078217\n",
      "tensor([[ 2.0756, -1.2046, -0.6564],\n",
      "        [-0.7420,  0.7942,  0.2198],\n",
      "        [-2.9298,  0.6537,  2.8641],\n",
      "        [ 2.0756, -1.2046, -0.6564],\n",
      "        [ 2.0756, -1.2046, -0.6564],\n",
      "        [-0.3211, -1.3015,  2.1918]], grad_fn=<AddBackward0>)\n",
      "progress: 451 loss= 0.18022631108760834\n",
      "tensor([[ 2.0776, -1.2058, -0.6571],\n",
      "        [-0.7413,  0.7943,  0.2190],\n",
      "        [-2.9298,  0.6531,  2.8650],\n",
      "        [ 2.0776, -1.2058, -0.6571],\n",
      "        [ 2.0776, -1.2058, -0.6571],\n",
      "        [-0.3202, -1.3028,  2.1924]], grad_fn=<AddBackward0>)\n",
      "progress: 452 loss= 0.18002665042877197\n",
      "tensor([[ 2.0774, -1.2054, -0.6574],\n",
      "        [-0.7430,  0.7959,  0.2192],\n",
      "        [-2.9338,  0.6556,  2.8668],\n",
      "        [ 2.0774, -1.2054, -0.6574],\n",
      "        [ 2.0774, -1.2054, -0.6574],\n",
      "        [-0.3221, -1.3024,  2.1939]], grad_fn=<AddBackward0>)\n",
      "progress: 453 loss= 0.1798570156097412\n",
      "tensor([[ 2.0792, -1.2065, -0.6585],\n",
      "        [-0.7425,  0.7963,  0.2183],\n",
      "        [-2.9336,  0.6551,  2.8668],\n",
      "        [ 2.0792, -1.2065, -0.6585],\n",
      "        [ 2.0792, -1.2065, -0.6585],\n",
      "        [-0.3212, -1.3036,  2.1941]], grad_fn=<AddBackward0>)\n",
      "progress: 454 loss= 0.17965084314346313\n",
      "tensor([[ 2.0793, -1.2061, -0.6589],\n",
      "        [-0.7440,  0.7976,  0.2185],\n",
      "        [-2.9376,  0.6576,  2.8686],\n",
      "        [ 2.0793, -1.2061, -0.6589],\n",
      "        [ 2.0793, -1.2061, -0.6589],\n",
      "        [-0.3230, -1.3032,  2.1956]], grad_fn=<AddBackward0>)\n",
      "progress: 455 loss= 0.17949001491069794\n",
      "tensor([[ 2.0808, -1.2072, -0.6594],\n",
      "        [-0.7437,  0.7983,  0.2176],\n",
      "        [-2.9377,  0.6569,  2.8696],\n",
      "        [ 2.0808, -1.2072, -0.6594],\n",
      "        [ 2.0808, -1.2072, -0.6594],\n",
      "        [-0.3222, -1.3045,  2.1962]], grad_fn=<AddBackward0>)\n",
      "progress: 456 loss= 0.17926602065563202\n",
      "tensor([[ 2.0810, -1.2069, -0.6599],\n",
      "        [-0.7450,  0.7993,  0.2178],\n",
      "        [-2.9417,  0.6595,  2.8713],\n",
      "        [ 2.0810, -1.2069, -0.6599],\n",
      "        [ 2.0810, -1.2069, -0.6599],\n",
      "        [-0.3240, -1.3040,  2.1978]], grad_fn=<AddBackward0>)\n",
      "progress: 457 loss= 0.1791248321533203\n",
      "tensor([[ 2.0819, -1.2078, -0.6599],\n",
      "        [-0.7462,  0.8003,  0.2180],\n",
      "        [-2.9431,  0.6591,  2.8733],\n",
      "        [ 2.0819, -1.2078, -0.6599],\n",
      "        [ 2.0819, -1.2078, -0.6599],\n",
      "        [-0.3246, -1.3051,  2.1994]], grad_fn=<AddBackward0>)\n",
      "progress: 458 loss= 0.1789000779390335\n",
      "tensor([[ 2.0839, -1.2091, -0.6607],\n",
      "        [-0.7450,  0.7999,  0.2174],\n",
      "        [-2.9431,  0.6584,  2.8742],\n",
      "        [ 2.0839, -1.2091, -0.6607],\n",
      "        [ 2.0839, -1.2091, -0.6607],\n",
      "        [-0.3238, -1.3064,  2.2000]], grad_fn=<AddBackward0>)\n",
      "progress: 459 loss= 0.17875392735004425\n",
      "tensor([[ 2.0838, -1.2085, -0.6614],\n",
      "        [-0.7471,  0.8020,  0.2173],\n",
      "        [-2.9469,  0.6611,  2.8751],\n",
      "        [ 2.0838, -1.2085, -0.6614],\n",
      "        [ 2.0838, -1.2085, -0.6614],\n",
      "        [-0.3255, -1.3059,  2.2011]], grad_fn=<AddBackward0>)\n",
      "progress: 460 loss= 0.17854030430316925\n",
      "tensor([[ 2.0855, -1.2097, -0.6620],\n",
      "        [-0.7462,  0.8019,  0.2165],\n",
      "        [-2.9470,  0.6604,  2.8760],\n",
      "        [ 2.0855, -1.2097, -0.6620],\n",
      "        [ 2.0855, -1.2097, -0.6620],\n",
      "        [-0.3247, -1.3072,  2.2017]], grad_fn=<AddBackward0>)\n",
      "progress: 461 loss= 0.17837153375148773\n",
      "tensor([[ 2.0856, -1.2093, -0.6624],\n",
      "        [-0.7481,  0.8036,  0.2166],\n",
      "        [-2.9510,  0.6630,  2.8778],\n",
      "        [ 2.0856, -1.2093, -0.6624],\n",
      "        [ 2.0856, -1.2093, -0.6624],\n",
      "        [-0.3265, -1.3067,  2.2032]], grad_fn=<AddBackward0>)\n",
      "progress: 462 loss= 0.1781715750694275\n",
      "tensor([[ 2.0871, -1.2104, -0.6629],\n",
      "        [-0.7475,  0.8038,  0.2158],\n",
      "        [-2.9510,  0.6623,  2.8787],\n",
      "        [ 2.0871, -1.2104, -0.6629],\n",
      "        [ 2.0871, -1.2104, -0.6629],\n",
      "        [-0.3257, -1.3081,  2.2039]], grad_fn=<AddBackward0>)\n",
      "progress: 463 loss= 0.17799012362957\n",
      "tensor([[ 2.0873, -1.2100, -0.6634],\n",
      "        [-0.7491,  0.8053,  0.2161],\n",
      "        [-2.9550,  0.6649,  2.8805],\n",
      "        [ 2.0873, -1.2100, -0.6634],\n",
      "        [ 2.0873, -1.2100, -0.6634],\n",
      "        [-0.3275, -1.3076,  2.2054]], grad_fn=<AddBackward0>)\n",
      "progress: 464 loss= 0.17781291902065277\n",
      "tensor([[ 2.0882, -1.2110, -0.6639],\n",
      "        [-0.7501,  0.8061,  0.2162],\n",
      "        [-2.9562,  0.6646,  2.8815],\n",
      "        [ 2.0882, -1.2110, -0.6639],\n",
      "        [ 2.0882, -1.2110, -0.6639],\n",
      "        [-0.3280, -1.3086,  2.2065]], grad_fn=<AddBackward0>)\n",
      "progress: 465 loss= 0.17761658132076263\n",
      "tensor([[ 2.0890, -1.2107, -0.6648],\n",
      "        [-0.7501,  0.8070,  0.2153],\n",
      "        [-2.9588,  0.6669,  2.8823],\n",
      "        [ 2.0890, -1.2107, -0.6648],\n",
      "        [ 2.0890, -1.2107, -0.6648],\n",
      "        [-0.3284, -1.3084,  2.2071]], grad_fn=<AddBackward0>)\n",
      "progress: 466 loss= 0.17746394872665405\n",
      "tensor([[ 2.0900, -1.2117, -0.6649],\n",
      "        [-0.7513,  0.8080,  0.2155],\n",
      "        [-2.9602,  0.6665,  2.8842],\n",
      "        [ 2.0900, -1.2117, -0.6649],\n",
      "        [ 2.0900, -1.2117, -0.6649],\n",
      "        [-0.3290, -1.3094,  2.2087]], grad_fn=<AddBackward0>)\n",
      "progress: 467 loss= 0.17723120748996735\n",
      "tensor([[ 2.0918, -1.2129, -0.6656],\n",
      "        [-0.7500,  0.8074,  0.2147],\n",
      "        [-2.9602,  0.6658,  2.8852],\n",
      "        [ 2.0918, -1.2129, -0.6656],\n",
      "        [ 2.0918, -1.2129, -0.6656],\n",
      "        [-0.3281, -1.3108,  2.2093]], grad_fn=<AddBackward0>)\n",
      "progress: 468 loss= 0.1771046370267868\n",
      "tensor([[ 2.0918, -1.2125, -0.6659],\n",
      "        [-0.7523,  0.8097,  0.2148],\n",
      "        [-2.9642,  0.6683,  2.8869],\n",
      "        [ 2.0918, -1.2125, -0.6659],\n",
      "        [ 2.0918, -1.2125, -0.6659],\n",
      "        [-0.3300, -1.3103,  2.2108]], grad_fn=<AddBackward0>)\n",
      "progress: 469 loss= 0.1768680065870285\n",
      "tensor([[ 2.0935, -1.2135, -0.6669],\n",
      "        [-0.7512,  0.8094,  0.2140],\n",
      "        [-2.9640,  0.6678,  2.8869],\n",
      "        [ 2.0935, -1.2135, -0.6669],\n",
      "        [ 2.0935, -1.2135, -0.6669],\n",
      "        [-0.3290, -1.3116,  2.2110]], grad_fn=<AddBackward0>)\n",
      "progress: 470 loss= 0.17673681676387787\n",
      "tensor([[ 2.0936, -1.2131, -0.6674],\n",
      "        [-0.7532,  0.8113,  0.2141],\n",
      "        [-2.9680,  0.6703,  2.8887],\n",
      "        [ 2.0936, -1.2131, -0.6674],\n",
      "        [ 2.0936, -1.2131, -0.6674],\n",
      "        [-0.3309, -1.3111,  2.2125]], grad_fn=<AddBackward0>)\n",
      "progress: 471 loss= 0.1765129417181015\n",
      "tensor([[ 2.0944, -1.2141, -0.6674],\n",
      "        [-0.7539,  0.8116,  0.2143],\n",
      "        [-2.9695,  0.6699,  2.8907],\n",
      "        [ 2.0944, -1.2141, -0.6674],\n",
      "        [ 2.0944, -1.2141, -0.6674],\n",
      "        [-0.3315, -1.3121,  2.2141]], grad_fn=<AddBackward0>)\n",
      "progress: 472 loss= 0.1763593554496765\n",
      "tensor([[ 2.0952, -1.2139, -0.6683],\n",
      "        [-0.7542,  0.8130,  0.2135],\n",
      "        [-2.9720,  0.6722,  2.8914],\n",
      "        [ 2.0952, -1.2139, -0.6683],\n",
      "        [ 2.0952, -1.2139, -0.6683],\n",
      "        [-0.3319, -1.3120,  2.2147]], grad_fn=<AddBackward0>)\n",
      "progress: 473 loss= 0.17616331577301025\n",
      "tensor([[ 2.0962, -1.2149, -0.6684],\n",
      "        [-0.7551,  0.8136,  0.2137],\n",
      "        [-2.9734,  0.6718,  2.8934],\n",
      "        [ 2.0962, -1.2149, -0.6684],\n",
      "        [ 2.0962, -1.2149, -0.6684],\n",
      "        [-0.3325, -1.3130,  2.2163]], grad_fn=<AddBackward0>)\n",
      "progress: 474 loss= 0.17597030103206635\n",
      "tensor([[ 2.0968, -1.2146, -0.6692],\n",
      "        [-0.7552,  0.8147,  0.2130],\n",
      "        [-2.9760,  0.6740,  2.8941],\n",
      "        [ 2.0968, -1.2146, -0.6692],\n",
      "        [ 2.0968, -1.2146, -0.6692],\n",
      "        [-0.3329, -1.3128,  2.2168]], grad_fn=<AddBackward0>)\n",
      "progress: 475 loss= 0.1758226901292801\n",
      "tensor([[ 2.0981, -1.2155, -0.6699],\n",
      "        [-0.7563,  0.8156,  0.2130],\n",
      "        [-2.9772,  0.6738,  2.8951],\n",
      "        [ 2.0981, -1.2155, -0.6699],\n",
      "        [ 2.0981, -1.2155, -0.6699],\n",
      "        [-0.3333, -1.3138,  2.2179]], grad_fn=<AddBackward0>)\n",
      "progress: 476 loss= 0.17559252679347992\n",
      "tensor([[ 2.0984, -1.2152, -0.6705],\n",
      "        [-0.7561,  0.8163,  0.2122],\n",
      "        [-2.9797,  0.6760,  2.8959],\n",
      "        [ 2.0984, -1.2152, -0.6705],\n",
      "        [ 2.0984, -1.2152, -0.6705],\n",
      "        [-0.3338, -1.3137,  2.2185]], grad_fn=<AddBackward0>)\n",
      "progress: 477 loss= 0.1754770278930664\n",
      "tensor([[ 2.0998, -1.2163, -0.6709],\n",
      "        [-0.7573,  0.8173,  0.2123],\n",
      "        [-2.9812,  0.6756,  2.8979],\n",
      "        [ 2.0998, -1.2163, -0.6709],\n",
      "        [ 2.0998, -1.2163, -0.6709],\n",
      "        [-0.3343, -1.3147,  2.2201]], grad_fn=<AddBackward0>)\n",
      "progress: 478 loss= 0.1752237230539322\n",
      "tensor([[ 2.1013, -1.2174, -0.6713],\n",
      "        [-0.7561,  0.8169,  0.2116],\n",
      "        [-2.9812,  0.6749,  2.8988],\n",
      "        [ 2.1013, -1.2174, -0.6713],\n",
      "        [ 2.1013, -1.2174, -0.6713],\n",
      "        [-0.3335, -1.3160,  2.2207]], grad_fn=<AddBackward0>)\n",
      "progress: 479 loss= 0.17511220276355743\n",
      "tensor([[ 2.1014, -1.2170, -0.6718],\n",
      "        [-0.7583,  0.8190,  0.2117],\n",
      "        [-2.9851,  0.6775,  2.9006],\n",
      "        [ 2.1014, -1.2170, -0.6718],\n",
      "        [ 2.1014, -1.2170, -0.6718],\n",
      "        [-0.3353, -1.3155,  2.2222]], grad_fn=<AddBackward0>)\n",
      "progress: 480 loss= 0.1748802214860916\n",
      "tensor([[ 2.1024, -1.2179, -0.6724],\n",
      "        [-0.7588,  0.8192,  0.2119],\n",
      "        [-2.9864,  0.6772,  2.9015],\n",
      "        [ 2.1024, -1.2179, -0.6724],\n",
      "        [ 2.1024, -1.2179, -0.6724],\n",
      "        [-0.3358, -1.3165,  2.2234]], grad_fn=<AddBackward0>)\n",
      "progress: 481 loss= 0.17473876476287842\n",
      "tensor([[ 2.1030, -1.2176, -0.6732],\n",
      "        [-0.7593,  0.8207,  0.2110],\n",
      "        [-2.9889,  0.6794,  2.9023],\n",
      "        [ 2.1030, -1.2176, -0.6732],\n",
      "        [ 2.1030, -1.2176, -0.6732],\n",
      "        [-0.3362, -1.3164,  2.2239]], grad_fn=<AddBackward0>)\n",
      "progress: 482 loss= 0.17454080283641815\n",
      "tensor([[ 2.1042, -1.2187, -0.6734],\n",
      "        [-0.7600,  0.8211,  0.2112],\n",
      "        [-2.9903,  0.6790,  2.9043],\n",
      "        [ 2.1042, -1.2187, -0.6734],\n",
      "        [ 2.1042, -1.2187, -0.6734],\n",
      "        [-0.3368, -1.3174,  2.2255]], grad_fn=<AddBackward0>)\n",
      "progress: 483 loss= 0.17435427010059357\n",
      "tensor([[ 2.1046, -1.2183, -0.6740],\n",
      "        [-0.7602,  0.8223,  0.2103],\n",
      "        [-2.9929,  0.6813,  2.9050],\n",
      "        [ 2.1046, -1.2183, -0.6740],\n",
      "        [ 2.1046, -1.2183, -0.6740],\n",
      "        [-0.3372, -1.3172,  2.2261]], grad_fn=<AddBackward0>)\n",
      "progress: 484 loss= 0.1741965413093567\n",
      "tensor([[ 2.1059, -1.2194, -0.6744],\n",
      "        [-0.7612,  0.8231,  0.2105],\n",
      "        [-2.9943,  0.6809,  2.9070],\n",
      "        [ 2.1059, -1.2194, -0.6744],\n",
      "        [ 2.1059, -1.2194, -0.6744],\n",
      "        [-0.3378, -1.3183,  2.2277]], grad_fn=<AddBackward0>)\n",
      "progress: 485 loss= 0.17397211492061615\n",
      "tensor([[ 2.1063, -1.2190, -0.6754],\n",
      "        [-0.7612,  0.8240,  0.2097],\n",
      "        [-2.9966,  0.6832,  2.9068],\n",
      "        [ 2.1063, -1.2190, -0.6754],\n",
      "        [ 2.1063, -1.2190, -0.6754],\n",
      "        [-0.3381, -1.3180,  2.2277]], grad_fn=<AddBackward0>)\n",
      "progress: 486 loss= 0.17386353015899658\n",
      "tensor([[ 2.1077, -1.2201, -0.6758],\n",
      "        [-0.7624,  0.8250,  0.2098],\n",
      "        [-2.9980,  0.6828,  2.9087],\n",
      "        [ 2.1077, -1.2201, -0.6758],\n",
      "        [ 2.1077, -1.2201, -0.6758],\n",
      "        [-0.3386, -1.3191,  2.2293]], grad_fn=<AddBackward0>)\n",
      "progress: 487 loss= 0.17361128330230713\n",
      "tensor([[ 2.1086, -1.2210, -0.6758],\n",
      "        [-0.7625,  0.8247,  0.2101],\n",
      "        [-2.9995,  0.6824,  2.9106],\n",
      "        [ 2.1086, -1.2210, -0.6758],\n",
      "        [ 2.1086, -1.2210, -0.6758],\n",
      "        [-0.3392, -1.3201,  2.2309]], grad_fn=<AddBackward0>)\n",
      "progress: 488 loss= 0.17350880801677704\n",
      "tensor([[ 2.1092, -1.2207, -0.6766],\n",
      "        [-0.7634,  0.8266,  0.2092],\n",
      "        [-3.0020,  0.6847,  2.9114],\n",
      "        [ 2.1092, -1.2207, -0.6766],\n",
      "        [ 2.1092, -1.2207, -0.6766],\n",
      "        [-0.3396, -1.3200,  2.2315]], grad_fn=<AddBackward0>)\n",
      "progress: 489 loss= 0.17326968908309937\n",
      "tensor([[ 2.1103, -1.2218, -0.6768],\n",
      "        [-0.7637,  0.8266,  0.2094],\n",
      "        [-3.0034,  0.6842,  2.9133],\n",
      "        [ 2.1103, -1.2218, -0.6768],\n",
      "        [ 2.1103, -1.2218, -0.6768],\n",
      "        [-0.3402, -1.3210,  2.2331]], grad_fn=<AddBackward0>)\n",
      "progress: 490 loss= 0.17312777042388916\n",
      "tensor([[ 2.1107, -1.2214, -0.6775],\n",
      "        [-0.7644,  0.8283,  0.2087],\n",
      "        [-3.0059,  0.6865,  2.9141],\n",
      "        [ 2.1107, -1.2214, -0.6775],\n",
      "        [ 2.1107, -1.2214, -0.6775],\n",
      "        [-0.3406, -1.3208,  2.2336]], grad_fn=<AddBackward0>)\n",
      "progress: 491 loss= 0.172937273979187\n",
      "tensor([[ 2.1121, -1.2224, -0.6783],\n",
      "        [-0.7649,  0.8286,  0.2087],\n",
      "        [-3.0071,  0.6862,  2.9151],\n",
      "        [ 2.1121, -1.2224, -0.6783],\n",
      "        [ 2.1121, -1.2224, -0.6783],\n",
      "        [-0.3410, -1.3218,  2.2347]], grad_fn=<AddBackward0>)\n",
      "progress: 492 loss= 0.1727580428123474\n",
      "tensor([[ 2.1124, -1.2221, -0.6788],\n",
      "        [-0.7653,  0.8300,  0.2079],\n",
      "        [-3.0097,  0.6884,  2.9159],\n",
      "        [ 2.1124, -1.2221, -0.6788],\n",
      "        [ 2.1124, -1.2221, -0.6788],\n",
      "        [-0.3415, -1.3216,  2.2353]], grad_fn=<AddBackward0>)\n",
      "progress: 493 loss= 0.17259949445724487\n",
      "tensor([[ 2.1138, -1.2232, -0.6792],\n",
      "        [-0.7662,  0.8306,  0.2080],\n",
      "        [-3.0111,  0.6880,  2.9178],\n",
      "        [ 2.1138, -1.2232, -0.6792],\n",
      "        [ 2.1138, -1.2232, -0.6792],\n",
      "        [-0.3420, -1.3227,  2.2369]], grad_fn=<AddBackward0>)\n",
      "progress: 494 loss= 0.1723855584859848\n",
      "tensor([[ 2.1134, -1.2227, -0.6793],\n",
      "        [-0.7677,  0.8319,  0.2082],\n",
      "        [-3.0150,  0.6906,  2.9196],\n",
      "        [ 2.1134, -1.2227, -0.6793],\n",
      "        [ 2.1134, -1.2227, -0.6793],\n",
      "        [-0.3438, -1.3222,  2.2384]], grad_fn=<AddBackward0>)\n",
      "progress: 495 loss= 0.172254279255867\n",
      "tensor([[ 2.1153, -1.2238, -0.6801],\n",
      "        [-0.7674,  0.8325,  0.2075],\n",
      "        [-3.0150,  0.6898,  2.9205],\n",
      "        [ 2.1153, -1.2238, -0.6801],\n",
      "        [ 2.1153, -1.2238, -0.6801],\n",
      "        [-0.3430, -1.3236,  2.2390]], grad_fn=<AddBackward0>)\n",
      "progress: 496 loss= 0.1720261573791504\n",
      "tensor([[ 2.1152, -1.2233, -0.6808],\n",
      "        [-0.7686,  0.8336,  0.2075],\n",
      "        [-3.0187,  0.6925,  2.9213],\n",
      "        [ 2.1152, -1.2233, -0.6808],\n",
      "        [ 2.1152, -1.2233, -0.6808],\n",
      "        [-0.3447, -1.3230,  2.2401]], grad_fn=<AddBackward0>)\n",
      "progress: 497 loss= 0.17191354930400848\n",
      "tensor([[ 2.1170, -1.2245, -0.6814],\n",
      "        [-0.7684,  0.8343,  0.2067],\n",
      "        [-3.0187,  0.6918,  2.9222],\n",
      "        [ 2.1170, -1.2245, -0.6814],\n",
      "        [ 2.1170, -1.2245, -0.6814],\n",
      "        [-0.3438, -1.3244,  2.2407]], grad_fn=<AddBackward0>)\n",
      "progress: 498 loss= 0.17168445885181427\n",
      "tensor([[ 2.1182, -1.2255, -0.6817],\n",
      "        [-0.7686,  0.8341,  0.2069],\n",
      "        [-3.0201,  0.6914,  2.9242],\n",
      "        [ 2.1182, -1.2255, -0.6817],\n",
      "        [ 2.1182, -1.2255, -0.6817],\n",
      "        [-0.3444, -1.3254,  2.2423]], grad_fn=<AddBackward0>)\n",
      "progress: 499 loss= 0.17154641449451447\n",
      "tensor([[ 2.1185, -1.2252, -0.6823],\n",
      "        [-0.7694,  0.8359,  0.2060],\n",
      "        [-3.0226,  0.6936,  2.9249],\n",
      "        [ 2.1185, -1.2252, -0.6823],\n",
      "        [ 2.1185, -1.2252, -0.6823],\n",
      "        [-0.3448, -1.3253,  2.2428]], grad_fn=<AddBackward0>)\n",
      "progress: 500 loss= 0.17134809494018555\n",
      "tensor([[ 2.1199, -1.2262, -0.6827],\n",
      "        [-0.7699,  0.8361,  0.2063],\n",
      "        [-3.0240,  0.6932,  2.9269],\n",
      "        [ 2.1199, -1.2262, -0.6827],\n",
      "        [ 2.1199, -1.2262, -0.6827],\n",
      "        [-0.3454, -1.3263,  2.2444]], grad_fn=<AddBackward0>)\n",
      "progress: 501 loss= 0.1711782068014145\n",
      "tensor([[ 2.1196, -1.2257, -0.6832],\n",
      "        [-0.7717,  0.8379,  0.2063],\n",
      "        [-3.0278,  0.6959,  2.9276],\n",
      "        [ 2.1196, -1.2257, -0.6832],\n",
      "        [ 2.1196, -1.2257, -0.6832],\n",
      "        [-0.3471, -1.3258,  2.2454]], grad_fn=<AddBackward0>)\n",
      "progress: 502 loss= 0.17101840674877167\n",
      "tensor([[ 2.1215, -1.2269, -0.6840],\n",
      "        [-0.7711,  0.8380,  0.2056],\n",
      "        [-3.0278,  0.6951,  2.9286],\n",
      "        [ 2.1215, -1.2269, -0.6840],\n",
      "        [ 2.1215, -1.2269, -0.6840],\n",
      "        [-0.3462, -1.3271,  2.2461]], grad_fn=<AddBackward0>)\n",
      "progress: 503 loss= 0.17082440853118896\n",
      "tensor([[ 2.1213, -1.2264, -0.6842],\n",
      "        [-0.7727,  0.8395,  0.2057],\n",
      "        [-3.0317,  0.6977,  2.9303],\n",
      "        [ 2.1213, -1.2264, -0.6842],\n",
      "        [ 2.1213, -1.2264, -0.6842],\n",
      "        [-0.3480, -1.3267,  2.2476]], grad_fn=<AddBackward0>)\n",
      "progress: 504 loss= 0.17067094147205353\n",
      "tensor([[ 2.1230, -1.2275, -0.6848],\n",
      "        [-0.7723,  0.8400,  0.2049],\n",
      "        [-3.0317,  0.6969,  2.9313],\n",
      "        [ 2.1230, -1.2275, -0.6848],\n",
      "        [ 2.1230, -1.2275, -0.6848],\n",
      "        [-0.3472, -1.3280,  2.2482]], grad_fn=<AddBackward0>)\n",
      "progress: 505 loss= 0.17046381533145905\n",
      "tensor([[ 2.1230, -1.2271, -0.6852],\n",
      "        [-0.7737,  0.8412,  0.2050],\n",
      "        [-3.0356,  0.6995,  2.9330],\n",
      "        [ 2.1230, -1.2271, -0.6852],\n",
      "        [ 2.1230, -1.2271, -0.6852],\n",
      "        [-0.3490, -1.3276,  2.2497]], grad_fn=<AddBackward0>)\n",
      "progress: 506 loss= 0.1703244000673294\n",
      "tensor([[ 2.1246, -1.2282, -0.6862],\n",
      "        [-0.7734,  0.8419,  0.2042],\n",
      "        [-3.0353,  0.6989,  2.9330],\n",
      "        [ 2.1246, -1.2282, -0.6862],\n",
      "        [ 2.1246, -1.2282, -0.6862],\n",
      "        [-0.3480, -1.3288,  2.2499]], grad_fn=<AddBackward0>)\n",
      "progress: 507 loss= 0.17011968791484833\n",
      "tensor([[ 2.1260, -1.2292, -0.6865],\n",
      "        [-0.7735,  0.8416,  0.2044],\n",
      "        [-3.0367,  0.6984,  2.9349],\n",
      "        [ 2.1260, -1.2292, -0.6865],\n",
      "        [ 2.1260, -1.2292, -0.6865],\n",
      "        [-0.3486, -1.3298,  2.2515]], grad_fn=<AddBackward0>)\n",
      "progress: 508 loss= 0.1699874848127365\n",
      "tensor([[ 2.1256, -1.2287, -0.6866],\n",
      "        [-0.7758,  0.8438,  0.2045],\n",
      "        [-3.0407,  0.7010,  2.9367],\n",
      "        [ 2.1256, -1.2287, -0.6866],\n",
      "        [ 2.1256, -1.2287, -0.6866],\n",
      "        [-0.3504, -1.3294,  2.2530]], grad_fn=<AddBackward0>)\n",
      "progress: 509 loss= 0.1697843223810196\n",
      "tensor([[ 2.1275, -1.2299, -0.6874],\n",
      "        [-0.7747,  0.8435,  0.2038],\n",
      "        [-3.0406,  0.7002,  2.9376],\n",
      "        [ 2.1275, -1.2299, -0.6874],\n",
      "        [ 2.1275, -1.2299, -0.6874],\n",
      "        [-0.3495, -1.3307,  2.2536]], grad_fn=<AddBackward0>)\n",
      "progress: 510 loss= 0.16962917149066925\n",
      "tensor([[ 2.1273, -1.2294, -0.6876],\n",
      "        [-0.7767,  0.8455,  0.2039],\n",
      "        [-3.0445,  0.7028,  2.9394],\n",
      "        [ 2.1273, -1.2294, -0.6876],\n",
      "        [ 2.1273, -1.2294, -0.6876],\n",
      "        [-0.3513, -1.3303,  2.2551]], grad_fn=<AddBackward0>)\n",
      "progress: 511 loss= 0.1694403439760208\n",
      "tensor([[ 2.1291, -1.2306, -0.6882],\n",
      "        [-0.7760,  0.8455,  0.2032],\n",
      "        [-3.0445,  0.7020,  2.9403],\n",
      "        [ 2.1291, -1.2306, -0.6882],\n",
      "        [ 2.1291, -1.2306, -0.6882],\n",
      "        [-0.3505, -1.3316,  2.2557]], grad_fn=<AddBackward0>)\n",
      "progress: 512 loss= 0.1692797690629959\n",
      "tensor([[ 2.1291, -1.2301, -0.6891],\n",
      "        [-0.7777,  0.8471,  0.2032],\n",
      "        [-3.0482,  0.7047,  2.9411],\n",
      "        [ 2.1291, -1.2301, -0.6891],\n",
      "        [ 2.1291, -1.2301, -0.6891],\n",
      "        [-0.3522, -1.3311,  2.2567]], grad_fn=<AddBackward0>)\n",
      "progress: 513 loss= 0.16910773515701294\n",
      "tensor([[ 2.1307, -1.2312, -0.6896],\n",
      "        [-0.7772,  0.8474,  0.2024],\n",
      "        [-3.0482,  0.7040,  2.9420],\n",
      "        [ 2.1307, -1.2312, -0.6896],\n",
      "        [ 2.1307, -1.2312, -0.6896],\n",
      "        [-0.3513, -1.3324,  2.2574]], grad_fn=<AddBackward0>)\n",
      "progress: 514 loss= 0.1689257025718689\n",
      "tensor([[ 2.1308, -1.2308, -0.6900],\n",
      "        [-0.7786,  0.8488,  0.2025],\n",
      "        [-3.0521,  0.7065,  2.9438],\n",
      "        [ 2.1308, -1.2308, -0.6900],\n",
      "        [ 2.1308, -1.2308, -0.6900],\n",
      "        [-0.3531, -1.3320,  2.2589]], grad_fn=<AddBackward0>)\n",
      "progress: 515 loss= 0.16876782476902008\n",
      "tensor([[ 2.1316, -1.2318, -0.6900],\n",
      "        [-0.7798,  0.8497,  0.2027],\n",
      "        [-3.0535,  0.7061,  2.9457],\n",
      "        [ 2.1316, -1.2318, -0.6900],\n",
      "        [ 2.1316, -1.2318, -0.6900],\n",
      "        [-0.3537, -1.3330,  2.2605]], grad_fn=<AddBackward0>)\n",
      "progress: 516 loss= 0.16856808960437775\n",
      "tensor([[ 2.1323, -1.2315, -0.6909],\n",
      "        [-0.7796,  0.8504,  0.2020],\n",
      "        [-3.0560,  0.7083,  2.9465],\n",
      "        [ 2.1323, -1.2315, -0.6909],\n",
      "        [ 2.1323, -1.2315, -0.6909],\n",
      "        [-0.3541, -1.3329,  2.2610]], grad_fn=<AddBackward0>)\n",
      "progress: 517 loss= 0.1684451848268509\n",
      "tensor([[ 2.1334, -1.2324, -0.6915],\n",
      "        [-0.7808,  0.8514,  0.2020],\n",
      "        [-3.0571,  0.7080,  2.9474],\n",
      "        [ 2.1334, -1.2324, -0.6915],\n",
      "        [ 2.1334, -1.2324, -0.6915],\n",
      "        [-0.3545, -1.3339,  2.2621]], grad_fn=<AddBackward0>)\n",
      "progress: 518 loss= 0.1682320237159729\n",
      "tensor([[ 2.1352, -1.2336, -0.6921],\n",
      "        [-0.7796,  0.8510,  0.2013],\n",
      "        [-3.0571,  0.7072,  2.9483],\n",
      "        [ 2.1352, -1.2336, -0.6921],\n",
      "        [ 2.1352, -1.2336, -0.6921],\n",
      "        [-0.3537, -1.3352,  2.2627]], grad_fn=<AddBackward0>)\n",
      "progress: 519 loss= 0.1681017130613327\n",
      "tensor([[ 2.1351, -1.2331, -0.6924],\n",
      "        [-0.7817,  0.8531,  0.2014],\n",
      "        [-3.0610,  0.7097,  2.9501],\n",
      "        [ 2.1351, -1.2331, -0.6924],\n",
      "        [ 2.1351, -1.2331, -0.6924],\n",
      "        [-0.3555, -1.3348,  2.2642]], grad_fn=<AddBackward0>)\n",
      "progress: 520 loss= 0.1678924411535263\n",
      "tensor([[ 2.1367, -1.2342, -0.6929],\n",
      "        [-0.7808,  0.8529,  0.2006],\n",
      "        [-3.0610,  0.7090,  2.9510],\n",
      "        [ 2.1367, -1.2342, -0.6929],\n",
      "        [ 2.1367, -1.2342, -0.6929],\n",
      "        [-0.3546, -1.3361,  2.2649]], grad_fn=<AddBackward0>)\n",
      "progress: 521 loss= 0.1677483320236206\n",
      "tensor([[ 2.1368, -1.2338, -0.6934],\n",
      "        [-0.7827,  0.8547,  0.2008],\n",
      "        [-3.0649,  0.7115,  2.9528],\n",
      "        [ 2.1368, -1.2338, -0.6934],\n",
      "        [ 2.1368, -1.2338, -0.6934],\n",
      "        [-0.3564, -1.3357,  2.2664]], grad_fn=<AddBackward0>)\n",
      "progress: 522 loss= 0.167558953166008\n",
      "tensor([[ 2.1377, -1.2347, -0.6939],\n",
      "        [-0.7834,  0.8552,  0.2009],\n",
      "        [-3.0660,  0.7112,  2.9537],\n",
      "        [ 2.1377, -1.2347, -0.6939],\n",
      "        [ 2.1377, -1.2347, -0.6939],\n",
      "        [-0.3568, -1.3366,  2.2675]], grad_fn=<AddBackward0>)\n",
      "progress: 523 loss= 0.1674051284790039\n",
      "tensor([[ 2.1384, -1.2344, -0.6947],\n",
      "        [-0.7836,  0.8563,  0.2001],\n",
      "        [-3.0685,  0.7134,  2.9545],\n",
      "        [ 2.1384, -1.2344, -0.6947],\n",
      "        [ 2.1384, -1.2344, -0.6947],\n",
      "        [-0.3572, -1.3365,  2.2680]], grad_fn=<AddBackward0>)\n",
      "progress: 524 loss= 0.16724036633968353\n",
      "tensor([[ 2.1394, -1.2354, -0.6948],\n",
      "        [-0.7846,  0.8571,  0.2002],\n",
      "        [-3.0699,  0.7130,  2.9564],\n",
      "        [ 2.1394, -1.2354, -0.6948],\n",
      "        [ 2.1394, -1.2354, -0.6948],\n",
      "        [-0.3578, -1.3375,  2.2696]], grad_fn=<AddBackward0>)\n",
      "progress: 525 loss= 0.16704130172729492\n",
      "tensor([[ 2.1399, -1.2351, -0.6955],\n",
      "        [-0.7846,  0.8580,  0.1994],\n",
      "        [-3.0724,  0.7152,  2.9571],\n",
      "        [ 2.1399, -1.2351, -0.6955],\n",
      "        [ 2.1399, -1.2351, -0.6955],\n",
      "        [-0.3582, -1.3374,  2.2701]], grad_fn=<AddBackward0>)\n",
      "progress: 526 loss= 0.1669159084558487\n",
      "tensor([[ 2.1411, -1.2361, -0.6958],\n",
      "        [-0.7857,  0.8590,  0.1996],\n",
      "        [-3.0737,  0.7148,  2.9590],\n",
      "        [ 2.1411, -1.2361, -0.6958],\n",
      "        [ 2.1411, -1.2361, -0.6958],\n",
      "        [-0.3587, -1.3384,  2.2717]], grad_fn=<AddBackward0>)\n",
      "progress: 527 loss= 0.16669093072414398\n",
      "tensor([[ 2.1427, -1.2372, -0.6966],\n",
      "        [-0.7845,  0.8584,  0.1988],\n",
      "        [-3.0735,  0.7142,  2.9590],\n",
      "        [ 2.1427, -1.2372, -0.6966],\n",
      "        [ 2.1427, -1.2372, -0.6966],\n",
      "        [-0.3577, -1.3397,  2.2719]], grad_fn=<AddBackward0>)\n",
      "progress: 528 loss= 0.16659723222255707\n",
      "tensor([[ 2.1428, -1.2368, -0.6970],\n",
      "        [-0.7867,  0.8606,  0.1989],\n",
      "        [-3.0774,  0.7166,  2.9610],\n",
      "        [ 2.1428, -1.2368, -0.6970],\n",
      "        [ 2.1428, -1.2368, -0.6970],\n",
      "        [-0.3596, -1.3393,  2.2736]], grad_fn=<AddBackward0>)\n",
      "progress: 529 loss= 0.16636379063129425\n",
      "tensor([[ 2.1436, -1.2378, -0.6969],\n",
      "        [-0.7871,  0.8607,  0.1991],\n",
      "        [-3.0788,  0.7162,  2.9629],\n",
      "        [ 2.1436, -1.2378, -0.6969],\n",
      "        [ 2.1436, -1.2378, -0.6969],\n",
      "        [-0.3601, -1.3403,  2.2752]], grad_fn=<AddBackward0>)\n",
      "progress: 530 loss= 0.16624176502227783\n",
      "tensor([[ 2.1443, -1.2375, -0.6978],\n",
      "        [-0.7876,  0.8622,  0.1983],\n",
      "        [-3.0813,  0.7184,  2.9637],\n",
      "        [ 2.1443, -1.2375, -0.6978],\n",
      "        [ 2.1443, -1.2375, -0.6978],\n",
      "        [-0.3605, -1.3402,  2.2758]], grad_fn=<AddBackward0>)\n",
      "progress: 531 loss= 0.16604770720005035\n",
      "tensor([[ 2.1453, -1.2384, -0.6981],\n",
      "        [-0.7883,  0.8626,  0.1984],\n",
      "        [-3.0824,  0.7181,  2.9646],\n",
      "        [ 2.1453, -1.2384, -0.6981],\n",
      "        [ 2.1453, -1.2384, -0.6981],\n",
      "        [-0.3609, -1.3411,  2.2769]], grad_fn=<AddBackward0>)\n",
      "progress: 532 loss= 0.16589908301830292\n",
      "tensor([[ 2.1458, -1.2381, -0.6988],\n",
      "        [-0.7886,  0.8639,  0.1976],\n",
      "        [-3.0849,  0.7202,  2.9657],\n",
      "        [ 2.1458, -1.2381, -0.6988],\n",
      "        [ 2.1458, -1.2381, -0.6988],\n",
      "        [-0.3614, -1.3411,  2.2777]], grad_fn=<AddBackward0>)\n",
      "progress: 533 loss= 0.16573023796081543\n",
      "tensor([[ 2.1470, -1.2391, -0.6990],\n",
      "        [-0.7895,  0.8646,  0.1977],\n",
      "        [-3.0863,  0.7198,  2.9676],\n",
      "        [ 2.1470, -1.2391, -0.6990],\n",
      "        [ 2.1470, -1.2391, -0.6990],\n",
      "        [-0.3619, -1.3421,  2.2793]], grad_fn=<AddBackward0>)\n",
      "progress: 534 loss= 0.16553111374378204\n",
      "tensor([[ 2.1473, -1.2388, -0.6996],\n",
      "        [-0.7895,  0.8655,  0.1971],\n",
      "        [-3.0888,  0.7220,  2.9684],\n",
      "        [ 2.1473, -1.2388, -0.6996],\n",
      "        [ 2.1473, -1.2388, -0.6996],\n",
      "        [-0.3623, -1.3420,  2.2798]], grad_fn=<AddBackward0>)\n",
      "progress: 535 loss= 0.16541965305805206\n",
      "tensor([[ 2.1487, -1.2398, -0.7002],\n",
      "        [-0.7907,  0.8665,  0.1971],\n",
      "        [-3.0899,  0.7217,  2.9693],\n",
      "        [ 2.1487, -1.2398, -0.7002],\n",
      "        [ 2.1487, -1.2398, -0.7002],\n",
      "        [-0.3627, -1.3429,  2.2809]], grad_fn=<AddBackward0>)\n",
      "progress: 536 loss= 0.16519467532634735\n",
      "tensor([[ 2.1495, -1.2407, -0.7002],\n",
      "        [-0.7907,  0.8662,  0.1973],\n",
      "        [-3.0913,  0.7212,  2.9715],\n",
      "        [ 2.1495, -1.2407, -0.7002],\n",
      "        [ 2.1495, -1.2407, -0.7002],\n",
      "        [-0.3633, -1.3440,  2.2828]], grad_fn=<AddBackward0>)\n",
      "progress: 537 loss= 0.16509868204593658\n",
      "tensor([[ 2.1501, -1.2405, -0.7007],\n",
      "        [-0.7917,  0.8681,  0.1968],\n",
      "        [-3.0938,  0.7234,  2.9725],\n",
      "        [ 2.1501, -1.2405, -0.7007],\n",
      "        [ 2.1501, -1.2405, -0.7007],\n",
      "        [-0.3638, -1.3439,  2.2836]], grad_fn=<AddBackward0>)\n",
      "progress: 538 loss= 0.16488276422023773\n",
      "tensor([[ 2.1512, -1.2414, -0.7012],\n",
      "        [-0.7919,  0.8681,  0.1966],\n",
      "        [-3.0950,  0.7231,  2.9734],\n",
      "        [ 2.1512, -1.2414, -0.7012],\n",
      "        [ 2.1512, -1.2414, -0.7012],\n",
      "        [-0.3642, -1.3449,  2.2847]], grad_fn=<AddBackward0>)\n",
      "progress: 539 loss= 0.16475549340248108\n",
      "tensor([[ 2.1517, -1.2411, -0.7018],\n",
      "        [-0.7925,  0.8698,  0.1958],\n",
      "        [-3.0975,  0.7252,  2.9745],\n",
      "        [ 2.1517, -1.2411, -0.7018],\n",
      "        [ 2.1517, -1.2411, -0.7018],\n",
      "        [-0.3646, -1.3448,  2.2855]], grad_fn=<AddBackward0>)\n",
      "progress: 540 loss= 0.16455720365047455\n",
      "tensor([[ 2.1529, -1.2421, -0.7022],\n",
      "        [-0.7931,  0.8700,  0.1959],\n",
      "        [-3.0986,  0.7249,  2.9754],\n",
      "        [ 2.1529, -1.2421, -0.7022],\n",
      "        [ 2.1529, -1.2421, -0.7022],\n",
      "        [-0.3651, -1.3457,  2.2866]], grad_fn=<AddBackward0>)\n",
      "progress: 541 loss= 0.1644132286310196\n",
      "tensor([[ 2.1532, -1.2418, -0.7028],\n",
      "        [-0.7935,  0.8714,  0.1951],\n",
      "        [-3.1012,  0.7271,  2.9765],\n",
      "        [ 2.1532, -1.2418, -0.7028],\n",
      "        [ 2.1532, -1.2418, -0.7028],\n",
      "        [-0.3655, -1.3457,  2.2874]], grad_fn=<AddBackward0>)\n",
      "progress: 542 loss= 0.1642477959394455\n",
      "tensor([[ 2.1545, -1.2428, -0.7032],\n",
      "        [-0.7943,  0.8720,  0.1953],\n",
      "        [-3.1025,  0.7266,  2.9783],\n",
      "        [ 2.1545, -1.2428, -0.7032],\n",
      "        [ 2.1545, -1.2428, -0.7032],\n",
      "        [-0.3660, -1.3467,  2.2890]], grad_fn=<AddBackward0>)\n",
      "progress: 543 loss= 0.1640477031469345\n",
      "tensor([[ 2.1541, -1.2423, -0.7032],\n",
      "        [-0.7958,  0.8733,  0.1955],\n",
      "        [-3.1063,  0.7291,  2.9801],\n",
      "        [ 2.1541, -1.2423, -0.7032],\n",
      "        [ 2.1541, -1.2423, -0.7032],\n",
      "        [-0.3678, -1.3463,  2.2905]], grad_fn=<AddBackward0>)\n",
      "progress: 544 loss= 0.16393698751926422\n",
      "tensor([[ 2.1560, -1.2435, -0.7041],\n",
      "        [-0.7955,  0.8739,  0.1946],\n",
      "        [-3.1061,  0.7285,  2.9800],\n",
      "        [ 2.1560, -1.2435, -0.7041],\n",
      "        [ 2.1560, -1.2435, -0.7041],\n",
      "        [-0.3668, -1.3475,  2.2906]], grad_fn=<AddBackward0>)\n",
      "progress: 545 loss= 0.16372844576835632\n",
      "tensor([[ 2.1558, -1.2430, -0.7043],\n",
      "        [-0.7967,  0.8750,  0.1947],\n",
      "        [-3.1100,  0.7309,  2.9820],\n",
      "        [ 2.1558, -1.2430, -0.7043],\n",
      "        [ 2.1558, -1.2430, -0.7043],\n",
      "        [-0.3686, -1.3472,  2.2924]], grad_fn=<AddBackward0>)\n",
      "progress: 546 loss= 0.16361479461193085\n",
      "tensor([[ 2.1575, -1.2442, -0.7047],\n",
      "        [-0.7965,  0.8756,  0.1942],\n",
      "        [-3.1100,  0.7301,  2.9832],\n",
      "        [ 2.1575, -1.2442, -0.7047],\n",
      "        [ 2.1575, -1.2442, -0.7047],\n",
      "        [-0.3678, -1.3485,  2.2933]], grad_fn=<AddBackward0>)\n",
      "progress: 547 loss= 0.1634068638086319\n",
      "tensor([[ 2.1587, -1.2451, -0.7052],\n",
      "        [-0.7967,  0.8755,  0.1941],\n",
      "        [-3.1111,  0.7298,  2.9842],\n",
      "        [ 2.1587, -1.2451, -0.7052],\n",
      "        [ 2.1587, -1.2451, -0.7052],\n",
      "        [-0.3683, -1.3495,  2.2943]], grad_fn=<AddBackward0>)\n",
      "progress: 548 loss= 0.16328322887420654\n",
      "tensor([[ 2.1590, -1.2448, -0.7057],\n",
      "        [-0.7974,  0.8773,  0.1933],\n",
      "        [-3.1136,  0.7320,  2.9852],\n",
      "        [ 2.1590, -1.2448, -0.7057],\n",
      "        [ 2.1590, -1.2448, -0.7057],\n",
      "        [-0.3687, -1.3494,  2.2952]], grad_fn=<AddBackward0>)\n",
      "progress: 549 loss= 0.16308750212192535\n",
      "tensor([[ 2.1603, -1.2458, -0.7061],\n",
      "        [-0.7979,  0.8774,  0.1936],\n",
      "        [-3.1150,  0.7315,  2.9871],\n",
      "        [ 2.1603, -1.2458, -0.7061],\n",
      "        [ 2.1603, -1.2458, -0.7061],\n",
      "        [-0.3692, -1.3504,  2.2967]], grad_fn=<AddBackward0>)\n",
      "progress: 550 loss= 0.16293247044086456\n",
      "tensor([[ 2.1599, -1.2453, -0.7063],\n",
      "        [-0.7997,  0.8792,  0.1936],\n",
      "        [-3.1186,  0.7341,  2.9878],\n",
      "        [ 2.1599, -1.2453, -0.7063],\n",
      "        [ 2.1599, -1.2453, -0.7063],\n",
      "        [-0.3709, -1.3500,  2.2977]], grad_fn=<AddBackward0>)\n",
      "progress: 551 loss= 0.16279439628124237\n",
      "tensor([[ 2.1618, -1.2465, -0.7071],\n",
      "        [-0.7991,  0.8794,  0.1928],\n",
      "        [-3.1186,  0.7334,  2.9890],\n",
      "        [ 2.1618, -1.2465, -0.7071],\n",
      "        [ 2.1618, -1.2465, -0.7071],\n",
      "        [-0.3701, -1.3513,  2.2986]], grad_fn=<AddBackward0>)\n",
      "progress: 552 loss= 0.16259504854679108\n",
      "tensor([[ 2.1615, -1.2460, -0.7070],\n",
      "        [-0.8007,  0.8808,  0.1932],\n",
      "        [-3.1225,  0.7358,  2.9910],\n",
      "        [ 2.1615, -1.2460, -0.7070],\n",
      "        [ 2.1615, -1.2460, -0.7070],\n",
      "        [-0.3719, -1.3509,  2.3004]], grad_fn=<AddBackward0>)\n",
      "progress: 553 loss= 0.1624745875597\n",
      "tensor([[ 2.1633, -1.2471, -0.7080],\n",
      "        [-0.8003,  0.8813,  0.1921],\n",
      "        [-3.1222,  0.7352,  2.9910],\n",
      "        [ 2.1633, -1.2471, -0.7080],\n",
      "        [ 2.1633, -1.2471, -0.7080],\n",
      "        [-0.3709, -1.3522,  2.3005]], grad_fn=<AddBackward0>)\n",
      "progress: 554 loss= 0.16227127611637115\n",
      "tensor([[ 2.1632, -1.2467, -0.7082],\n",
      "        [-0.8016,  0.8824,  0.1922],\n",
      "        [-3.1261,  0.7376,  2.9930],\n",
      "        [ 2.1632, -1.2467, -0.7082],\n",
      "        [ 2.1632, -1.2467, -0.7082],\n",
      "        [-0.3727, -1.3518,  2.3023]], grad_fn=<AddBackward0>)\n",
      "progress: 555 loss= 0.1621430516242981\n",
      "tensor([[ 2.1648, -1.2478, -0.7089],\n",
      "        [-0.8014,  0.8831,  0.1914],\n",
      "        [-3.1258,  0.7370,  2.9930],\n",
      "        [ 2.1648, -1.2478, -0.7089],\n",
      "        [ 2.1648, -1.2478, -0.7089],\n",
      "        [-0.3717, -1.3531,  2.3024]], grad_fn=<AddBackward0>)\n",
      "progress: 556 loss= 0.16195888817310333\n",
      "tensor([[ 2.1662, -1.2488, -0.7092],\n",
      "        [-0.8015,  0.8829,  0.1916],\n",
      "        [-3.1272,  0.7365,  2.9951],\n",
      "        [ 2.1662, -1.2488, -0.7092],\n",
      "        [ 2.1662, -1.2488, -0.7092],\n",
      "        [-0.3723, -1.3542,  2.3043]], grad_fn=<AddBackward0>)\n",
      "progress: 557 loss= 0.16182075440883636\n",
      "tensor([[ 2.1657, -1.2483, -0.7093],\n",
      "        [-0.8036,  0.8850,  0.1917],\n",
      "        [-3.1310,  0.7390,  2.9968],\n",
      "        [ 2.1657, -1.2483, -0.7093],\n",
      "        [ 2.1657, -1.2483, -0.7093],\n",
      "        [-0.3741, -1.3538,  2.3057]], grad_fn=<AddBackward0>)\n",
      "progress: 558 loss= 0.16163600981235504\n",
      "tensor([[ 2.1676, -1.2495, -0.7100],\n",
      "        [-0.8027,  0.8848,  0.1910],\n",
      "        [-3.1309,  0.7382,  2.9977],\n",
      "        [ 2.1676, -1.2495, -0.7100],\n",
      "        [ 2.1676, -1.2495, -0.7100],\n",
      "        [-0.3732, -1.3551,  2.3063]], grad_fn=<AddBackward0>)\n",
      "progress: 559 loss= 0.16148914396762848\n",
      "tensor([[ 2.1674, -1.2490, -0.7104],\n",
      "        [-0.8046,  0.8867,  0.1910],\n",
      "        [-3.1345,  0.7408,  2.9985],\n",
      "        [ 2.1674, -1.2490, -0.7104],\n",
      "        [ 2.1674, -1.2490, -0.7104],\n",
      "        [-0.3748, -1.3546,  2.3073]], grad_fn=<AddBackward0>)\n",
      "progress: 560 loss= 0.1613372415304184\n",
      "tensor([[ 2.1691, -1.2501, -0.7110],\n",
      "        [-0.8039,  0.8868,  0.1903],\n",
      "        [-3.1345,  0.7400,  2.9997],\n",
      "        [ 2.1691, -1.2501, -0.7110],\n",
      "        [ 2.1691, -1.2501, -0.7110],\n",
      "        [-0.3740, -1.3560,  2.3082]], grad_fn=<AddBackward0>)\n",
      "progress: 561 loss= 0.1611616462469101\n",
      "tensor([[ 2.1690, -1.2497, -0.7111],\n",
      "        [-0.8055,  0.8883,  0.1906],\n",
      "        [-3.1384,  0.7424,  3.0017],\n",
      "        [ 2.1690, -1.2497, -0.7111],\n",
      "        [ 2.1690, -1.2497, -0.7111],\n",
      "        [-0.3758, -1.3556,  2.3100]], grad_fn=<AddBackward0>)\n",
      "progress: 562 loss= 0.16101545095443726\n",
      "tensor([[ 2.1706, -1.2507, -0.7119],\n",
      "        [-0.8050,  0.8887,  0.1896],\n",
      "        [-3.1381,  0.7418,  3.0016],\n",
      "        [ 2.1706, -1.2507, -0.7119],\n",
      "        [ 2.1706, -1.2507, -0.7119],\n",
      "        [-0.3749, -1.3569,  2.3101]], grad_fn=<AddBackward0>)\n",
      "progress: 563 loss= 0.1608416885137558\n",
      "tensor([[ 2.1707, -1.2503, -0.7122],\n",
      "        [-0.8064,  0.8899,  0.1897],\n",
      "        [-3.1420,  0.7442,  3.0036],\n",
      "        [ 2.1707, -1.2503, -0.7122],\n",
      "        [ 2.1707, -1.2503, -0.7122],\n",
      "        [-0.3767, -1.3565,  2.3119]], grad_fn=<AddBackward0>)\n",
      "progress: 564 loss= 0.16069498658180237\n",
      "tensor([[ 2.1715, -1.2513, -0.7122],\n",
      "        [-0.8076,  0.8908,  0.1900],\n",
      "        [-3.1433,  0.7438,  3.0055],\n",
      "        [ 2.1715, -1.2513, -0.7122],\n",
      "        [ 2.1715, -1.2513, -0.7122],\n",
      "        [-0.3771, -1.3575,  2.3134]], grad_fn=<AddBackward0>)\n",
      "progress: 565 loss= 0.16050684452056885\n",
      "tensor([[ 2.1734, -1.2524, -0.7131],\n",
      "        [-0.8062,  0.8903,  0.1891],\n",
      "        [-3.1430,  0.7432,  3.0054],\n",
      "        [ 2.1734, -1.2524, -0.7131],\n",
      "        [ 2.1734, -1.2524, -0.7131],\n",
      "        [-0.3762, -1.3588,  2.3136]], grad_fn=<AddBackward0>)\n",
      "progress: 566 loss= 0.1604064553976059\n",
      "tensor([[ 2.1732, -1.2519, -0.7134],\n",
      "        [-0.8085,  0.8925,  0.1892],\n",
      "        [-3.1469,  0.7456,  3.0074],\n",
      "        [ 2.1732, -1.2519, -0.7134],\n",
      "        [ 2.1732, -1.2519, -0.7134],\n",
      "        [-0.3780, -1.3584,  2.3153]], grad_fn=<AddBackward0>)\n",
      "progress: 567 loss= 0.16019172966480255\n",
      "tensor([[ 2.1748, -1.2531, -0.7137],\n",
      "        [-0.8075,  0.8922,  0.1888],\n",
      "        [-3.1469,  0.7448,  3.0086],\n",
      "        [ 2.1748, -1.2531, -0.7137],\n",
      "        [ 2.1748, -1.2531, -0.7137],\n",
      "        [-0.3772, -1.3598,  2.3162]], grad_fn=<AddBackward0>)\n",
      "progress: 568 loss= 0.1600775420665741\n",
      "tensor([[ 2.1748, -1.2526, -0.7144],\n",
      "        [-0.8094,  0.8941,  0.1885],\n",
      "        [-3.1504,  0.7474,  3.0093],\n",
      "        [ 2.1748, -1.2526, -0.7144],\n",
      "        [ 2.1748, -1.2526, -0.7144],\n",
      "        [-0.3788, -1.3593,  2.3172]], grad_fn=<AddBackward0>)\n",
      "progress: 569 loss= 0.1598881334066391\n",
      "tensor([[ 2.1763, -1.2537, -0.7147],\n",
      "        [-0.8086,  0.8941,  0.1878],\n",
      "        [-3.1504,  0.7466,  3.0105],\n",
      "        [ 2.1763, -1.2537, -0.7147],\n",
      "        [ 2.1763, -1.2537, -0.7147],\n",
      "        [-0.3780, -1.3607,  2.3181]], grad_fn=<AddBackward0>)\n",
      "progress: 570 loss= 0.1597399115562439\n",
      "tensor([[ 2.1764, -1.2533, -0.7151],\n",
      "        [-0.8103,  0.8957,  0.1881],\n",
      "        [-3.1542,  0.7490,  3.0122],\n",
      "        [ 2.1764, -1.2533, -0.7151],\n",
      "        [ 2.1764, -1.2533, -0.7151],\n",
      "        [-0.3797, -1.3603,  2.3195]], grad_fn=<AddBackward0>)\n",
      "progress: 571 loss= 0.15957923233509064\n",
      "tensor([[ 2.1773, -1.2542, -0.7154],\n",
      "        [-0.8111,  0.8963,  0.1880],\n",
      "        [-3.1553,  0.7487,  3.0131],\n",
      "        [ 2.1773, -1.2542, -0.7154],\n",
      "        [ 2.1773, -1.2542, -0.7154],\n",
      "        [-0.3801, -1.3613,  2.3206]], grad_fn=<AddBackward0>)\n",
      "progress: 572 loss= 0.15942400693893433\n",
      "tensor([[ 2.1779, -1.2539, -0.7162],\n",
      "        [-0.8112,  0.8974,  0.1872],\n",
      "        [-3.1578,  0.7508,  3.0141],\n",
      "        [ 2.1779, -1.2539, -0.7162],\n",
      "        [ 2.1779, -1.2539, -0.7162],\n",
      "        [-0.3805, -1.3612,  2.3214]], grad_fn=<AddBackward0>)\n",
      "progress: 573 loss= 0.15927544236183167\n",
      "tensor([[ 2.1789, -1.2549, -0.7163],\n",
      "        [-0.8123,  0.8982,  0.1874],\n",
      "        [-3.1591,  0.7504,  3.0160],\n",
      "        [ 2.1789, -1.2549, -0.7163],\n",
      "        [ 2.1789, -1.2549, -0.7163],\n",
      "        [-0.3810, -1.3622,  2.3230]], grad_fn=<AddBackward0>)\n",
      "progress: 574 loss= 0.15907539427280426\n",
      "tensor([[ 2.1793, -1.2545, -0.7170],\n",
      "        [-0.8121,  0.8990,  0.1866],\n",
      "        [-3.1613,  0.7527,  3.0158],\n",
      "        [ 2.1793, -1.2545, -0.7170],\n",
      "        [ 2.1793, -1.2545, -0.7170],\n",
      "        [-0.3813, -1.3620,  2.3230]], grad_fn=<AddBackward0>)\n",
      "progress: 575 loss= 0.15899547934532166\n",
      "tensor([[ 2.1806, -1.2555, -0.7174],\n",
      "        [-0.8132,  0.8999,  0.1867],\n",
      "        [-3.1626,  0.7521,  3.0179],\n",
      "        [ 2.1806, -1.2555, -0.7174],\n",
      "        [ 2.1806, -1.2555, -0.7174],\n",
      "        [-0.3818, -1.3631,  2.3248]], grad_fn=<AddBackward0>)\n",
      "progress: 576 loss= 0.15876585245132446\n",
      "tensor([[ 2.1820, -1.2566, -0.7176],\n",
      "        [-0.8122,  0.8995,  0.1862],\n",
      "        [-3.1626,  0.7513,  3.0191],\n",
      "        [ 2.1820, -1.2566, -0.7176],\n",
      "        [ 2.1820, -1.2566, -0.7176],\n",
      "        [-0.3810, -1.3645,  2.3257]], grad_fn=<AddBackward0>)\n",
      "progress: 577 loss= 0.15866869688034058\n",
      "tensor([[ 2.1821, -1.2562, -0.7183],\n",
      "        [-0.8142,  0.9015,  0.1860],\n",
      "        [-3.1662,  0.7539,  3.0199],\n",
      "        [ 2.1821, -1.2562, -0.7183],\n",
      "        [ 2.1821, -1.2562, -0.7183],\n",
      "        [-0.3826, -1.3640,  2.3267]], grad_fn=<AddBackward0>)\n",
      "progress: 578 loss= 0.15847322344779968\n",
      "tensor([[ 2.1830, -1.2571, -0.7183],\n",
      "        [-0.8147,  0.9018,  0.1862],\n",
      "        [-3.1675,  0.7534,  3.0220],\n",
      "        [ 2.1830, -1.2571, -0.7183],\n",
      "        [ 2.1830, -1.2571, -0.7183],\n",
      "        [-0.3832, -1.3651,  2.3285]], grad_fn=<AddBackward0>)\n",
      "progress: 579 loss= 0.15833167731761932\n",
      "tensor([[ 2.1835, -1.2568, -0.7190],\n",
      "        [-0.8151,  0.9031,  0.1855],\n",
      "        [-3.1699,  0.7556,  3.0227],\n",
      "        [ 2.1835, -1.2568, -0.7190],\n",
      "        [ 2.1835, -1.2568, -0.7190],\n",
      "        [-0.3835, -1.3650,  2.3291]], grad_fn=<AddBackward0>)\n",
      "progress: 580 loss= 0.15816934406757355\n",
      "tensor([[ 2.1847, -1.2578, -0.7194],\n",
      "        [-0.8158,  0.9037,  0.1855],\n",
      "        [-3.1710,  0.7552,  3.0236],\n",
      "        [ 2.1847, -1.2578, -0.7194],\n",
      "        [ 2.1847, -1.2578, -0.7194],\n",
      "        [-0.3839, -1.3660,  2.3301]], grad_fn=<AddBackward0>)\n",
      "progress: 581 loss= 0.15801461040973663\n",
      "tensor([[ 2.1850, -1.2574, -0.7200],\n",
      "        [-0.8160,  0.9048,  0.1847],\n",
      "        [-3.1734,  0.7573,  3.0247],\n",
      "        [ 2.1850, -1.2574, -0.7200],\n",
      "        [ 2.1850, -1.2574, -0.7200],\n",
      "        [-0.3843, -1.3659,  2.3309]], grad_fn=<AddBackward0>)\n",
      "progress: 582 loss= 0.15787442028522491\n",
      "tensor([[ 2.1863, -1.2585, -0.7201],\n",
      "        [-0.8170,  0.9055,  0.1851],\n",
      "        [-3.1748,  0.7568,  3.0268],\n",
      "        [ 2.1863, -1.2585, -0.7201],\n",
      "        [ 2.1863, -1.2585, -0.7201],\n",
      "        [-0.3849, -1.3670,  2.3327]], grad_fn=<AddBackward0>)\n",
      "progress: 583 loss= 0.15767832100391388\n",
      "tensor([[ 2.1865, -1.2581, -0.7209],\n",
      "        [-0.8169,  0.9064,  0.1841],\n",
      "        [-3.1770,  0.7591,  3.0266],\n",
      "        [ 2.1865, -1.2581, -0.7209],\n",
      "        [ 2.1865, -1.2581, -0.7209],\n",
      "        [-0.3851, -1.3668,  2.3328]], grad_fn=<AddBackward0>)\n",
      "progress: 584 loss= 0.1575891524553299\n",
      "tensor([[ 2.1878, -1.2591, -0.7211],\n",
      "        [-0.8180,  0.9073,  0.1842],\n",
      "        [-3.1783,  0.7586,  3.0287],\n",
      "        [ 2.1878, -1.2591, -0.7211],\n",
      "        [ 2.1878, -1.2591, -0.7211],\n",
      "        [-0.3857, -1.3679,  2.3346]], grad_fn=<AddBackward0>)\n",
      "progress: 585 loss= 0.1573607325553894\n",
      "tensor([[ 2.1887, -1.2601, -0.7212],\n",
      "        [-0.8182,  0.9071,  0.1845],\n",
      "        [-3.1796,  0.7581,  3.0305],\n",
      "        [ 2.1887, -1.2601, -0.7212],\n",
      "        [ 2.1887, -1.2601, -0.7212],\n",
      "        [-0.3861, -1.3689,  2.3361]], grad_fn=<AddBackward0>)\n",
      "progress: 586 loss= 0.15726740658283234\n",
      "tensor([[ 2.1892, -1.2597, -0.7221],\n",
      "        [-0.8189,  0.9089,  0.1835],\n",
      "        [-3.1818,  0.7604,  3.0303],\n",
      "        [ 2.1892, -1.2597, -0.7221],\n",
      "        [ 2.1892, -1.2597, -0.7221],\n",
      "        [-0.3864, -1.3687,  2.3362]], grad_fn=<AddBackward0>)\n",
      "progress: 587 loss= 0.15708281099796295\n",
      "tensor([[ 2.1904, -1.2607, -0.7224],\n",
      "        [-0.8193,  0.9091,  0.1837],\n",
      "        [-3.1831,  0.7599,  3.0324],\n",
      "        [ 2.1904, -1.2607, -0.7224],\n",
      "        [ 2.1904, -1.2607, -0.7224],\n",
      "        [-0.3869, -1.3698,  2.3380]], grad_fn=<AddBackward0>)\n",
      "progress: 588 loss= 0.15693299472332\n",
      "tensor([[ 2.1907, -1.2604, -0.7229],\n",
      "        [-0.8198,  0.9105,  0.1829],\n",
      "        [-3.1855,  0.7620,  3.0332],\n",
      "        [ 2.1907, -1.2604, -0.7229],\n",
      "        [ 2.1907, -1.2604, -0.7229],\n",
      "        [-0.3873, -1.3697,  2.3385]], grad_fn=<AddBackward0>)\n",
      "progress: 589 loss= 0.1567767709493637\n",
      "tensor([[ 2.1920, -1.2614, -0.7233],\n",
      "        [-0.8205,  0.9110,  0.1830],\n",
      "        [-3.1865,  0.7617,  3.0341],\n",
      "        [ 2.1920, -1.2614, -0.7233],\n",
      "        [ 2.1920, -1.2614, -0.7233],\n",
      "        [-0.3877, -1.3707,  2.3396]], grad_fn=<AddBackward0>)\n",
      "progress: 590 loss= 0.15662170946598053\n",
      "tensor([[ 2.1921, -1.2610, -0.7238],\n",
      "        [-0.8207,  0.9122,  0.1822],\n",
      "        [-3.1890,  0.7638,  3.0351],\n",
      "        [ 2.1921, -1.2610, -0.7238],\n",
      "        [ 2.1921, -1.2610, -0.7238],\n",
      "        [-0.3881, -1.3706,  2.3404]], grad_fn=<AddBackward0>)\n",
      "progress: 591 loss= 0.15649129450321198\n",
      "tensor([[ 2.1934, -1.2620, -0.7240],\n",
      "        [-0.8217,  0.9129,  0.1826],\n",
      "        [-3.1903,  0.7633,  3.0372],\n",
      "        [ 2.1934, -1.2620, -0.7240],\n",
      "        [ 2.1934, -1.2620, -0.7240],\n",
      "        [-0.3886, -1.3717,  2.3422]], grad_fn=<AddBackward0>)\n",
      "progress: 592 loss= 0.15629540383815765\n",
      "tensor([[ 2.1932, -1.2615, -0.7244],\n",
      "        [-0.8230,  0.9141,  0.1825],\n",
      "        [-3.1938,  0.7658,  3.0379],\n",
      "        [ 2.1932, -1.2615, -0.7244],\n",
      "        [ 2.1932, -1.2615, -0.7244],\n",
      "        [-0.3902, -1.3712,  2.3432]], grad_fn=<AddBackward0>)\n",
      "progress: 593 loss= 0.15619772672653198\n",
      "tensor([[ 2.1949, -1.2626, -0.7250],\n",
      "        [-0.8227,  0.9147,  0.1817],\n",
      "        [-3.1938,  0.7650,  3.0391],\n",
      "        [ 2.1949, -1.2626, -0.7250],\n",
      "        [ 2.1949, -1.2626, -0.7250],\n",
      "        [-0.3894, -1.3726,  2.3441]], grad_fn=<AddBackward0>)\n",
      "progress: 594 loss= 0.15598183870315552\n",
      "tensor([[ 2.1961, -1.2636, -0.7252],\n",
      "        [-0.8228,  0.9144,  0.1820],\n",
      "        [-3.1951,  0.7645,  3.0410],\n",
      "        [ 2.1961, -1.2636, -0.7252],\n",
      "        [ 2.1961, -1.2636, -0.7252],\n",
      "        [-0.3899, -1.3737,  2.3456]], grad_fn=<AddBackward0>)\n",
      "progress: 595 loss= 0.155877485871315\n",
      "tensor([[ 2.1963, -1.2632, -0.7259],\n",
      "        [-0.8236,  0.9163,  0.1810],\n",
      "        [-3.1973,  0.7668,  3.0407],\n",
      "        [ 2.1963, -1.2632, -0.7259],\n",
      "        [ 2.1963, -1.2632, -0.7259],\n",
      "        [-0.3901, -1.3735,  2.3456]], grad_fn=<AddBackward0>)\n",
      "progress: 596 loss= 0.1557093858718872\n",
      "tensor([[ 2.1977, -1.2643, -0.7263],\n",
      "        [-0.8240,  0.9164,  0.1812],\n",
      "        [-3.1986,  0.7663,  3.0429],\n",
      "        [ 2.1977, -1.2643, -0.7263],\n",
      "        [ 2.1977, -1.2643, -0.7263],\n",
      "        [-0.3906, -1.3746,  2.3474]], grad_fn=<AddBackward0>)\n",
      "progress: 597 loss= 0.15555523335933685\n",
      "tensor([[ 2.1972, -1.2638, -0.7262],\n",
      "        [-0.8259,  0.9182,  0.1815],\n",
      "        [-3.2023,  0.7687,  3.0448],\n",
      "        [ 2.1972, -1.2638, -0.7262],\n",
      "        [ 2.1972, -1.2638, -0.7262],\n",
      "        [-0.3924, -1.3742,  2.3492]], grad_fn=<AddBackward0>)\n",
      "progress: 598 loss= 0.15541265904903412\n",
      "tensor([[ 2.1991, -1.2649, -0.7271],\n",
      "        [-0.8252,  0.9183,  0.1805],\n",
      "        [-3.2020,  0.7681,  3.0447],\n",
      "        [ 2.1991, -1.2649, -0.7271],\n",
      "        [ 2.1991, -1.2649, -0.7271],\n",
      "        [-0.3914, -1.3755,  2.3493]], grad_fn=<AddBackward0>)\n",
      "progress: 599 loss= 0.15525050461292267\n",
      "tensor([[ 2.1989, -1.2644, -0.7273],\n",
      "        [-0.8268,  0.9198,  0.1806],\n",
      "        [-3.2058,  0.7704,  3.0467],\n",
      "        [ 2.1989, -1.2644, -0.7273],\n",
      "        [ 2.1989, -1.2644, -0.7273],\n",
      "        [-0.3932, -1.3751,  2.3510]], grad_fn=<AddBackward0>)\n",
      "progress: 600 loss= 0.1551038771867752\n",
      "tensor([[ 2.2005, -1.2655, -0.7279],\n",
      "        [-0.8263,  0.9202,  0.1800],\n",
      "        [-3.2057,  0.7697,  3.0476],\n",
      "        [ 2.2005, -1.2655, -0.7279],\n",
      "        [ 2.2005, -1.2655, -0.7279],\n",
      "        [-0.3923, -1.3765,  2.3516]], grad_fn=<AddBackward0>)\n",
      "progress: 601 loss= 0.15493173897266388\n",
      "tensor([[ 2.2005, -1.2651, -0.7284],\n",
      "        [-0.8277,  0.9214,  0.1799],\n",
      "        [-3.2092,  0.7722,  3.0483],\n",
      "        [ 2.2005, -1.2651, -0.7284],\n",
      "        [ 2.2005, -1.2651, -0.7284],\n",
      "        [-0.3939, -1.3760,  2.3526]], grad_fn=<AddBackward0>)\n",
      "progress: 602 loss= 0.15481995046138763\n",
      "tensor([[ 2.2020, -1.2661, -0.7288],\n",
      "        [-0.8274,  0.9221,  0.1792],\n",
      "        [-3.2092,  0.7714,  3.0495],\n",
      "        [ 2.2020, -1.2661, -0.7288],\n",
      "        [ 2.2020, -1.2661, -0.7288],\n",
      "        [-0.3931, -1.3774,  2.3535]], grad_fn=<AddBackward0>)\n",
      "progress: 603 loss= 0.1546202450990677\n",
      "tensor([[ 2.2032, -1.2672, -0.7289],\n",
      "        [-0.8275,  0.9217,  0.1796],\n",
      "        [-3.2105,  0.7709,  3.0516],\n",
      "        [ 2.2032, -1.2672, -0.7289],\n",
      "        [ 2.2032, -1.2672, -0.7289],\n",
      "        [-0.3936, -1.3785,  2.3553]], grad_fn=<AddBackward0>)\n",
      "progress: 604 loss= 0.15452362596988678\n",
      "tensor([[ 2.2029, -1.2666, -0.7294],\n",
      "        [-0.8297,  0.9240,  0.1794],\n",
      "        [-3.2140,  0.7734,  3.0523],\n",
      "        [ 2.2029, -1.2666, -0.7294],\n",
      "        [ 2.2029, -1.2666, -0.7294],\n",
      "        [-0.3952, -1.3780,  2.3562]], grad_fn=<AddBackward0>)\n",
      "progress: 605 loss= 0.15433736145496368\n",
      "tensor([[ 2.2047, -1.2678, -0.7299],\n",
      "        [-0.8286,  0.9237,  0.1787],\n",
      "        [-3.2140,  0.7726,  3.0535],\n",
      "        [ 2.2047, -1.2678, -0.7299],\n",
      "        [ 2.2047, -1.2678, -0.7299],\n",
      "        [-0.3943, -1.3794,  2.3571]], grad_fn=<AddBackward0>)\n",
      "progress: 606 loss= 0.15420134365558624\n",
      "tensor([[ 2.2045, -1.2673, -0.7302],\n",
      "        [-0.8306,  0.9255,  0.1789],\n",
      "        [-3.2177,  0.7750,  3.0551],\n",
      "        [ 2.2045, -1.2673, -0.7302],\n",
      "        [ 2.2045, -1.2673, -0.7302],\n",
      "        [-0.3960, -1.3790,  2.3585]], grad_fn=<AddBackward0>)\n",
      "progress: 607 loss= 0.15403825044631958\n",
      "tensor([[ 2.2061, -1.2684, -0.7309],\n",
      "        [-0.8298,  0.9256,  0.1780],\n",
      "        [-3.2174,  0.7744,  3.0551],\n",
      "        [ 2.2061, -1.2684, -0.7309],\n",
      "        [ 2.2061, -1.2684, -0.7309],\n",
      "        [-0.3950, -1.3803,  2.3586]], grad_fn=<AddBackward0>)\n",
      "progress: 608 loss= 0.15390513837337494\n",
      "tensor([[ 2.2062, -1.2679, -0.7313],\n",
      "        [-0.8314,  0.9272,  0.1781],\n",
      "        [-3.2211,  0.7768,  3.0570],\n",
      "        [ 2.2062, -1.2679, -0.7313],\n",
      "        [ 2.2062, -1.2679, -0.7313],\n",
      "        [-0.3968, -1.3799,  2.3604]], grad_fn=<AddBackward0>)\n",
      "progress: 609 loss= 0.15373694896697998\n",
      "tensor([[ 2.2075, -1.2690, -0.7317],\n",
      "        [-0.8309,  0.9275,  0.1774],\n",
      "        [-3.2210,  0.7760,  3.0579],\n",
      "        [ 2.2075, -1.2690, -0.7317],\n",
      "        [ 2.2075, -1.2690, -0.7317],\n",
      "        [-0.3959, -1.3812,  2.3610]], grad_fn=<AddBackward0>)\n",
      "progress: 610 loss= 0.15358437597751617\n",
      "tensor([[ 2.2076, -1.2686, -0.7322],\n",
      "        [-0.8323,  0.9288,  0.1774],\n",
      "        [-3.2245,  0.7785,  3.0586],\n",
      "        [ 2.2076, -1.2686, -0.7322],\n",
      "        [ 2.2076, -1.2686, -0.7322],\n",
      "        [-0.3975, -1.3808,  2.3619]], grad_fn=<AddBackward0>)\n",
      "progress: 611 loss= 0.15346844494342804\n",
      "tensor([[ 2.2086, -1.2695, -0.7323],\n",
      "        [-0.8334,  0.9297,  0.1775],\n",
      "        [-3.2258,  0.7780,  3.0607],\n",
      "        [ 2.2086, -1.2695, -0.7323],\n",
      "        [ 2.2086, -1.2695, -0.7323],\n",
      "        [-0.3980, -1.3819,  2.3637]], grad_fn=<AddBackward0>)\n",
      "progress: 612 loss= 0.15326999127864838\n",
      "tensor([[ 2.2090, -1.2692, -0.7328],\n",
      "        [-0.8333,  0.9303,  0.1770],\n",
      "        [-3.2282,  0.7801,  3.0617],\n",
      "        [ 2.2090, -1.2692, -0.7328],\n",
      "        [ 2.2090, -1.2692, -0.7328],\n",
      "        [-0.3984, -1.3818,  2.3645]], grad_fn=<AddBackward0>)\n",
      "progress: 613 loss= 0.15317828953266144\n",
      "tensor([[ 2.2102, -1.2702, -0.7333],\n",
      "        [-0.8343,  0.9313,  0.1769],\n",
      "        [-3.2292,  0.7797,  3.0626],\n",
      "        [ 2.2102, -1.2702, -0.7333],\n",
      "        [ 2.2102, -1.2702, -0.7333],\n",
      "        [-0.3987, -1.3828,  2.3655]], grad_fn=<AddBackward0>)\n",
      "progress: 614 loss= 0.15298138558864594\n",
      "tensor([[ 2.2117, -1.2712, -0.7338],\n",
      "        [-0.8332,  0.9309,  0.1762],\n",
      "        [-3.2292,  0.7789,  3.0638],\n",
      "        [ 2.2117, -1.2712, -0.7338],\n",
      "        [ 2.2117, -1.2712, -0.7338],\n",
      "        [-0.3979, -1.3842,  2.3664]], grad_fn=<AddBackward0>)\n",
      "progress: 615 loss= 0.15286655724048615\n",
      "tensor([[ 2.2118, -1.2708, -0.7342],\n",
      "        [-0.8352,  0.9329,  0.1763],\n",
      "        [-3.2329,  0.7813,  3.0654],\n",
      "        [ 2.2118, -1.2708, -0.7342],\n",
      "        [ 2.2118, -1.2708, -0.7342],\n",
      "        [-0.3996, -1.3838,  2.3679]], grad_fn=<AddBackward0>)\n",
      "progress: 616 loss= 0.15268193185329437\n",
      "tensor([[ 2.2126, -1.2717, -0.7343],\n",
      "        [-0.8357,  0.9331,  0.1764],\n",
      "        [-3.2339,  0.7809,  3.0662],\n",
      "        [ 2.2126, -1.2717, -0.7343],\n",
      "        [ 2.2126, -1.2717, -0.7343],\n",
      "        [-0.3999, -1.3848,  2.3689]], grad_fn=<AddBackward0>)\n",
      "progress: 617 loss= 0.15257425606250763\n",
      "tensor([[ 2.2132, -1.2714, -0.7351],\n",
      "        [-0.8361,  0.9345,  0.1756],\n",
      "        [-3.2363,  0.7830,  3.0673],\n",
      "        [ 2.2132, -1.2714, -0.7351],\n",
      "        [ 2.2132, -1.2714, -0.7351],\n",
      "        [-0.4003, -1.3847,  2.3697]], grad_fn=<AddBackward0>)\n",
      "progress: 618 loss= 0.1524008959531784\n",
      "tensor([[ 2.2142, -1.2724, -0.7350],\n",
      "        [-0.8369,  0.9350,  0.1760],\n",
      "        [-3.2376,  0.7825,  3.0694],\n",
      "        [ 2.2142, -1.2724, -0.7350],\n",
      "        [ 2.2142, -1.2724, -0.7350],\n",
      "        [-0.4008, -1.3858,  2.3715]], grad_fn=<AddBackward0>)\n",
      "progress: 619 loss= 0.15225328505039215\n",
      "tensor([[ 2.2146, -1.2720, -0.7360],\n",
      "        [-0.8370,  0.9361,  0.1749],\n",
      "        [-3.2397,  0.7847,  3.0691],\n",
      "        [ 2.2146, -1.2720, -0.7360],\n",
      "        [ 2.2146, -1.2720, -0.7360],\n",
      "        [-0.4011, -1.3856,  2.3715]], grad_fn=<AddBackward0>)\n",
      "progress: 620 loss= 0.152129665017128\n",
      "tensor([[ 2.2158, -1.2730, -0.7362],\n",
      "        [-0.8380,  0.9369,  0.1750],\n",
      "        [-3.2410,  0.7842,  3.0712],\n",
      "        [ 2.2158, -1.2730, -0.7362],\n",
      "        [ 2.2158, -1.2730, -0.7362],\n",
      "        [-0.4016, -1.3867,  2.3733]], grad_fn=<AddBackward0>)\n",
      "progress: 621 loss= 0.15192648768424988\n",
      "tensor([[ 2.2160, -1.2726, -0.7367],\n",
      "        [-0.8379,  0.9376,  0.1744],\n",
      "        [-3.2433,  0.7863,  3.0720],\n",
      "        [ 2.2160, -1.2726, -0.7367],\n",
      "        [ 2.2160, -1.2726, -0.7367],\n",
      "        [-0.4019, -1.3866,  2.3738]], grad_fn=<AddBackward0>)\n",
      "progress: 622 loss= 0.15184657275676727\n",
      "tensor([[ 2.2174, -1.2736, -0.7372],\n",
      "        [-0.8389,  0.9386,  0.1744],\n",
      "        [-3.2443,  0.7859,  3.0728],\n",
      "        [ 2.2174, -1.2736, -0.7372],\n",
      "        [ 2.2174, -1.2736, -0.7372],\n",
      "        [-0.4022, -1.3876,  2.3749]], grad_fn=<AddBackward0>)\n",
      "progress: 623 loss= 0.15164725482463837\n",
      "tensor([[ 2.2182, -1.2746, -0.7373],\n",
      "        [-0.8391,  0.9384,  0.1745],\n",
      "        [-3.2456,  0.7854,  3.0749],\n",
      "        [ 2.2182, -1.2746, -0.7373],\n",
      "        [ 2.2182, -1.2746, -0.7373],\n",
      "        [-0.4027, -1.3887,  2.3766]], grad_fn=<AddBackward0>)\n",
      "progress: 624 loss= 0.1515418142080307\n",
      "tensor([[ 2.2187, -1.2743, -0.7380],\n",
      "        [-0.8398,  0.9402,  0.1737],\n",
      "        [-3.2480,  0.7875,  3.0756],\n",
      "        [ 2.2187, -1.2743, -0.7380],\n",
      "        [ 2.2187, -1.2743, -0.7380],\n",
      "        [-0.4031, -1.3886,  2.3772]], grad_fn=<AddBackward0>)\n",
      "progress: 625 loss= 0.1513560712337494\n",
      "tensor([[ 2.2198, -1.2752, -0.7382],\n",
      "        [-0.8402,  0.9403,  0.1739],\n",
      "        [-3.2489,  0.7871,  3.0765],\n",
      "        [ 2.2198, -1.2752, -0.7382],\n",
      "        [ 2.2198, -1.2752, -0.7382],\n",
      "        [-0.4034, -1.3896,  2.3782]], grad_fn=<AddBackward0>)\n",
      "progress: 626 loss= 0.15124471485614777\n",
      "tensor([[ 2.2202, -1.2748, -0.7389],\n",
      "        [-0.8407,  0.9418,  0.1730],\n",
      "        [-3.2514,  0.7892,  3.0775],\n",
      "        [ 2.2202, -1.2748, -0.7389],\n",
      "        [ 2.2202, -1.2748, -0.7389],\n",
      "        [-0.4038, -1.3895,  2.3790]], grad_fn=<AddBackward0>)\n",
      "progress: 627 loss= 0.1510840505361557\n",
      "tensor([[ 2.2214, -1.2759, -0.7390],\n",
      "        [-0.8414,  0.9422,  0.1734],\n",
      "        [-3.2526,  0.7886,  3.0796],\n",
      "        [ 2.2214, -1.2759, -0.7390],\n",
      "        [ 2.2214, -1.2759, -0.7390],\n",
      "        [-0.4043, -1.3906,  2.3808]], grad_fn=<AddBackward0>)\n",
      "progress: 628 loss= 0.15092189610004425\n",
      "tensor([[ 2.2216, -1.2754, -0.7397],\n",
      "        [-0.8416,  0.9434,  0.1724],\n",
      "        [-3.2548,  0.7909,  3.0793],\n",
      "        [ 2.2216, -1.2754, -0.7397],\n",
      "        [ 2.2216, -1.2754, -0.7397],\n",
      "        [-0.4046, -1.3905,  2.3808]], grad_fn=<AddBackward0>)\n",
      "progress: 629 loss= 0.1508161723613739\n",
      "tensor([[ 2.2229, -1.2765, -0.7400],\n",
      "        [-0.8425,  0.9441,  0.1725],\n",
      "        [-3.2560,  0.7903,  3.0814],\n",
      "        [ 2.2229, -1.2765, -0.7400],\n",
      "        [ 2.2229, -1.2765, -0.7400],\n",
      "        [-0.4050, -1.3916,  2.3826]], grad_fn=<AddBackward0>)\n",
      "progress: 630 loss= 0.1506122201681137\n",
      "tensor([[ 2.2226, -1.2760, -0.7402],\n",
      "        [-0.8438,  0.9452,  0.1727],\n",
      "        [-3.2597,  0.7927,  3.0831],\n",
      "        [ 2.2226, -1.2760, -0.7402],\n",
      "        [ 2.2226, -1.2760, -0.7402],\n",
      "        [-0.4067, -1.3912,  2.3840]], grad_fn=<AddBackward0>)\n",
      "progress: 631 loss= 0.15052099525928497\n",
      "tensor([[ 2.2243, -1.2771, -0.7409],\n",
      "        [-0.8435,  0.9459,  0.1718],\n",
      "        [-3.2593,  0.7921,  3.0830],\n",
      "        [ 2.2243, -1.2771, -0.7409],\n",
      "        [ 2.2243, -1.2771, -0.7409],\n",
      "        [-0.4057, -1.3925,  2.3841]], grad_fn=<AddBackward0>)\n",
      "progress: 632 loss= 0.15033946931362152\n",
      "tensor([[ 2.2254, -1.2780, -0.7412],\n",
      "        [-0.8436,  0.9457,  0.1720],\n",
      "        [-3.2606,  0.7915,  3.0851],\n",
      "        [ 2.2254, -1.2780, -0.7412],\n",
      "        [ 2.2254, -1.2780, -0.7412],\n",
      "        [-0.4062, -1.3936,  2.3859]], grad_fn=<AddBackward0>)\n",
      "progress: 633 loss= 0.15022404491901398\n",
      "tensor([[ 2.2256, -1.2777, -0.7415],\n",
      "        [-0.8445,  0.9474,  0.1714],\n",
      "        [-3.2630,  0.7936,  3.0861],\n",
      "        [ 2.2256, -1.2777, -0.7415],\n",
      "        [ 2.2256, -1.2777, -0.7415],\n",
      "        [-0.4066, -1.3935,  2.3867]], grad_fn=<AddBackward0>)\n",
      "progress: 634 loss= 0.15005964040756226\n",
      "tensor([[ 2.2270, -1.2787, -0.7421],\n",
      "        [-0.8448,  0.9476,  0.1713],\n",
      "        [-3.2640,  0.7932,  3.0869],\n",
      "        [ 2.2270, -1.2787, -0.7421],\n",
      "        [ 2.2270, -1.2787, -0.7421],\n",
      "        [-0.4069, -1.3945,  2.3877]], grad_fn=<AddBackward0>)\n",
      "progress: 635 loss= 0.14992423355579376\n",
      "tensor([[ 2.2265, -1.2782, -0.7421],\n",
      "        [-0.8466,  0.9493,  0.1714],\n",
      "        [-3.2677,  0.7956,  3.0888],\n",
      "        [ 2.2265, -1.2782, -0.7421],\n",
      "        [ 2.2265, -1.2782, -0.7421],\n",
      "        [-0.4086, -1.3941,  2.3894]], grad_fn=<AddBackward0>)\n",
      "progress: 636 loss= 0.14977392554283142\n",
      "tensor([[ 2.2283, -1.2793, -0.7428],\n",
      "        [-0.8459,  0.9494,  0.1708],\n",
      "        [-3.2675,  0.7948,  3.0897],\n",
      "        [ 2.2283, -1.2793, -0.7428],\n",
      "        [ 2.2283, -1.2793, -0.7428],\n",
      "        [-0.4077, -1.3955,  2.3900]], grad_fn=<AddBackward0>)\n",
      "progress: 637 loss= 0.14962048828601837\n",
      "tensor([[ 2.2282, -1.2788, -0.7432],\n",
      "        [-0.8475,  0.9509,  0.1707],\n",
      "        [-3.2710,  0.7973,  3.0904],\n",
      "        [ 2.2282, -1.2788, -0.7432],\n",
      "        [ 2.2282, -1.2788, -0.7432],\n",
      "        [-0.4093, -1.3950,  2.3909]], grad_fn=<AddBackward0>)\n",
      "progress: 638 loss= 0.149503692984581\n",
      "tensor([[ 2.2298, -1.2799, -0.7438],\n",
      "        [-0.8470,  0.9513,  0.1700],\n",
      "        [-3.2709,  0.7965,  3.0916],\n",
      "        [ 2.2298, -1.2799, -0.7438],\n",
      "        [ 2.2298, -1.2799, -0.7438],\n",
      "        [-0.4084, -1.3964,  2.3918]], grad_fn=<AddBackward0>)\n",
      "progress: 639 loss= 0.14932043850421906\n",
      "tensor([[ 2.2297, -1.2795, -0.7439],\n",
      "        [-0.8484,  0.9524,  0.1704],\n",
      "        [-3.2746,  0.7988,  3.0935],\n",
      "        [ 2.2297, -1.2795, -0.7439],\n",
      "        [ 2.2297, -1.2795, -0.7439],\n",
      "        [-0.4101, -1.3961,  2.3935]], grad_fn=<AddBackward0>)\n",
      "progress: 640 loss= 0.14921791851520538\n",
      "tensor([[ 2.2312, -1.2805, -0.7446],\n",
      "        [-0.8481,  0.9531,  0.1693],\n",
      "        [-3.2743,  0.7981,  3.0934],\n",
      "        [ 2.2312, -1.2805, -0.7446],\n",
      "        [ 2.2312, -1.2805, -0.7446],\n",
      "        [-0.4092, -1.3973,  2.3936]], grad_fn=<AddBackward0>)\n",
      "progress: 641 loss= 0.14903835952281952\n",
      "tensor([[ 2.2324, -1.2815, -0.7448],\n",
      "        [-0.8482,  0.9529,  0.1695],\n",
      "        [-3.2755,  0.7976,  3.0955],\n",
      "        [ 2.2324, -1.2815, -0.7448],\n",
      "        [ 2.2324, -1.2815, -0.7448],\n",
      "        [-0.4096, -1.3984,  2.3954]], grad_fn=<AddBackward0>)\n",
      "progress: 642 loss= 0.14892429113388062\n",
      "tensor([[ 2.2321, -1.2810, -0.7450],\n",
      "        [-0.8503,  0.9550,  0.1697],\n",
      "        [-3.2791,  0.7999,  3.0971],\n",
      "        [ 2.2321, -1.2810, -0.7450],\n",
      "        [ 2.2321, -1.2810, -0.7450],\n",
      "        [-0.4113, -1.3981,  2.3968]], grad_fn=<AddBackward0>)\n",
      "progress: 643 loss= 0.14875774085521698\n",
      "tensor([[ 2.2339, -1.2821, -0.7458],\n",
      "        [-0.8493,  0.9548,  0.1688],\n",
      "        [-3.2788,  0.7993,  3.0970],\n",
      "        [ 2.2339, -1.2821, -0.7458],\n",
      "        [ 2.2339, -1.2821, -0.7458],\n",
      "        [-0.4103, -1.3993,  2.3969]], grad_fn=<AddBackward0>)\n",
      "progress: 644 loss= 0.14864210784435272\n",
      "tensor([[ 2.2337, -1.2816, -0.7461],\n",
      "        [-0.8511,  0.9566,  0.1688],\n",
      "        [-3.2825,  0.8016,  3.0989],\n",
      "        [ 2.2337, -1.2816, -0.7461],\n",
      "        [ 2.2337, -1.2816, -0.7461],\n",
      "        [-0.4120, -1.3990,  2.3986]], grad_fn=<AddBackward0>)\n",
      "progress: 645 loss= 0.1484694927930832\n",
      "tensor([[ 2.2352, -1.2827, -0.7466],\n",
      "        [-0.8504,  0.9566,  0.1682],\n",
      "        [-3.2824,  0.8008,  3.0998],\n",
      "        [ 2.2352, -1.2827, -0.7466],\n",
      "        [ 2.2352, -1.2827, -0.7466],\n",
      "        [-0.4111, -1.4003,  2.3992]], grad_fn=<AddBackward0>)\n",
      "progress: 646 loss= 0.14833630621433258\n",
      "tensor([[ 2.2353, -1.2822, -0.7471],\n",
      "        [-0.8520,  0.9582,  0.1682],\n",
      "        [-3.2858,  0.8033,  3.1005],\n",
      "        [ 2.2353, -1.2822, -0.7471],\n",
      "        [ 2.2353, -1.2822, -0.7471],\n",
      "        [-0.4126, -1.3999,  2.4001]], grad_fn=<AddBackward0>)\n",
      "progress: 647 loss= 0.1482057273387909\n",
      "tensor([[ 2.2361, -1.2831, -0.7471],\n",
      "        [-0.8528,  0.9588,  0.1683],\n",
      "        [-3.2870,  0.8028,  3.1025],\n",
      "        [ 2.2361, -1.2831, -0.7471],\n",
      "        [ 2.2361, -1.2831, -0.7471],\n",
      "        [-0.4131, -1.4010,  2.4019]], grad_fn=<AddBackward0>)\n",
      "progress: 648 loss= 0.14804385602474213\n",
      "tensor([[ 2.2367, -1.2829, -0.7477],\n",
      "        [-0.8529,  0.9597,  0.1678],\n",
      "        [-3.2894,  0.8048,  3.1035],\n",
      "        [ 2.2367, -1.2829, -0.7477],\n",
      "        [ 2.2367, -1.2829, -0.7477],\n",
      "        [-0.4135, -1.4010,  2.4027]], grad_fn=<AddBackward0>)\n",
      "progress: 649 loss= 0.1479298323392868\n",
      "tensor([[ 2.2377, -1.2838, -0.7481],\n",
      "        [-0.8539,  0.9607,  0.1676],\n",
      "        [-3.2903,  0.8044,  3.1043],\n",
      "        [ 2.2377, -1.2838, -0.7481],\n",
      "        [ 2.2377, -1.2838, -0.7481],\n",
      "        [-0.4138, -1.4019,  2.4037]], grad_fn=<AddBackward0>)\n",
      "progress: 650 loss= 0.1477486789226532\n",
      "tensor([[ 2.2393, -1.2848, -0.7486],\n",
      "        [-0.8526,  0.9601,  0.1669],\n",
      "        [-3.2903,  0.8036,  3.1055],\n",
      "        [ 2.2393, -1.2848, -0.7486],\n",
      "        [ 2.2393, -1.2848, -0.7486],\n",
      "        [-0.4129, -1.4033,  2.4045]], grad_fn=<AddBackward0>)\n",
      "progress: 651 loss= 0.14765165746212006\n",
      "tensor([[ 2.2393, -1.2844, -0.7489],\n",
      "        [-0.8548,  0.9622,  0.1671],\n",
      "        [-3.2939,  0.8060,  3.1071],\n",
      "        [ 2.2393, -1.2844, -0.7489],\n",
      "        [ 2.2393, -1.2844, -0.7489],\n",
      "        [-0.4146, -1.4029,  2.4060]], grad_fn=<AddBackward0>)\n",
      "progress: 652 loss= 0.14746199548244476\n",
      "tensor([[ 2.2407, -1.2854, -0.7495],\n",
      "        [-0.8538,  0.9619,  0.1662],\n",
      "        [-3.2935,  0.8053,  3.1071],\n",
      "        [ 2.2407, -1.2854, -0.7495],\n",
      "        [ 2.2407, -1.2854, -0.7495],\n",
      "        [-0.4136, -1.4042,  2.4061]], grad_fn=<AddBackward0>)\n",
      "progress: 653 loss= 0.14737477898597717\n",
      "tensor([[ 2.2408, -1.2850, -0.7499],\n",
      "        [-0.8557,  0.9638,  0.1663],\n",
      "        [-3.2972,  0.8076,  3.1090],\n",
      "        [ 2.2408, -1.2850, -0.7499],\n",
      "        [ 2.2408, -1.2850, -0.7499],\n",
      "        [-0.4153, -1.4039,  2.4077]], grad_fn=<AddBackward0>)\n",
      "progress: 654 loss= 0.1471884697675705\n",
      "tensor([[ 2.2416, -1.2860, -0.7498],\n",
      "        [-0.8562,  0.9640,  0.1667],\n",
      "        [-3.2984,  0.8071,  3.1110],\n",
      "        [ 2.2416, -1.2860, -0.7498],\n",
      "        [ 2.2416, -1.2860, -0.7498],\n",
      "        [-0.4157, -1.4050,  2.4095]], grad_fn=<AddBackward0>)\n",
      "progress: 655 loss= 0.14707383513450623\n",
      "tensor([[ 2.2421, -1.2856, -0.7508],\n",
      "        [-0.8565,  0.9654,  0.1656],\n",
      "        [-3.3005,  0.8093,  3.1108],\n",
      "        [ 2.2421, -1.2856, -0.7508],\n",
      "        [ 2.2421, -1.2856, -0.7508],\n",
      "        [-0.4160, -1.4048,  2.4095]], grad_fn=<AddBackward0>)\n",
      "progress: 656 loss= 0.14693035185337067\n",
      "tensor([[ 2.2432, -1.2866, -0.7509],\n",
      "        [-0.8573,  0.9660,  0.1658],\n",
      "        [-3.3017,  0.8087,  3.1128],\n",
      "        [ 2.2432, -1.2866, -0.7509],\n",
      "        [ 2.2432, -1.2866, -0.7509],\n",
      "        [-0.4164, -1.4059,  2.4113]], grad_fn=<AddBackward0>)\n",
      "progress: 657 loss= 0.14676043391227722\n",
      "tensor([[ 2.2435, -1.2862, -0.7514],\n",
      "        [-0.8574,  0.9669,  0.1651],\n",
      "        [-3.3041,  0.8108,  3.1136],\n",
      "        [ 2.2435, -1.2862, -0.7514],\n",
      "        [ 2.2435, -1.2862, -0.7514],\n",
      "        [-0.4168, -1.4058,  2.4118]], grad_fn=<AddBackward0>)\n",
      "progress: 658 loss= 0.14666111767292023\n",
      "tensor([[ 2.2448, -1.2872, -0.7519],\n",
      "        [-0.8584,  0.9678,  0.1651],\n",
      "        [-3.3050,  0.8104,  3.1144],\n",
      "        [ 2.2448, -1.2872, -0.7519],\n",
      "        [ 2.2448, -1.2872, -0.7519],\n",
      "        [-0.4171, -1.4068,  2.4128]], grad_fn=<AddBackward0>)\n",
      "progress: 659 loss= 0.14647343754768372\n",
      "tensor([[ 2.2444, -1.2866, -0.7520],\n",
      "        [-0.8595,  0.9688,  0.1652],\n",
      "        [-3.3086,  0.8127,  3.1163],\n",
      "        [ 2.2444, -1.2866, -0.7520],\n",
      "        [ 2.2444, -1.2866, -0.7520],\n",
      "        [-0.4187, -1.4065,  2.4145]], grad_fn=<AddBackward0>)\n",
      "progress: 660 loss= 0.14639070630073547\n",
      "tensor([[ 2.2461, -1.2878, -0.7525],\n",
      "        [-0.8594,  0.9694,  0.1647],\n",
      "        [-3.3086,  0.8119,  3.1174],\n",
      "        [ 2.2461, -1.2878, -0.7525],\n",
      "        [ 2.2461, -1.2878, -0.7525],\n",
      "        [-0.4179, -1.4079,  2.4154]], grad_fn=<AddBackward0>)\n",
      "progress: 661 loss= 0.14620645344257355\n",
      "tensor([[ 2.2472, -1.2887, -0.7529],\n",
      "        [-0.8595,  0.9694,  0.1646],\n",
      "        [-3.3095,  0.8115,  3.1182],\n",
      "        [ 2.2472, -1.2887, -0.7529],\n",
      "        [ 2.2472, -1.2887, -0.7529],\n",
      "        [-0.4182, -1.4089,  2.4163]], grad_fn=<AddBackward0>)\n",
      "progress: 662 loss= 0.14610163867473602\n",
      "tensor([[ 2.2475, -1.2884, -0.7534],\n",
      "        [-0.8602,  0.9710,  0.1638],\n",
      "        [-3.3119,  0.8135,  3.1192],\n",
      "        [ 2.2475, -1.2884, -0.7534],\n",
      "        [ 2.2475, -1.2884, -0.7534],\n",
      "        [-0.4186, -1.4088,  2.4171]], grad_fn=<AddBackward0>)\n",
      "progress: 663 loss= 0.14592993259429932\n",
      "tensor([[ 2.2487, -1.2893, -0.7539],\n",
      "        [-0.8606,  0.9712,  0.1639],\n",
      "        [-3.3128,  0.8131,  3.1200],\n",
      "        [ 2.2487, -1.2893, -0.7539],\n",
      "        [ 2.2487, -1.2893, -0.7539],\n",
      "        [-0.4189, -1.4098,  2.4181]], grad_fn=<AddBackward0>)\n",
      "progress: 664 loss= 0.14581017196178436\n",
      "tensor([[ 2.2489, -1.2889, -0.7544],\n",
      "        [-0.8610,  0.9726,  0.1631],\n",
      "        [-3.3152,  0.8151,  3.1210],\n",
      "        [ 2.2489, -1.2889, -0.7544],\n",
      "        [ 2.2489, -1.2889, -0.7544],\n",
      "        [-0.4193, -1.4098,  2.4189]], grad_fn=<AddBackward0>)\n",
      "progress: 665 loss= 0.1456698179244995\n",
      "tensor([[ 2.2501, -1.2900, -0.7545],\n",
      "        [-0.8618,  0.9731,  0.1634],\n",
      "        [-3.3164,  0.8146,  3.1231],\n",
      "        [ 2.2501, -1.2900, -0.7545],\n",
      "        [ 2.2501, -1.2900, -0.7545],\n",
      "        [-0.4197, -1.4109,  2.4207]], grad_fn=<AddBackward0>)\n",
      "progress: 666 loss= 0.14551012217998505\n",
      "tensor([[ 2.2499, -1.2894, -0.7549],\n",
      "        [-0.8631,  0.9744,  0.1633],\n",
      "        [-3.3197,  0.8171,  3.1237],\n",
      "        [ 2.2499, -1.2894, -0.7549],\n",
      "        [ 2.2499, -1.2894, -0.7549],\n",
      "        [-0.4212, -1.4105,  2.4216]], grad_fn=<AddBackward0>)\n",
      "progress: 667 loss= 0.14540930092334747\n",
      "tensor([[ 2.2515, -1.2905, -0.7554],\n",
      "        [-0.8628,  0.9750,  0.1625],\n",
      "        [-3.3196,  0.8162,  3.1249],\n",
      "        [ 2.2515, -1.2905, -0.7554],\n",
      "        [ 2.2515, -1.2905, -0.7554],\n",
      "        [-0.4204, -1.4118,  2.4224]], grad_fn=<AddBackward0>)\n",
      "progress: 668 loss= 0.14521841704845428\n",
      "tensor([[ 2.2514, -1.2901, -0.7557],\n",
      "        [-0.8640,  0.9760,  0.1627],\n",
      "        [-3.3232,  0.8185,  3.1265],\n",
      "        [ 2.2514, -1.2901, -0.7557],\n",
      "        [ 2.2514, -1.2901, -0.7557],\n",
      "        [-0.4220, -1.4115,  2.4238]], grad_fn=<AddBackward0>)\n",
      "progress: 669 loss= 0.14512787759304047\n",
      "tensor([[ 2.2529, -1.2911, -0.7564],\n",
      "        [-0.8638,  0.9766,  0.1619],\n",
      "        [-3.3229,  0.8179,  3.1264],\n",
      "        [ 2.2529, -1.2911, -0.7564],\n",
      "        [ 2.2529, -1.2911, -0.7564],\n",
      "        [-0.4210, -1.4128,  2.4240]], grad_fn=<AddBackward0>)\n",
      "progress: 670 loss= 0.14496196806430817\n",
      "tensor([[ 2.2542, -1.2921, -0.7567],\n",
      "        [-0.8639,  0.9765,  0.1620],\n",
      "        [-3.3240,  0.8173,  3.1285],\n",
      "        [ 2.2542, -1.2921, -0.7567],\n",
      "        [ 2.2542, -1.2921, -0.7567],\n",
      "        [-0.4214, -1.4139,  2.4257]], grad_fn=<AddBackward0>)\n",
      "progress: 671 loss= 0.14483949542045593\n",
      "tensor([[ 2.2538, -1.2916, -0.7568],\n",
      "        [-0.8659,  0.9785,  0.1621],\n",
      "        [-3.3276,  0.8196,  3.1301],\n",
      "        [ 2.2538, -1.2916, -0.7568],\n",
      "        [ 2.2538, -1.2916, -0.7568],\n",
      "        [-0.4230, -1.4135,  2.4271]], grad_fn=<AddBackward0>)\n",
      "progress: 672 loss= 0.14468611776828766\n",
      "tensor([[ 2.2556, -1.2927, -0.7575],\n",
      "        [-0.8651,  0.9783,  0.1615],\n",
      "        [-3.3275,  0.8188,  3.1310],\n",
      "        [ 2.2556, -1.2927, -0.7575],\n",
      "        [ 2.2556, -1.2927, -0.7575],\n",
      "        [-0.4221, -1.4148,  2.4277]], grad_fn=<AddBackward0>)\n",
      "progress: 673 loss= 0.14455802738666534\n",
      "tensor([[ 2.2554, -1.2922, -0.7578],\n",
      "        [-0.8667,  0.9800,  0.1614],\n",
      "        [-3.3308,  0.8213,  3.1316],\n",
      "        [ 2.2554, -1.2922, -0.7578],\n",
      "        [ 2.2554, -1.2922, -0.7578],\n",
      "        [-0.4236, -1.4144,  2.4286]], grad_fn=<AddBackward0>)\n",
      "progress: 674 loss= 0.14442908763885498\n",
      "tensor([[ 2.2569, -1.2932, -0.7584],\n",
      "        [-0.8661,  0.9802,  0.1607],\n",
      "        [-3.3307,  0.8205,  3.1328],\n",
      "        [ 2.2569, -1.2932, -0.7584],\n",
      "        [ 2.2569, -1.2932, -0.7584],\n",
      "        [-0.4228, -1.4158,  2.4295]], grad_fn=<AddBackward0>)\n",
      "progress: 675 loss= 0.14427043497562408\n",
      "tensor([[ 2.2569, -1.2928, -0.7585],\n",
      "        [-0.8676,  0.9815,  0.1611],\n",
      "        [-3.3344,  0.8227,  3.1346],\n",
      "        [ 2.2569, -1.2928, -0.7585],\n",
      "        [ 2.2569, -1.2928, -0.7585],\n",
      "        [-0.4245, -1.4155,  2.4311]], grad_fn=<AddBackward0>)\n",
      "progress: 676 loss= 0.1441573202610016\n",
      "tensor([[ 2.2583, -1.2938, -0.7592],\n",
      "        [-0.8672,  0.9821,  0.1600],\n",
      "        [-3.3340,  0.8221,  3.1345],\n",
      "        [ 2.2583, -1.2938, -0.7592],\n",
      "        [ 2.2583, -1.2938, -0.7592],\n",
      "        [-0.4235, -1.4167,  2.4312]], grad_fn=<AddBackward0>)\n",
      "progress: 677 loss= 0.14399559795856476\n",
      "tensor([[ 2.2583, -1.2934, -0.7595],\n",
      "        [-0.8684,  0.9832,  0.1601],\n",
      "        [-3.3376,  0.8244,  3.1364],\n",
      "        [ 2.2583, -1.2934, -0.7595],\n",
      "        [ 2.2583, -1.2934, -0.7595],\n",
      "        [-0.4251, -1.4164,  2.4329]], grad_fn=<AddBackward0>)\n",
      "progress: 678 loss= 0.1438813954591751\n",
      "tensor([[ 2.2593, -1.2943, -0.7598],\n",
      "        [-0.8695,  0.9841,  0.1602],\n",
      "        [-3.3385,  0.8240,  3.1372],\n",
      "        [ 2.2593, -1.2943, -0.7598],\n",
      "        [ 2.2593, -1.2943, -0.7598],\n",
      "        [-0.4254, -1.4174,  2.4339]], grad_fn=<AddBackward0>)\n",
      "progress: 679 loss= 0.14372636377811432\n",
      "tensor([[ 2.2609, -1.2954, -0.7604],\n",
      "        [-0.8683,  0.9836,  0.1595],\n",
      "        [-3.3384,  0.8231,  3.1384],\n",
      "        [ 2.2609, -1.2954, -0.7604],\n",
      "        [ 2.2609, -1.2954, -0.7604],\n",
      "        [-0.4246, -1.4188,  2.4347]], grad_fn=<AddBackward0>)\n",
      "progress: 680 loss= 0.14361582696437836\n",
      "tensor([[ 2.2608, -1.2950, -0.7604],\n",
      "        [-0.8704,  0.9856,  0.1597],\n",
      "        [-3.3420,  0.8254,  3.1402],\n",
      "        [ 2.2608, -1.2950, -0.7604],\n",
      "        [ 2.2608, -1.2950, -0.7604],\n",
      "        [-0.4262, -1.4185,  2.4364]], grad_fn=<AddBackward0>)\n",
      "progress: 681 loss= 0.1434483379125595\n",
      "tensor([[ 2.2623, -1.2960, -0.7612],\n",
      "        [-0.8694,  0.9855,  0.1588],\n",
      "        [-3.3417,  0.8248,  3.1401],\n",
      "        [ 2.2623, -1.2960, -0.7612],\n",
      "        [ 2.2623, -1.2960, -0.7612],\n",
      "        [-0.4252, -1.4198,  2.4365]], grad_fn=<AddBackward0>)\n",
      "progress: 682 loss= 0.14334255456924438\n",
      "tensor([[ 2.2623, -1.2955, -0.7615],\n",
      "        [-0.8712,  0.9872,  0.1589],\n",
      "        [-3.3453,  0.8270,  3.1420],\n",
      "        [ 2.2623, -1.2955, -0.7615],\n",
      "        [ 2.2623, -1.2955, -0.7615],\n",
      "        [-0.4269, -1.4194,  2.4382]], grad_fn=<AddBackward0>)\n",
      "progress: 683 loss= 0.14317673444747925\n",
      "tensor([[ 2.2631, -1.2964, -0.7615],\n",
      "        [-0.8718,  0.9876,  0.1590],\n",
      "        [-3.3464,  0.8265,  3.1438],\n",
      "        [ 2.2631, -1.2964, -0.7615],\n",
      "        [ 2.2631, -1.2964, -0.7615],\n",
      "        [-0.4272, -1.4205,  2.4396]], grad_fn=<AddBackward0>)\n",
      "progress: 684 loss= 0.1430511325597763\n",
      "tensor([[ 2.2637, -1.2961, -0.7625],\n",
      "        [-0.8720,  0.9887,  0.1582],\n",
      "        [-3.3485,  0.8287,  3.1435],\n",
      "        [ 2.2637, -1.2961, -0.7625],\n",
      "        [ 2.2637, -1.2961, -0.7625],\n",
      "        [-0.4275, -1.4204,  2.4397]], grad_fn=<AddBackward0>)\n",
      "progress: 685 loss= 0.14293381571769714\n",
      "tensor([[ 2.2647, -1.2970, -0.7626],\n",
      "        [-0.8729,  0.9895,  0.1583],\n",
      "        [-3.3496,  0.8281,  3.1455],\n",
      "        [ 2.2647, -1.2970, -0.7626],\n",
      "        [ 2.2647, -1.2970, -0.7626],\n",
      "        [-0.4279, -1.4215,  2.4414]], grad_fn=<AddBackward0>)\n",
      "progress: 686 loss= 0.14276038110256195\n",
      "tensor([[ 2.2650, -1.2967, -0.7630],\n",
      "        [-0.8729,  0.9903,  0.1578],\n",
      "        [-3.3520,  0.8301,  3.1465],\n",
      "        [ 2.2650, -1.2967, -0.7630],\n",
      "        [ 2.2650, -1.2967, -0.7630],\n",
      "        [-0.4283, -1.4214,  2.4422]], grad_fn=<AddBackward0>)\n",
      "progress: 687 loss= 0.14267295598983765\n",
      "tensor([[ 2.2663, -1.2977, -0.7636],\n",
      "        [-0.8739,  0.9912,  0.1576],\n",
      "        [-3.3529,  0.8297,  3.1473],\n",
      "        [ 2.2663, -1.2977, -0.7636],\n",
      "        [ 2.2663, -1.2977, -0.7636],\n",
      "        [-0.4285, -1.4224,  2.4432]], grad_fn=<AddBackward0>)\n",
      "progress: 688 loss= 0.142485573887825\n",
      "tensor([[ 2.2676, -1.2987, -0.7638],\n",
      "        [-0.8727,  0.9907,  0.1569],\n",
      "        [-3.3528,  0.8288,  3.1485],\n",
      "        [ 2.2676, -1.2987, -0.7638],\n",
      "        [ 2.2676, -1.2987, -0.7638],\n",
      "        [-0.4277, -1.4238,  2.4440]], grad_fn=<AddBackward0>)\n",
      "progress: 689 loss= 0.14240284264087677\n",
      "tensor([[ 2.2676, -1.2983, -0.7642],\n",
      "        [-0.8747,  0.9927,  0.1571],\n",
      "        [-3.3563,  0.8311,  3.1501],\n",
      "        [ 2.2676, -1.2983, -0.7642],\n",
      "        [ 2.2676, -1.2983, -0.7642],\n",
      "        [-0.4293, -1.4235,  2.4454]], grad_fn=<AddBackward0>)\n",
      "progress: 690 loss= 0.14222271740436554\n",
      "tensor([[ 2.2686, -1.2991, -0.7645],\n",
      "        [-0.8750,  0.9928,  0.1571],\n",
      "        [-3.3572,  0.8308,  3.1509],\n",
      "        [ 2.2686, -1.2991, -0.7645],\n",
      "        [ 2.2686, -1.2991, -0.7645],\n",
      "        [-0.4295, -1.4245,  2.4464]], grad_fn=<AddBackward0>)\n",
      "progress: 691 loss= 0.14212842285633087\n",
      "tensor([[ 2.2690, -1.2988, -0.7652],\n",
      "        [-0.8756,  0.9943,  0.1563],\n",
      "        [-3.3595,  0.8327,  3.1519],\n",
      "        [ 2.2690, -1.2988, -0.7652],\n",
      "        [ 2.2690, -1.2988, -0.7652],\n",
      "        [-0.4299, -1.4244,  2.4472]], grad_fn=<AddBackward0>)\n",
      "progress: 692 loss= 0.1419667899608612\n",
      "tensor([[ 2.2701, -1.2998, -0.7654],\n",
      "        [-0.8761,  0.9947,  0.1564],\n",
      "        [-3.3606,  0.8322,  3.1536],\n",
      "        [ 2.2701, -1.2998, -0.7654],\n",
      "        [ 2.2701, -1.2998, -0.7654],\n",
      "        [-0.4303, -1.4255,  2.4486]], grad_fn=<AddBackward0>)\n",
      "progress: 693 loss= 0.14182578027248383\n",
      "tensor([[ 2.2704, -1.2994, -0.7660],\n",
      "        [-0.8764,  0.9959,  0.1556],\n",
      "        [-3.3627,  0.8344,  3.1534],\n",
      "        [ 2.2704, -1.2994, -0.7660],\n",
      "        [ 2.2704, -1.2994, -0.7660],\n",
      "        [-0.4305, -1.4253,  2.4487]], grad_fn=<AddBackward0>)\n",
      "progress: 694 loss= 0.14172880351543427\n",
      "tensor([[ 2.2716, -1.3004, -0.7664],\n",
      "        [-0.8772,  0.9965,  0.1558],\n",
      "        [-3.3638,  0.8338,  3.1554],\n",
      "        [ 2.2716, -1.3004, -0.7664],\n",
      "        [ 2.2716, -1.3004, -0.7664],\n",
      "        [-0.4309, -1.4265,  2.4504]], grad_fn=<AddBackward0>)\n",
      "progress: 695 loss= 0.14154690504074097\n",
      "tensor([[ 2.2712, -1.2999, -0.7663],\n",
      "        [-0.8785,  0.9977,  0.1560],\n",
      "        [-3.3674,  0.8360,  3.1572],\n",
      "        [ 2.2712, -1.2999, -0.7663],\n",
      "        [ 2.2712, -1.2999, -0.7663],\n",
      "        [-0.4326, -1.4262,  2.4520]], grad_fn=<AddBackward0>)\n",
      "progress: 696 loss= 0.1414625495672226\n",
      "tensor([[ 2.2730, -1.3009, -0.7672],\n",
      "        [-0.8783,  0.9983,  0.1551],\n",
      "        [-3.3670,  0.8354,  3.1571],\n",
      "        [ 2.2730, -1.3009, -0.7672],\n",
      "        [ 2.2730, -1.3009, -0.7672],\n",
      "        [-0.4316, -1.4274,  2.4521]], grad_fn=<AddBackward0>)\n",
      "progress: 697 loss= 0.14128267765045166\n",
      "tensor([[ 2.2740, -1.3019, -0.7673],\n",
      "        [-0.8783,  0.9980,  0.1552],\n",
      "        [-3.3682,  0.8348,  3.1592],\n",
      "        [ 2.2740, -1.3019, -0.7673],\n",
      "        [ 2.2740, -1.3019, -0.7673],\n",
      "        [-0.4320, -1.4285,  2.4539]], grad_fn=<AddBackward0>)\n",
      "progress: 698 loss= 0.1411907821893692\n",
      "tensor([[ 2.2743, -1.3015, -0.7679],\n",
      "        [-0.8791,  0.9999,  0.1545],\n",
      "        [-3.3705,  0.8368,  3.1599],\n",
      "        [ 2.2743, -1.3015, -0.7679],\n",
      "        [ 2.2743, -1.3015, -0.7679],\n",
      "        [-0.4323, -1.4285,  2.4544]], grad_fn=<AddBackward0>)\n",
      "progress: 699 loss= 0.14102107286453247\n",
      "tensor([[ 2.2756, -1.3025, -0.7684],\n",
      "        [-0.8794,  0.9999,  0.1546],\n",
      "        [-3.3713,  0.8364,  3.1607],\n",
      "        [ 2.2756, -1.3025, -0.7684],\n",
      "        [ 2.2756, -1.3025, -0.7684],\n",
      "        [-0.4326, -1.4294,  2.4553]], grad_fn=<AddBackward0>)\n",
      "progress: 700 loss= 0.14091850817203522\n",
      "tensor([[ 2.2757, -1.3020, -0.7688],\n",
      "        [-0.8799,  1.0014,  0.1538],\n",
      "        [-3.3737,  0.8384,  3.1617],\n",
      "        [ 2.2757, -1.3020, -0.7688],\n",
      "        [ 2.2757, -1.3020, -0.7688],\n",
      "        [-0.4329, -1.4294,  2.4561]], grad_fn=<AddBackward0>)\n",
      "progress: 701 loss= 0.1407717764377594\n",
      "tensor([[ 2.2769, -1.3031, -0.7689],\n",
      "        [-0.8805,  1.0017,  0.1541],\n",
      "        [-3.3748,  0.8378,  3.1637],\n",
      "        [ 2.2769, -1.3031, -0.7689],\n",
      "        [ 2.2769, -1.3031, -0.7689],\n",
      "        [-0.4334, -1.4305,  2.4579]], grad_fn=<AddBackward0>)\n",
      "progress: 702 loss= 0.1406375616788864\n",
      "tensor([[ 2.2767, -1.3025, -0.7694],\n",
      "        [-0.8820,  1.0032,  0.1539],\n",
      "        [-3.3781,  0.8403,  3.1643],\n",
      "        [ 2.2767, -1.3025, -0.7694],\n",
      "        [ 2.2767, -1.3025, -0.7694],\n",
      "        [-0.4348, -1.4301,  2.4587]], grad_fn=<AddBackward0>)\n",
      "progress: 703 loss= 0.14051875472068787\n",
      "tensor([[ 2.2782, -1.3036, -0.7698],\n",
      "        [-0.8815,  1.0036,  0.1532],\n",
      "        [-3.3780,  0.8394,  3.1654],\n",
      "        [ 2.2782, -1.3036, -0.7698],\n",
      "        [ 2.2782, -1.3036, -0.7698],\n",
      "        [-0.4340, -1.4315,  2.4596]], grad_fn=<AddBackward0>)\n",
      "progress: 704 loss= 0.14035679399967194\n",
      "tensor([[ 2.2782, -1.3032, -0.7702],\n",
      "        [-0.8829,  1.0048,  0.1534],\n",
      "        [-3.3815,  0.8417,  3.1670],\n",
      "        [ 2.2782, -1.3032, -0.7702],\n",
      "        [ 2.2782, -1.3032, -0.7702],\n",
      "        [-0.4355, -1.4312,  2.4610]], grad_fn=<AddBackward0>)\n",
      "progress: 705 loss= 0.14025132358074188\n",
      "tensor([[ 2.2796, -1.3042, -0.7708],\n",
      "        [-0.8826,  1.0054,  0.1525],\n",
      "        [-3.3811,  0.8410,  3.1669],\n",
      "        [ 2.2796, -1.3042, -0.7708],\n",
      "        [ 2.2796, -1.3042, -0.7708],\n",
      "        [-0.4345, -1.4324,  2.4611]], grad_fn=<AddBackward0>)\n",
      "progress: 706 loss= 0.14009727537631989\n",
      "tensor([[ 2.2796, -1.3037, -0.7712],\n",
      "        [-0.8837,  1.0063,  0.1526],\n",
      "        [-3.3847,  0.8432,  3.1688],\n",
      "        [ 2.2796, -1.3037, -0.7712],\n",
      "        [ 2.2796, -1.3037, -0.7712],\n",
      "        [-0.4362, -1.4321,  2.4627]], grad_fn=<AddBackward0>)\n",
      "progress: 707 loss= 0.13999515771865845\n",
      "tensor([[ 2.2805, -1.3046, -0.7712],\n",
      "        [-0.8847,  1.0072,  0.1527],\n",
      "        [-3.3857,  0.8427,  3.1705],\n",
      "        [ 2.2805, -1.3046, -0.7712],\n",
      "        [ 2.2805, -1.3046, -0.7712],\n",
      "        [-0.4365, -1.4332,  2.4642]], grad_fn=<AddBackward0>)\n",
      "progress: 708 loss= 0.1398269236087799\n",
      "tensor([[ 2.2822, -1.3057, -0.7719],\n",
      "        [-0.8837,  1.0069,  0.1520],\n",
      "        [-3.3854,  0.8420,  3.1704],\n",
      "        [ 2.2822, -1.3057, -0.7719],\n",
      "        [ 2.2822, -1.3057, -0.7719],\n",
      "        [-0.4355, -1.4345,  2.4643]], grad_fn=<AddBackward0>)\n",
      "progress: 709 loss= 0.13974027335643768\n",
      "tensor([[ 2.2821, -1.3052, -0.7722],\n",
      "        [-0.8855,  1.0088,  0.1520],\n",
      "        [-3.3889,  0.8443,  3.1723],\n",
      "        [ 2.2821, -1.3052, -0.7722],\n",
      "        [ 2.2821, -1.3052, -0.7722],\n",
      "        [-0.4371, -1.4342,  2.4659]], grad_fn=<AddBackward0>)\n",
      "progress: 710 loss= 0.13957364857196808\n",
      "tensor([[ 2.2835, -1.3063, -0.7725],\n",
      "        [-0.8848,  1.0087,  0.1515],\n",
      "        [-3.3888,  0.8434,  3.1734],\n",
      "        [ 2.2835, -1.3063, -0.7725],\n",
      "        [ 2.2835, -1.3063, -0.7725],\n",
      "        [-0.4363, -1.4356,  2.4668]], grad_fn=<AddBackward0>)\n",
      "progress: 711 loss= 0.13945861160755157\n",
      "tensor([[ 2.2836, -1.3058, -0.7731],\n",
      "        [-0.8863,  1.0103,  0.1514],\n",
      "        [-3.3921,  0.8458,  3.1740],\n",
      "        [ 2.2836, -1.3058, -0.7731],\n",
      "        [ 2.2836, -1.3058, -0.7731],\n",
      "        [-0.4378, -1.4351,  2.4677]], grad_fn=<AddBackward0>)\n",
      "progress: 712 loss= 0.13932521641254425\n",
      "tensor([[ 2.2844, -1.3067, -0.7731],\n",
      "        [-0.8871,  1.0109,  0.1515],\n",
      "        [-3.3932,  0.8452,  3.1760],\n",
      "        [ 2.2844, -1.3067, -0.7731],\n",
      "        [ 2.2844, -1.3067, -0.7731],\n",
      "        [-0.4382, -1.4363,  2.4694]], grad_fn=<AddBackward0>)\n",
      "progress: 713 loss= 0.13918127119541168\n",
      "tensor([[ 2.2849, -1.3064, -0.7739],\n",
      "        [-0.8872,  1.0118,  0.1508],\n",
      "        [-3.3955,  0.8472,  3.1767],\n",
      "        [ 2.2849, -1.3064, -0.7739],\n",
      "        [ 2.2849, -1.3064, -0.7739],\n",
      "        [-0.4385, -1.4362,  2.4699]], grad_fn=<AddBackward0>)\n",
      "progress: 714 loss= 0.1390676349401474\n",
      "tensor([[ 2.2859, -1.3073, -0.7741],\n",
      "        [-0.8881,  1.0127,  0.1508],\n",
      "        [-3.3963,  0.8468,  3.1775],\n",
      "        [ 2.2859, -1.3073, -0.7741],\n",
      "        [ 2.2859, -1.3073, -0.7741],\n",
      "        [-0.4387, -1.4372,  2.4708]], grad_fn=<AddBackward0>)\n",
      "progress: 715 loss= 0.1389152854681015\n",
      "tensor([[ 2.2862, -1.3070, -0.7747],\n",
      "        [-0.8880,  1.0134,  0.1501],\n",
      "        [-3.3986,  0.8488,  3.1785],\n",
      "        [ 2.2862, -1.3070, -0.7747],\n",
      "        [ 2.2862, -1.3070, -0.7747],\n",
      "        [-0.4391, -1.4372,  2.4716]], grad_fn=<AddBackward0>)\n",
      "progress: 716 loss= 0.13882382214069366\n",
      "tensor([[ 2.2874, -1.3080, -0.7748],\n",
      "        [-0.8891,  1.0143,  0.1504],\n",
      "        [-3.3997,  0.8482,  3.1805],\n",
      "        [ 2.2874, -1.3080, -0.7748],\n",
      "        [ 2.2874, -1.3080, -0.7748],\n",
      "        [-0.4395, -1.4383,  2.4733]], grad_fn=<AddBackward0>)\n",
      "progress: 717 loss= 0.13864637911319733\n",
      "tensor([[ 2.2887, -1.3089, -0.7754],\n",
      "        [-0.8879,  1.0139,  0.1495],\n",
      "        [-3.3993,  0.8475,  3.1804],\n",
      "        [ 2.2887, -1.3089, -0.7754],\n",
      "        [ 2.2887, -1.3089, -0.7754],\n",
      "        [-0.4385, -1.4396,  2.4735]], grad_fn=<AddBackward0>)\n",
      "progress: 718 loss= 0.13856816291809082\n",
      "tensor([[ 2.2888, -1.3085, -0.7758],\n",
      "        [-0.8898,  1.0158,  0.1495],\n",
      "        [-3.4029,  0.8497,  3.1822],\n",
      "        [ 2.2888, -1.3085, -0.7758],\n",
      "        [ 2.2888, -1.3085, -0.7758],\n",
      "        [-0.4401, -1.4393,  2.4751]], grad_fn=<AddBackward0>)\n",
      "progress: 719 loss= 0.1383923888206482\n",
      "tensor([[ 2.2897, -1.3094, -0.7759],\n",
      "        [-0.8903,  1.0160,  0.1497],\n",
      "        [-3.4039,  0.8492,  3.1840],\n",
      "        [ 2.2897, -1.3094, -0.7759],\n",
      "        [ 2.2897, -1.3094, -0.7759],\n",
      "        [-0.4404, -1.4403,  2.4765]], grad_fn=<AddBackward0>)\n",
      "progress: 720 loss= 0.13828332722187042\n",
      "tensor([[ 2.2901, -1.3090, -0.7767],\n",
      "        [-0.8907,  1.0174,  0.1488],\n",
      "        [-3.4060,  0.8513,  3.1837],\n",
      "        [ 2.2901, -1.3090, -0.7767],\n",
      "        [ 2.2901, -1.3090, -0.7767],\n",
      "        [-0.4406, -1.4402,  2.4765]], grad_fn=<AddBackward0>)\n",
      "progress: 721 loss= 0.138161763548851\n",
      "tensor([[ 2.2913, -1.3100, -0.7770],\n",
      "        [-0.8913,  1.0179,  0.1489],\n",
      "        [-3.4071,  0.8507,  3.1857],\n",
      "        [ 2.2913, -1.3100, -0.7770],\n",
      "        [ 2.2913, -1.3100, -0.7770],\n",
      "        [-0.4410, -1.4413,  2.4783]], grad_fn=<AddBackward0>)\n",
      "progress: 722 loss= 0.13800354301929474\n",
      "tensor([[ 2.2914, -1.3096, -0.7772],\n",
      "        [-0.8915,  1.0189,  0.1484],\n",
      "        [-3.4094,  0.8527,  3.1867],\n",
      "        [ 2.2914, -1.3096, -0.7772],\n",
      "        [ 2.2914, -1.3096, -0.7772],\n",
      "        [-0.4414, -1.4413,  2.4790]], grad_fn=<AddBackward0>)\n",
      "progress: 723 loss= 0.13791470229625702\n",
      "tensor([[ 2.2927, -1.3106, -0.7778],\n",
      "        [-0.8924,  1.0197,  0.1483],\n",
      "        [-3.4102,  0.8523,  3.1874],\n",
      "        [ 2.2927, -1.3106, -0.7778],\n",
      "        [ 2.2927, -1.3106, -0.7778],\n",
      "        [-0.4416, -1.4423,  2.4800]], grad_fn=<AddBackward0>)\n",
      "progress: 724 loss= 0.13773977756500244\n",
      "tensor([[ 2.2923, -1.3101, -0.7779],\n",
      "        [-0.8935,  1.0207,  0.1483],\n",
      "        [-3.4137,  0.8545,  3.1893],\n",
      "        [ 2.2923, -1.3101, -0.7779],\n",
      "        [ 2.2923, -1.3101, -0.7779],\n",
      "        [-0.4432, -1.4420,  2.4816]], grad_fn=<AddBackward0>)\n",
      "progress: 725 loss= 0.1376550942659378\n",
      "tensor([[ 2.2940, -1.3112, -0.7784],\n",
      "        [-0.8933,  1.0213,  0.1477],\n",
      "        [-3.4135,  0.8537,  3.1902],\n",
      "        [ 2.2940, -1.3112, -0.7784],\n",
      "        [ 2.2940, -1.3112, -0.7784],\n",
      "        [-0.4423, -1.4434,  2.4822]], grad_fn=<AddBackward0>)\n",
      "progress: 726 loss= 0.13748471438884735\n",
      "tensor([[ 2.2951, -1.3121, -0.7788],\n",
      "        [-0.8934,  1.0212,  0.1477],\n",
      "        [-3.4144,  0.8533,  3.1909],\n",
      "        [ 2.2951, -1.3121, -0.7788],\n",
      "        [ 2.2951, -1.3121, -0.7788],\n",
      "        [-0.4426, -1.4443,  2.4832]], grad_fn=<AddBackward0>)\n",
      "progress: 727 loss= 0.13739991188049316\n",
      "tensor([[ 2.2953, -1.3117, -0.7794],\n",
      "        [-0.8941,  1.0229,  0.1469],\n",
      "        [-3.4167,  0.8552,  3.1919],\n",
      "        [ 2.2953, -1.3117, -0.7794],\n",
      "        [ 2.2953, -1.3117, -0.7794],\n",
      "        [-0.4429, -1.4443,  2.4839]], grad_fn=<AddBackward0>)\n",
      "progress: 728 loss= 0.1372375339269638\n",
      "tensor([[ 2.2966, -1.3127, -0.7797],\n",
      "        [-0.8945,  1.0230,  0.1471],\n",
      "        [-3.4177,  0.8547,  3.1936],\n",
      "        [ 2.2966, -1.3127, -0.7797],\n",
      "        [ 2.2966, -1.3127, -0.7797],\n",
      "        [-0.4433, -1.4454,  2.4854]], grad_fn=<AddBackward0>)\n",
      "progress: 729 loss= 0.1371152549982071\n",
      "tensor([[ 2.2962, -1.3121, -0.7799],\n",
      "        [-0.8962,  1.0247,  0.1471],\n",
      "        [-3.4210,  0.8571,  3.1942],\n",
      "        [ 2.2962, -1.3121, -0.7799],\n",
      "        [ 2.2962, -1.3121, -0.7799],\n",
      "        [-0.4447, -1.4450,  2.4862]], grad_fn=<AddBackward0>)\n",
      "progress: 730 loss= 0.13700883090496063\n",
      "tensor([[ 2.2979, -1.3132, -0.7805],\n",
      "        [-0.8956,  1.0248,  0.1464],\n",
      "        [-3.4208,  0.8562,  3.1953],\n",
      "        [ 2.2979, -1.3132, -0.7805],\n",
      "        [ 2.2979, -1.3132, -0.7805],\n",
      "        [-0.4439, -1.4464,  2.4871]], grad_fn=<AddBackward0>)\n",
      "progress: 731 loss= 0.13685409724712372\n",
      "tensor([[ 2.2977, -1.3128, -0.7806],\n",
      "        [-0.8970,  1.0262,  0.1466],\n",
      "        [-3.4243,  0.8584,  3.1972],\n",
      "        [ 2.2977, -1.3128, -0.7806],\n",
      "        [ 2.2977, -1.3128, -0.7806],\n",
      "        [-0.4454, -1.4461,  2.4887]], grad_fn=<AddBackward0>)\n",
      "progress: 732 loss= 0.1367490440607071\n",
      "tensor([[ 2.2992, -1.3138, -0.7813],\n",
      "        [-0.8966,  1.0267,  0.1457],\n",
      "        [-3.4240,  0.8577,  3.1971],\n",
      "        [ 2.2992, -1.3138, -0.7813],\n",
      "        [ 2.2992, -1.3138, -0.7813],\n",
      "        [-0.4444, -1.4474,  2.4888]], grad_fn=<AddBackward0>)\n",
      "progress: 733 loss= 0.13659849762916565\n",
      "tensor([[ 2.2992, -1.3133, -0.7817],\n",
      "        [-0.8978,  1.0277,  0.1458],\n",
      "        [-3.4275,  0.8599,  3.1989],\n",
      "        [ 2.2992, -1.3133, -0.7817],\n",
      "        [ 2.2992, -1.3133, -0.7817],\n",
      "        [-0.4460, -1.4471,  2.4904]], grad_fn=<AddBackward0>)\n",
      "progress: 734 loss= 0.1364896148443222\n",
      "tensor([[ 2.3005, -1.3143, -0.7820],\n",
      "        [-0.8976,  1.0283,  0.1451],\n",
      "        [-3.4273,  0.8591,  3.1998],\n",
      "        [ 2.3005, -1.3143, -0.7820],\n",
      "        [ 2.3005, -1.3143, -0.7820],\n",
      "        [-0.4451, -1.4484,  2.4910]], grad_fn=<AddBackward0>)\n",
      "progress: 735 loss= 0.13633793592453003\n",
      "tensor([[ 2.3017, -1.3153, -0.7825],\n",
      "        [-0.8976,  1.0281,  0.1452],\n",
      "        [-3.4281,  0.8587,  3.2005],\n",
      "        [ 2.3017, -1.3153, -0.7825],\n",
      "        [ 2.3017, -1.3153, -0.7825],\n",
      "        [-0.4454, -1.4494,  2.4920]], grad_fn=<AddBackward0>)\n",
      "progress: 736 loss= 0.13625411689281464\n",
      "tensor([[ 2.3015, -1.3148, -0.7827],\n",
      "        [-0.8996,  1.0301,  0.1452],\n",
      "        [-3.4316,  0.8609,  3.2023],\n",
      "        [ 2.3015, -1.3148, -0.7827],\n",
      "        [ 2.3015, -1.3148, -0.7827],\n",
      "        [-0.4469, -1.4491,  2.4936]], grad_fn=<AddBackward0>)\n",
      "progress: 737 loss= 0.13608692586421967\n",
      "tensor([[ 2.3030, -1.3159, -0.7830],\n",
      "        [-0.8988,  1.0299,  0.1448],\n",
      "        [-3.4315,  0.8600,  3.2035],\n",
      "        [ 2.3030, -1.3159, -0.7830],\n",
      "        [ 2.3030, -1.3159, -0.7830],\n",
      "        [-0.4461, -1.4505,  2.4945]], grad_fn=<AddBackward0>)\n",
      "progress: 738 loss= 0.13598866760730743\n",
      "tensor([[ 2.3030, -1.3154, -0.7836],\n",
      "        [-0.9004,  1.0317,  0.1445],\n",
      "        [-3.4347,  0.8624,  3.2040],\n",
      "        [ 2.3030, -1.3154, -0.7836],\n",
      "        [ 2.3030, -1.3154, -0.7836],\n",
      "        [-0.4475, -1.4501,  2.4953]], grad_fn=<AddBackward0>)\n",
      "progress: 739 loss= 0.13584469258785248\n",
      "tensor([[ 2.3043, -1.3164, -0.7839],\n",
      "        [-0.8998,  1.0318,  0.1438],\n",
      "        [-3.4346,  0.8615,  3.2052],\n",
      "        [ 2.3043, -1.3164, -0.7839],\n",
      "        [ 2.3043, -1.3164, -0.7839],\n",
      "        [-0.4467, -1.4515,  2.4962]], grad_fn=<AddBackward0>)\n",
      "progress: 740 loss= 0.1357170194387436\n",
      "tensor([[ 2.3044, -1.3160, -0.7843],\n",
      "        [-0.9013,  1.0332,  0.1440],\n",
      "        [-3.4380,  0.8638,  3.2068],\n",
      "        [ 2.3044, -1.3160, -0.7843],\n",
      "        [ 2.3044, -1.3160, -0.7843],\n",
      "        [-0.4482, -1.4512,  2.4975]], grad_fn=<AddBackward0>)\n",
      "progress: 741 loss= 0.13559915125370026\n",
      "tensor([[ 2.3053, -1.3168, -0.7846],\n",
      "        [-0.9020,  1.0339,  0.1440],\n",
      "        [-3.4388,  0.8634,  3.2075],\n",
      "        [ 2.3053, -1.3168, -0.7846],\n",
      "        [ 2.3053, -1.3168, -0.7846],\n",
      "        [-0.4484, -1.4522,  2.4985]], grad_fn=<AddBackward0>)\n",
      "progress: 742 loss= 0.13546237349510193\n",
      "tensor([[ 2.3057, -1.3165, -0.7852],\n",
      "        [-0.9020,  1.0347,  0.1432],\n",
      "        [-3.4411,  0.8653,  3.2085],\n",
      "        [ 2.3057, -1.3165, -0.7852],\n",
      "        [ 2.3057, -1.3165, -0.7852],\n",
      "        [-0.4488, -1.4522,  2.4992]], grad_fn=<AddBackward0>)\n",
      "progress: 743 loss= 0.1353568434715271\n",
      "tensor([[ 2.3068, -1.3175, -0.7852],\n",
      "        [-0.9031,  1.0356,  0.1436],\n",
      "        [-3.4422,  0.8647,  3.2104],\n",
      "        [ 2.3068, -1.3175, -0.7852],\n",
      "        [ 2.3068, -1.3175, -0.7852],\n",
      "        [-0.4492, -1.4533,  2.5009]], grad_fn=<AddBackward0>)\n",
      "progress: 744 loss= 0.13519731163978577\n",
      "tensor([[ 2.3082, -1.3184, -0.7859],\n",
      "        [-0.9018,  1.0351,  0.1426],\n",
      "        [-3.4418,  0.8640,  3.2103],\n",
      "        [ 2.3082, -1.3184, -0.7859],\n",
      "        [ 2.3082, -1.3184, -0.7859],\n",
      "        [-0.4482, -1.4546,  2.5010]], grad_fn=<AddBackward0>)\n",
      "progress: 745 loss= 0.13512194156646729\n",
      "tensor([[ 2.3082, -1.3180, -0.7863],\n",
      "        [-0.9038,  1.0371,  0.1426],\n",
      "        [-3.4452,  0.8662,  3.2122],\n",
      "        [ 2.3082, -1.3180, -0.7863],\n",
      "        [ 2.3082, -1.3180, -0.7863],\n",
      "        [-0.4497, -1.4543,  2.5026]], grad_fn=<AddBackward0>)\n",
      "progress: 746 loss= 0.13494209945201874\n",
      "tensor([[ 2.3091, -1.3189, -0.7864],\n",
      "        [-0.9041,  1.0372,  0.1427],\n",
      "        [-3.4460,  0.8658,  3.2129],\n",
      "        [ 2.3091, -1.3189, -0.7864],\n",
      "        [ 2.3091, -1.3189, -0.7864],\n",
      "        [-0.4499, -1.4553,  2.5036]], grad_fn=<AddBackward0>)\n",
      "progress: 747 loss= 0.1348658949136734\n",
      "tensor([[ 2.3095, -1.3185, -0.7871],\n",
      "        [-0.9046,  1.0387,  0.1419],\n",
      "        [-3.4483,  0.8677,  3.2139],\n",
      "        [ 2.3095, -1.3185, -0.7871],\n",
      "        [ 2.3095, -1.3185, -0.7871],\n",
      "        [-0.4503, -1.4553,  2.5043]], grad_fn=<AddBackward0>)\n",
      "progress: 748 loss= 0.13470959663391113\n",
      "tensor([[ 2.3105, -1.3195, -0.7871],\n",
      "        [-0.9052,  1.0389,  0.1422],\n",
      "        [-3.4494,  0.8671,  3.2158],\n",
      "        [ 2.3105, -1.3195, -0.7871],\n",
      "        [ 2.3105, -1.3195, -0.7871],\n",
      "        [-0.4507, -1.4564,  2.5060]], grad_fn=<AddBackward0>)\n",
      "progress: 749 loss= 0.13458867371082306\n",
      "tensor([[ 2.3108, -1.3191, -0.7879],\n",
      "        [-0.9054,  1.0402,  0.1413],\n",
      "        [-3.4514,  0.8692,  3.2156],\n",
      "        [ 2.3108, -1.3191, -0.7879],\n",
      "        [ 2.3108, -1.3191, -0.7879],\n",
      "        [-0.4509, -1.4563,  2.5061]], grad_fn=<AddBackward0>)\n",
      "progress: 750 loss= 0.134481742978096\n",
      "tensor([[ 2.3120, -1.3201, -0.7882],\n",
      "        [-0.9062,  1.0408,  0.1414],\n",
      "        [-3.4524,  0.8686,  3.2175],\n",
      "        [ 2.3120, -1.3201, -0.7882],\n",
      "        [ 2.3120, -1.3201, -0.7882],\n",
      "        [-0.4512, -1.4574,  2.5077]], grad_fn=<AddBackward0>)\n",
      "progress: 751 loss= 0.13431687653064728\n",
      "tensor([[ 2.3116, -1.3195, -0.7882],\n",
      "        [-0.9075,  1.0419,  0.1415],\n",
      "        [-3.4559,  0.8708,  3.2191],\n",
      "        [ 2.3116, -1.3195, -0.7882],\n",
      "        [ 2.3116, -1.3195, -0.7882],\n",
      "        [-0.4527, -1.4571,  2.5091]], grad_fn=<AddBackward0>)\n",
      "progress: 752 loss= 0.13423670828342438\n",
      "tensor([[ 2.3134, -1.3206, -0.7891],\n",
      "        [-0.9072,  1.0426,  0.1407],\n",
      "        [-3.4554,  0.8701,  3.2190],\n",
      "        [ 2.3134, -1.3206, -0.7891],\n",
      "        [ 2.3134, -1.3206, -0.7891],\n",
      "        [-0.4517, -1.4583,  2.5092]], grad_fn=<AddBackward0>)\n",
      "progress: 753 loss= 0.13407418131828308\n",
      "tensor([[ 2.3144, -1.3215, -0.7892],\n",
      "        [-0.9072,  1.0423,  0.1409],\n",
      "        [-3.4565,  0.8695,  3.2209],\n",
      "        [ 2.3144, -1.3215, -0.7892],\n",
      "        [ 2.3144, -1.3215, -0.7892],\n",
      "        [-0.4521, -1.4595,  2.5109]], grad_fn=<AddBackward0>)\n",
      "progress: 754 loss= 0.13398946821689606\n",
      "tensor([[ 2.3146, -1.3211, -0.7898],\n",
      "        [-0.9080,  1.0441,  0.1400],\n",
      "        [-3.4587,  0.8715,  3.2217],\n",
      "        [ 2.3146, -1.3211, -0.7898],\n",
      "        [ 2.3146, -1.3211, -0.7898],\n",
      "        [-0.4524, -1.4594,  2.5114]], grad_fn=<AddBackward0>)\n",
      "progress: 755 loss= 0.13382546603679657\n",
      "tensor([[ 2.3159, -1.3221, -0.7901],\n",
      "        [-0.9083,  1.0440,  0.1404],\n",
      "        [-3.4597,  0.8709,  3.2234],\n",
      "        [ 2.3159, -1.3221, -0.7901],\n",
      "        [ 2.3159, -1.3221, -0.7901],\n",
      "        [-0.4527, -1.4605,  2.5128]], grad_fn=<AddBackward0>)\n",
      "progress: 756 loss= 0.13372626900672913\n",
      "tensor([[ 2.3159, -1.3217, -0.7906],\n",
      "        [-0.9088,  1.0456,  0.1394],\n",
      "        [-3.4617,  0.8730,  3.2231],\n",
      "        [ 2.3159, -1.3217, -0.7906],\n",
      "        [ 2.3159, -1.3217, -0.7906],\n",
      "        [-0.4529, -1.4603,  2.5128]], grad_fn=<AddBackward0>)\n",
      "progress: 757 loss= 0.13360626995563507\n",
      "tensor([[ 2.3172, -1.3226, -0.7909],\n",
      "        [-0.9093,  1.0459,  0.1395],\n",
      "        [-3.4628,  0.8724,  3.2251],\n",
      "        [ 2.3172, -1.3226, -0.7909],\n",
      "        [ 2.3172, -1.3226, -0.7909],\n",
      "        [-0.4533, -1.4615,  2.5145]], grad_fn=<AddBackward0>)\n",
      "progress: 758 loss= 0.13346602022647858\n",
      "tensor([[ 2.3169, -1.3222, -0.7910],\n",
      "        [-0.9109,  1.0473,  0.1399],\n",
      "        [-3.4662,  0.8746,  3.2269],\n",
      "        [ 2.3169, -1.3222, -0.7910],\n",
      "        [ 2.3169, -1.3222, -0.7910],\n",
      "        [-0.4548, -1.4612,  2.5161]], grad_fn=<AddBackward0>)\n",
      "progress: 759 loss= 0.13336287438869476\n",
      "tensor([[ 2.3185, -1.3232, -0.7917],\n",
      "        [-0.9103,  1.0477,  0.1388],\n",
      "        [-3.4658,  0.8739,  3.2268],\n",
      "        [ 2.3185, -1.3232, -0.7917],\n",
      "        [ 2.3185, -1.3232, -0.7917],\n",
      "        [-0.4538, -1.4625,  2.5162]], grad_fn=<AddBackward0>)\n",
      "progress: 760 loss= 0.13321910798549652\n",
      "tensor([[ 2.3184, -1.3227, -0.7920],\n",
      "        [-0.9116,  1.0489,  0.1389],\n",
      "        [-3.4693,  0.8761,  3.2286],\n",
      "        [ 2.3184, -1.3227, -0.7920],\n",
      "        [ 2.3184, -1.3227, -0.7920],\n",
      "        [-0.4554, -1.4622,  2.5178]], grad_fn=<AddBackward0>)\n",
      "progress: 761 loss= 0.1331074833869934\n",
      "tensor([[ 2.3197, -1.3237, -0.7925],\n",
      "        [-0.9114,  1.0495,  0.1381],\n",
      "        [-3.4689,  0.8754,  3.2285],\n",
      "        [ 2.3197, -1.3237, -0.7925],\n",
      "        [ 2.3197, -1.3237, -0.7925],\n",
      "        [-0.4544, -1.4635,  2.5179]], grad_fn=<AddBackward0>)\n",
      "progress: 762 loss= 0.13297288119792938\n",
      "tensor([[ 2.3198, -1.3233, -0.7929],\n",
      "        [-0.9124,  1.0504,  0.1382],\n",
      "        [-3.4723,  0.8775,  3.2303],\n",
      "        [ 2.3198, -1.3233, -0.7929],\n",
      "        [ 2.3198, -1.3233, -0.7929],\n",
      "        [-0.4560, -1.4632,  2.5195]], grad_fn=<AddBackward0>)\n",
      "progress: 763 loss= 0.13287661969661713\n",
      "tensor([[ 2.3207, -1.3242, -0.7928],\n",
      "        [-0.9135,  1.0513,  0.1385],\n",
      "        [-3.4734,  0.8769,  3.2322],\n",
      "        [ 2.3207, -1.3242, -0.7928],\n",
      "        [ 2.3207, -1.3242, -0.7928],\n",
      "        [-0.4563, -1.4643,  2.5212]], grad_fn=<AddBackward0>)\n",
      "progress: 764 loss= 0.1327226608991623\n",
      "tensor([[ 2.3223, -1.3252, -0.7936],\n",
      "        [-0.9124,  1.0510,  0.1376],\n",
      "        [-3.4729,  0.8763,  3.2321],\n",
      "        [ 2.3223, -1.3252, -0.7936],\n",
      "        [ 2.3223, -1.3252, -0.7936],\n",
      "        [-0.4553, -1.4656,  2.5213]], grad_fn=<AddBackward0>)\n",
      "progress: 765 loss= 0.13263386487960815\n",
      "tensor([[ 2.3222, -1.3248, -0.7939],\n",
      "        [-0.9142,  1.0528,  0.1376],\n",
      "        [-3.4764,  0.8784,  3.2339],\n",
      "        [ 2.3222, -1.3248, -0.7939],\n",
      "        [ 2.3222, -1.3248, -0.7939],\n",
      "        [-0.4569, -1.4653,  2.5229]], grad_fn=<AddBackward0>)\n",
      "progress: 766 loss= 0.13247503340244293\n",
      "tensor([[ 2.3235, -1.3257, -0.7943],\n",
      "        [-0.9134,  1.0527,  0.1370],\n",
      "        [-3.4762,  0.8776,  3.2348],\n",
      "        [ 2.3235, -1.3257, -0.7943],\n",
      "        [ 2.3235, -1.3257, -0.7943],\n",
      "        [-0.4560, -1.4667,  2.5235]], grad_fn=<AddBackward0>)\n",
      "progress: 767 loss= 0.13237327337265015\n",
      "tensor([[ 2.3236, -1.3253, -0.7948],\n",
      "        [-0.9150,  1.0543,  0.1370],\n",
      "        [-3.4793,  0.8799,  3.2353],\n",
      "        [ 2.3236, -1.3253, -0.7948],\n",
      "        [ 2.3236, -1.3253, -0.7948],\n",
      "        [-0.4573, -1.4663,  2.5243]], grad_fn=<AddBackward0>)\n",
      "progress: 768 loss= 0.13225315511226654\n",
      "tensor([[ 2.3244, -1.3262, -0.7949],\n",
      "        [-0.9157,  1.0548,  0.1371],\n",
      "        [-3.4804,  0.8793,  3.2373],\n",
      "        [ 2.3244, -1.3262, -0.7949],\n",
      "        [ 2.3244, -1.3262, -0.7949],\n",
      "        [-0.4577, -1.4674,  2.5260]], grad_fn=<AddBackward0>)\n",
      "progress: 769 loss= 0.13211552798748016\n",
      "tensor([[ 2.3248, -1.3259, -0.7953],\n",
      "        [-0.9158,  1.0558,  0.1365],\n",
      "        [-3.4826,  0.8812,  3.2383],\n",
      "        [ 2.3248, -1.3259, -0.7953],\n",
      "        [ 2.3248, -1.3259, -0.7953],\n",
      "        [-0.4581, -1.4674,  2.5268]], grad_fn=<AddBackward0>)\n",
      "progress: 770 loss= 0.13201913237571716\n",
      "tensor([[ 2.3259, -1.3268, -0.7958],\n",
      "        [-0.9167,  1.0566,  0.1364],\n",
      "        [-3.4834,  0.8808,  3.2390],\n",
      "        [ 2.3259, -1.3268, -0.7958],\n",
      "        [ 2.3259, -1.3268, -0.7958],\n",
      "        [-0.4582, -1.4684,  2.5277]], grad_fn=<AddBackward0>)\n",
      "progress: 771 loss= 0.1318611204624176\n",
      "tensor([[ 2.3261, -1.3264, -0.7962],\n",
      "        [-0.9166,  1.0573,  0.1356],\n",
      "        [-3.4856,  0.8827,  3.2400],\n",
      "        [ 2.3261, -1.3264, -0.7962],\n",
      "        [ 2.3261, -1.3264, -0.7962],\n",
      "        [-0.4586, -1.4684,  2.5285]], grad_fn=<AddBackward0>)\n",
      "progress: 772 loss= 0.13178129494190216\n",
      "tensor([[ 2.3273, -1.3274, -0.7965],\n",
      "        [-0.9176,  1.0582,  0.1359],\n",
      "        [-3.4866,  0.8821,  3.2417],\n",
      "        [ 2.3273, -1.3274, -0.7965],\n",
      "        [ 2.3273, -1.3274, -0.7965],\n",
      "        [-0.4589, -1.4695,  2.5299]], grad_fn=<AddBackward0>)\n",
      "progress: 773 loss= 0.1316141039133072\n",
      "tensor([[ 2.3282, -1.3282, -0.7968],\n",
      "        [-0.9177,  1.0581,  0.1358],\n",
      "        [-3.4874,  0.8817,  3.2424],\n",
      "        [ 2.3282, -1.3282, -0.7968],\n",
      "        [ 2.3282, -1.3282, -0.7968],\n",
      "        [-0.4591, -1.4705,  2.5308]], grad_fn=<AddBackward0>)\n",
      "progress: 774 loss= 0.13154657185077667\n",
      "tensor([[ 2.3286, -1.3279, -0.7975],\n",
      "        [-0.9183,  1.0597,  0.1350],\n",
      "        [-3.4896,  0.8835,  3.2433],\n",
      "        [ 2.3286, -1.3279, -0.7975],\n",
      "        [ 2.3286, -1.3279, -0.7975],\n",
      "        [-0.4594, -1.4705,  2.5316]], grad_fn=<AddBackward0>)\n",
      "progress: 775 loss= 0.13138212263584137\n",
      "tensor([[ 2.3296, -1.3288, -0.7974],\n",
      "        [-0.9188,  1.0598,  0.1355],\n",
      "        [-3.4907,  0.8829,  3.2453],\n",
      "        [ 2.3296, -1.3288, -0.7974],\n",
      "        [ 2.3296, -1.3288, -0.7974],\n",
      "        [-0.4598, -1.4716,  2.5332]], grad_fn=<AddBackward0>)\n",
      "progress: 776 loss= 0.1312856525182724\n",
      "tensor([[ 2.3299, -1.3284, -0.7982],\n",
      "        [-0.9191,  1.0612,  0.1344],\n",
      "        [-3.4926,  0.8850,  3.2450],\n",
      "        [ 2.3299, -1.3284, -0.7982],\n",
      "        [ 2.3299, -1.3284, -0.7982],\n",
      "        [-0.4600, -1.4715,  2.5332]], grad_fn=<AddBackward0>)\n",
      "progress: 777 loss= 0.13116219639778137\n",
      "tensor([[ 2.3311, -1.3294, -0.7984],\n",
      "        [-0.9197,  1.0617,  0.1345],\n",
      "        [-3.4937,  0.8844,  3.2470],\n",
      "        [ 2.3311, -1.3294, -0.7984],\n",
      "        [ 2.3311, -1.3294, -0.7984],\n",
      "        [-0.4603, -1.4726,  2.5349]], grad_fn=<AddBackward0>)\n",
      "progress: 778 loss= 0.13101603090763092\n",
      "tensor([[ 2.3307, -1.3289, -0.7985],\n",
      "        [-0.9211,  1.0630,  0.1347],\n",
      "        [-3.4970,  0.8866,  3.2485],\n",
      "        [ 2.3307, -1.3289, -0.7985],\n",
      "        [ 2.3307, -1.3289, -0.7985],\n",
      "        [-0.4618, -1.4723,  2.5362]], grad_fn=<AddBackward0>)\n",
      "progress: 779 loss= 0.13093271851539612\n",
      "tensor([[ 2.3324, -1.3299, -0.7993],\n",
      "        [-0.9208,  1.0635,  0.1338],\n",
      "        [-3.4966,  0.8859,  3.2484],\n",
      "        [ 2.3324, -1.3299, -0.7993],\n",
      "        [ 2.3324, -1.3299, -0.7993],\n",
      "        [-0.4608, -1.4736,  2.5363]], grad_fn=<AddBackward0>)\n",
      "progress: 780 loss= 0.13077940046787262\n",
      "tensor([[ 2.3322, -1.3294, -0.7996],\n",
      "        [-0.9219,  1.0645,  0.1339],\n",
      "        [-3.5000,  0.8880,  3.2502],\n",
      "        [ 2.3322, -1.3294, -0.7996],\n",
      "        [ 2.3322, -1.3294, -0.7996],\n",
      "        [-0.4623, -1.4733,  2.5379]], grad_fn=<AddBackward0>)\n",
      "progress: 781 loss= 0.1306883692741394\n",
      "tensor([[ 2.3337, -1.3304, -0.8000],\n",
      "        [-0.9217,  1.0651,  0.1332],\n",
      "        [-3.4998,  0.8872,  3.2510],\n",
      "        [ 2.3337, -1.3304, -0.8000],\n",
      "        [ 2.3337, -1.3304, -0.8000],\n",
      "        [-0.4614, -1.4747,  2.5385]], grad_fn=<AddBackward0>)\n",
      "progress: 782 loss= 0.1305340975522995\n",
      "tensor([[ 2.3349, -1.3314, -0.8004],\n",
      "        [-0.9217,  1.0649,  0.1333],\n",
      "        [-3.5006,  0.8868,  3.2517],\n",
      "        [ 2.3349, -1.3314, -0.8004],\n",
      "        [ 2.3349, -1.3314, -0.8004],\n",
      "        [-0.4616, -1.4757,  2.5394]], grad_fn=<AddBackward0>)\n",
      "progress: 783 loss= 0.13045579195022583\n",
      "tensor([[ 2.3345, -1.3308, -0.8005],\n",
      "        [-0.9236,  1.0669,  0.1333],\n",
      "        [-3.5040,  0.8889,  3.2535],\n",
      "        [ 2.3345, -1.3308, -0.8005],\n",
      "        [ 2.3345, -1.3308, -0.8005],\n",
      "        [-0.4631, -1.4754,  2.5410]], grad_fn=<AddBackward0>)\n",
      "progress: 784 loss= 0.1303081065416336\n",
      "tensor([[ 2.3361, -1.3319, -0.8010],\n",
      "        [-0.9228,  1.0667,  0.1329],\n",
      "        [-3.5038,  0.8880,  3.2546],\n",
      "        [ 2.3361, -1.3319, -0.8010],\n",
      "        [ 2.3361, -1.3319, -0.8010],\n",
      "        [-0.4623, -1.4768,  2.5419]], grad_fn=<AddBackward0>)\n",
      "progress: 785 loss= 0.13020490109920502\n",
      "tensor([[ 2.3360, -1.3314, -0.8015],\n",
      "        [-0.9244,  1.0684,  0.1326],\n",
      "        [-3.5069,  0.8904,  3.2552],\n",
      "        [ 2.3360, -1.3314, -0.8015],\n",
      "        [ 2.3360, -1.3314, -0.8015],\n",
      "        [-0.4636, -1.4764,  2.5427]], grad_fn=<AddBackward0>)\n",
      "progress: 786 loss= 0.1300797015428543\n",
      "tensor([[ 2.3374, -1.3324, -0.8019],\n",
      "        [-0.9238,  1.0685,  0.1319],\n",
      "        [-3.5068,  0.8895,  3.2563],\n",
      "        [ 2.3374, -1.3324, -0.8019],\n",
      "        [ 2.3374, -1.3324, -0.8019],\n",
      "        [-0.4628, -1.4778,  2.5435]], grad_fn=<AddBackward0>)\n",
      "progress: 787 loss= 0.1299489587545395\n",
      "tensor([[ 2.3374, -1.3320, -0.8022],\n",
      "        [-0.9252,  1.0699,  0.1321],\n",
      "        [-3.5101,  0.8916,  3.2578],\n",
      "        [ 2.3374, -1.3320, -0.8022],\n",
      "        [ 2.3374, -1.3320, -0.8022],\n",
      "        [-0.4643, -1.4775,  2.5449]], grad_fn=<AddBackward0>)\n",
      "progress: 788 loss= 0.1298402100801468\n",
      "tensor([[ 2.3387, -1.3329, -0.8027],\n",
      "        [-0.9248,  1.0703,  0.1312],\n",
      "        [-3.5097,  0.8909,  3.2577],\n",
      "        [ 2.3387, -1.3329, -0.8027],\n",
      "        [ 2.3387, -1.3329, -0.8027],\n",
      "        [-0.4633, -1.4788,  2.5450]], grad_fn=<AddBackward0>)\n",
      "progress: 789 loss= 0.12971679866313934\n",
      "tensor([[ 2.3387, -1.3325, -0.8031],\n",
      "        [-0.9260,  1.0714,  0.1313],\n",
      "        [-3.5131,  0.8931,  3.2595],\n",
      "        [ 2.3387, -1.3325, -0.8031],\n",
      "        [ 2.3387, -1.3325, -0.8031],\n",
      "        [-0.4648, -1.4785,  2.5465]], grad_fn=<AddBackward0>)\n",
      "progress: 790 loss= 0.1296110600233078\n",
      "tensor([[ 2.3396, -1.3334, -0.8030],\n",
      "        [-0.9270,  1.0722,  0.1317],\n",
      "        [-3.5141,  0.8924,  3.2614],\n",
      "        [ 2.3396, -1.3334, -0.8030],\n",
      "        [ 2.3396, -1.3334, -0.8030],\n",
      "        [-0.4651, -1.4797,  2.5482]], grad_fn=<AddBackward0>)\n",
      "progress: 791 loss= 0.12946777045726776\n",
      "tensor([[ 2.3412, -1.3344, -0.8038],\n",
      "        [-0.9258,  1.0717,  0.1307],\n",
      "        [-3.5137,  0.8918,  3.2613],\n",
      "        [ 2.3412, -1.3344, -0.8038],\n",
      "        [ 2.3412, -1.3344, -0.8038],\n",
      "        [-0.4641, -1.4809,  2.5483]], grad_fn=<AddBackward0>)\n",
      "progress: 792 loss= 0.1293894648551941\n",
      "tensor([[ 2.3411, -1.3340, -0.8041],\n",
      "        [-0.9277,  1.0738,  0.1307],\n",
      "        [-3.5171,  0.8939,  3.2631],\n",
      "        [ 2.3411, -1.3340, -0.8041],\n",
      "        [ 2.3411, -1.3340, -0.8041],\n",
      "        [-0.4656, -1.4807,  2.5499]], grad_fn=<AddBackward0>)\n",
      "progress: 793 loss= 0.12922221422195435\n",
      "tensor([[ 2.3424, -1.3349, -0.8046],\n",
      "        [-0.9268,  1.0735,  0.1300],\n",
      "        [-3.5166,  0.8932,  3.2630],\n",
      "        [ 2.3424, -1.3349, -0.8046],\n",
      "        [ 2.3424, -1.3349, -0.8046],\n",
      "        [-0.4646, -1.4819,  2.5500]], grad_fn=<AddBackward0>)\n",
      "progress: 794 loss= 0.12915284931659698\n",
      "tensor([[ 2.3425, -1.3345, -0.8050],\n",
      "        [-0.9285,  1.0752,  0.1300],\n",
      "        [-3.5200,  0.8953,  3.2648],\n",
      "        [ 2.3425, -1.3345, -0.8050],\n",
      "        [ 2.3425, -1.3345, -0.8050],\n",
      "        [-0.4662, -1.4817,  2.5516]], grad_fn=<AddBackward0>)\n",
      "progress: 795 loss= 0.12900124490261078\n",
      "tensor([[ 2.3433, -1.3354, -0.8049],\n",
      "        [-0.9290,  1.0755,  0.1303],\n",
      "        [-3.5210,  0.8947,  3.2667],\n",
      "        [ 2.3433, -1.3354, -0.8049],\n",
      "        [ 2.3433, -1.3354, -0.8049],\n",
      "        [-0.4665, -1.4828,  2.5532]], grad_fn=<AddBackward0>)\n",
      "progress: 796 loss= 0.1288929134607315\n",
      "tensor([[ 2.3437, -1.3350, -0.8058],\n",
      "        [-0.9293,  1.0767,  0.1294],\n",
      "        [-3.5230,  0.8968,  3.2664],\n",
      "        [ 2.3437, -1.3350, -0.8058],\n",
      "        [ 2.3437, -1.3350, -0.8058],\n",
      "        [-0.4667, -1.4827,  2.5532]], grad_fn=<AddBackward0>)\n",
      "progress: 797 loss= 0.1287868320941925\n",
      "tensor([[ 2.3448, -1.3360, -0.8059],\n",
      "        [-0.9300,  1.0773,  0.1294],\n",
      "        [-3.5240,  0.8961,  3.2683],\n",
      "        [ 2.3448, -1.3360, -0.8059],\n",
      "        [ 2.3448, -1.3360, -0.8059],\n",
      "        [-0.4670, -1.4838,  2.5549]], grad_fn=<AddBackward0>)\n",
      "progress: 798 loss= 0.1286344975233078\n",
      "tensor([[ 2.3449, -1.3356, -0.8064],\n",
      "        [-0.9301,  1.0782,  0.1288],\n",
      "        [-3.5261,  0.8980,  3.2691],\n",
      "        [ 2.3449, -1.3356, -0.8064],\n",
      "        [ 2.3449, -1.3356, -0.8064],\n",
      "        [-0.4673, -1.4838,  2.5554]], grad_fn=<AddBackward0>)\n",
      "progress: 799 loss= 0.128557026386261\n",
      "tensor([[ 2.3462, -1.3365, -0.8068],\n",
      "        [-0.9310,  1.0791,  0.1288],\n",
      "        [-3.5268,  0.8976,  3.2698],\n",
      "        [ 2.3462, -1.3365, -0.8068],\n",
      "        [ 2.3462, -1.3365, -0.8068],\n",
      "        [-0.4675, -1.4848,  2.5563]], grad_fn=<AddBackward0>)\n",
      "progress: 800 loss= 0.1284024566411972\n",
      "tensor([[ 2.3471, -1.3374, -0.8070],\n",
      "        [-0.9309,  1.0788,  0.1289],\n",
      "        [-3.5279,  0.8969,  3.2717],\n",
      "        [ 2.3471, -1.3374, -0.8070],\n",
      "        [ 2.3471, -1.3374, -0.8070],\n",
      "        [-0.4678, -1.4859,  2.5579]], grad_fn=<AddBackward0>)\n",
      "progress: 801 loss= 0.1283280849456787\n",
      "tensor([[ 2.3474, -1.3371, -0.8073],\n",
      "        [-0.9318,  1.0806,  0.1283],\n",
      "        [-3.5301,  0.8988,  3.2726],\n",
      "        [ 2.3474, -1.3371, -0.8073],\n",
      "        [ 2.3474, -1.3371, -0.8073],\n",
      "        [-0.4681, -1.4859,  2.5587]], grad_fn=<AddBackward0>)\n",
      "progress: 802 loss= 0.12817761301994324\n",
      "tensor([[ 2.3485, -1.3379, -0.8079],\n",
      "        [-0.9320,  1.0806,  0.1282],\n",
      "        [-3.5308,  0.8984,  3.2733],\n",
      "        [ 2.3485, -1.3379, -0.8079],\n",
      "        [ 2.3485, -1.3379, -0.8079],\n",
      "        [-0.4683, -1.4869,  2.5596]], grad_fn=<AddBackward0>)\n",
      "progress: 803 loss= 0.1280835121870041\n",
      "tensor([[ 2.3487, -1.3375, -0.8082],\n",
      "        [-0.9326,  1.0821,  0.1274],\n",
      "        [-3.5330,  0.9002,  3.2743],\n",
      "        [ 2.3487, -1.3375, -0.8082],\n",
      "        [ 2.3487, -1.3375, -0.8082],\n",
      "        [-0.4686, -1.4869,  2.5604]], grad_fn=<AddBackward0>)\n",
      "progress: 804 loss= 0.12794969975948334\n",
      "tensor([[ 2.3499, -1.3385, -0.8085],\n",
      "        [-0.9330,  1.0823,  0.1277],\n",
      "        [-3.5339,  0.8996,  3.2760],\n",
      "        [ 2.3499, -1.3385, -0.8085],\n",
      "        [ 2.3499, -1.3385, -0.8085],\n",
      "        [-0.4689, -1.4880,  2.5618]], grad_fn=<AddBackward0>)\n",
      "progress: 805 loss= 0.12783336639404297\n",
      "tensor([[ 2.3496, -1.3380, -0.8089],\n",
      "        [-0.9345,  1.0838,  0.1276],\n",
      "        [-3.5370,  0.9020,  3.2765],\n",
      "        [ 2.3496, -1.3380, -0.8089],\n",
      "        [ 2.3496, -1.3380, -0.8089],\n",
      "        [-0.4702, -1.4876,  2.5626]], grad_fn=<AddBackward0>)\n",
      "progress: 806 loss= 0.12773622572422028\n",
      "tensor([[ 2.3511, -1.3390, -0.8094],\n",
      "        [-0.9340,  1.0841,  0.1269],\n",
      "        [-3.5369,  0.9010,  3.2776],\n",
      "        [ 2.3511, -1.3390, -0.8094],\n",
      "        [ 2.3511, -1.3390, -0.8094],\n",
      "        [-0.4694, -1.4890,  2.5634]], grad_fn=<AddBackward0>)\n",
      "progress: 807 loss= 0.1275901049375534\n",
      "tensor([[ 2.3510, -1.3385, -0.8097],\n",
      "        [-0.9353,  1.0853,  0.1270],\n",
      "        [-3.5402,  0.9032,  3.2791],\n",
      "        [ 2.3510, -1.3385, -0.8097],\n",
      "        [ 2.3510, -1.3385, -0.8097],\n",
      "        [-0.4709, -1.4887,  2.5648]], grad_fn=<AddBackward0>)\n",
      "progress: 808 loss= 0.12749499082565308\n",
      "tensor([[ 2.3524, -1.3395, -0.8102],\n",
      "        [-0.9350,  1.0859,  0.1262],\n",
      "        [-3.5397,  0.9025,  3.2790],\n",
      "        [ 2.3524, -1.3395, -0.8102],\n",
      "        [ 2.3524, -1.3395, -0.8102],\n",
      "        [-0.4698, -1.4900,  2.5649]], grad_fn=<AddBackward0>)\n",
      "progress: 809 loss= 0.12736496329307556\n",
      "tensor([[ 2.3524, -1.3391, -0.8106],\n",
      "        [-0.9360,  1.0868,  0.1263],\n",
      "        [-3.5431,  0.9046,  3.2808],\n",
      "        [ 2.3524, -1.3391, -0.8106],\n",
      "        [ 2.3524, -1.3391, -0.8106],\n",
      "        [-0.4713, -1.4898,  2.5664]], grad_fn=<AddBackward0>)\n",
      "progress: 810 loss= 0.12727390229701996\n",
      "tensor([[ 2.3532, -1.3400, -0.8105],\n",
      "        [-0.9370,  1.0876,  0.1265],\n",
      "        [-3.5441,  0.9039,  3.2827],\n",
      "        [ 2.3532, -1.3400, -0.8105],\n",
      "        [ 2.3532, -1.3400, -0.8105],\n",
      "        [-0.4717, -1.4909,  2.5681]], grad_fn=<AddBackward0>)\n",
      "progress: 811 loss= 0.12713131308555603\n",
      "tensor([[ 2.3548, -1.3410, -0.8113],\n",
      "        [-0.9359,  1.0873,  0.1256],\n",
      "        [-3.5436,  0.9033,  3.2826],\n",
      "        [ 2.3548, -1.3410, -0.8113],\n",
      "        [ 2.3548, -1.3410, -0.8113],\n",
      "        [-0.4707, -1.4922,  2.5682]], grad_fn=<AddBackward0>)\n",
      "progress: 812 loss= 0.12704607844352722\n",
      "tensor([[ 2.3547, -1.3405, -0.8116],\n",
      "        [-0.9377,  1.0892,  0.1257],\n",
      "        [-3.5470,  0.9054,  3.2843],\n",
      "        [ 2.3547, -1.3405, -0.8116],\n",
      "        [ 2.3547, -1.3405, -0.8116],\n",
      "        [-0.4722, -1.4919,  2.5697]], grad_fn=<AddBackward0>)\n",
      "progress: 813 loss= 0.1268966943025589\n",
      "tensor([[ 2.3561, -1.3415, -0.8119],\n",
      "        [-0.9370,  1.0891,  0.1251],\n",
      "        [-3.5467,  0.9045,  3.2852],\n",
      "        [ 2.3561, -1.3415, -0.8119],\n",
      "        [ 2.3561, -1.3415, -0.8119],\n",
      "        [-0.4713, -1.4933,  2.5703]], grad_fn=<AddBackward0>)\n",
      "progress: 814 loss= 0.1268005222082138\n",
      "tensor([[ 2.3561, -1.3411, -0.8125],\n",
      "        [-0.9385,  1.0906,  0.1250],\n",
      "        [-3.5498,  0.9068,  3.2857],\n",
      "        [ 2.3561, -1.3411, -0.8125],\n",
      "        [ 2.3561, -1.3411, -0.8125],\n",
      "        [-0.4726, -1.4929,  2.5711]], grad_fn=<AddBackward0>)\n",
      "progress: 815 loss= 0.126686230301857\n",
      "tensor([[ 2.3569, -1.3419, -0.8125],\n",
      "        [-0.9391,  1.0911,  0.1251],\n",
      "        [-3.5508,  0.9062,  3.2876],\n",
      "        [ 2.3569, -1.3419, -0.8125],\n",
      "        [ 2.3569, -1.3419, -0.8125],\n",
      "        [-0.4729, -1.4940,  2.5728]], grad_fn=<AddBackward0>)\n",
      "progress: 816 loss= 0.12655872106552124\n",
      "tensor([[ 2.3573, -1.3416, -0.8130],\n",
      "        [-0.9393,  1.0921,  0.1246],\n",
      "        [-3.5530,  0.9080,  3.2886],\n",
      "        [ 2.3573, -1.3416, -0.8130],\n",
      "        [ 2.3573, -1.3416, -0.8130],\n",
      "        [-0.4732, -1.4941,  2.5735]], grad_fn=<AddBackward0>)\n",
      "progress: 817 loss= 0.12646600604057312\n",
      "tensor([[ 2.3584, -1.3425, -0.8134],\n",
      "        [-0.9401,  1.0929,  0.1244],\n",
      "        [-3.5537,  0.9076,  3.2893],\n",
      "        [ 2.3584, -1.3425, -0.8134],\n",
      "        [ 2.3584, -1.3425, -0.8134],\n",
      "        [-0.4734, -1.4950,  2.5744]], grad_fn=<AddBackward0>)\n",
      "progress: 818 loss= 0.1263187974691391\n",
      "tensor([[ 2.3586, -1.3421, -0.8139],\n",
      "        [-0.9400,  1.0936,  0.1237],\n",
      "        [-3.5559,  0.9094,  3.2902],\n",
      "        [ 2.3586, -1.3421, -0.8139],\n",
      "        [ 2.3586, -1.3421, -0.8139],\n",
      "        [-0.4737, -1.4951,  2.5752]], grad_fn=<AddBackward0>)\n",
      "progress: 819 loss= 0.1262405514717102\n",
      "tensor([[ 2.3598, -1.3430, -0.8141],\n",
      "        [-0.9410,  1.0944,  0.1239],\n",
      "        [-3.5568,  0.9088,  3.2919],\n",
      "        [ 2.3598, -1.3430, -0.8141],\n",
      "        [ 2.3598, -1.3430, -0.8141],\n",
      "        [-0.4740, -1.4962,  2.5766]], grad_fn=<AddBackward0>)\n",
      "progress: 820 loss= 0.12608401477336884\n",
      "tensor([[ 2.3606, -1.3439, -0.8143],\n",
      "        [-0.9410,  1.0943,  0.1239],\n",
      "        [-3.5575,  0.9084,  3.2926],\n",
      "        [ 2.3606, -1.3439, -0.8143],\n",
      "        [ 2.3606, -1.3439, -0.8143],\n",
      "        [-0.4741, -1.4972,  2.5775]], grad_fn=<AddBackward0>)\n",
      "progress: 821 loss= 0.12602190673351288\n",
      "tensor([[ 2.3610, -1.3435, -0.8150],\n",
      "        [-0.9417,  1.0960,  0.1231],\n",
      "        [-3.5597,  0.9102,  3.2935],\n",
      "        [ 2.3610, -1.3435, -0.8150],\n",
      "        [ 2.3610, -1.3435, -0.8150],\n",
      "        [-0.4745, -1.4972,  2.5782]], grad_fn=<AddBackward0>)\n",
      "progress: 822 loss= 0.12586449086666107\n",
      "tensor([[ 2.3620, -1.3445, -0.8150],\n",
      "        [-0.9421,  1.0960,  0.1235],\n",
      "        [-3.5607,  0.9095,  3.2954],\n",
      "        [ 2.3620, -1.3445, -0.8150],\n",
      "        [ 2.3620, -1.3445, -0.8150],\n",
      "        [-0.4748, -1.4983,  2.5799]], grad_fn=<AddBackward0>)\n",
      "progress: 823 loss= 0.12577621638774872\n",
      "tensor([[ 2.3623, -1.3440, -0.8158],\n",
      "        [-0.9425,  1.0974,  0.1224],\n",
      "        [-3.5626,  0.9116,  3.2952],\n",
      "        [ 2.3623, -1.3440, -0.8158],\n",
      "        [ 2.3623, -1.3440, -0.8158],\n",
      "        [-0.4750, -1.4982,  2.5799]], grad_fn=<AddBackward0>)\n",
      "progress: 824 loss= 0.1256573349237442\n",
      "tensor([[ 2.3634, -1.3450, -0.8160],\n",
      "        [-0.9431,  1.0978,  0.1225],\n",
      "        [-3.5635,  0.9109,  3.2971],\n",
      "        [ 2.3634, -1.3450, -0.8160],\n",
      "        [ 2.3634, -1.3450, -0.8160],\n",
      "        [-0.4753, -1.4993,  2.5815]], grad_fn=<AddBackward0>)\n",
      "progress: 825 loss= 0.12552182376384735\n",
      "tensor([[ 2.3631, -1.3445, -0.8162],\n",
      "        [-0.9444,  1.0992,  0.1225],\n",
      "        [-3.5666,  0.9132,  3.2976],\n",
      "        [ 2.3631, -1.3445, -0.8162],\n",
      "        [ 2.3631, -1.3445, -0.8162],\n",
      "        [-0.4766, -1.4990,  2.5823]], grad_fn=<AddBackward0>)\n",
      "progress: 826 loss= 0.1254480481147766\n",
      "tensor([[ 2.3647, -1.3455, -0.8168],\n",
      "        [-0.9440,  1.0996,  0.1218],\n",
      "        [-3.5664,  0.9123,  3.2987],\n",
      "        [ 2.3647, -1.3455, -0.8168],\n",
      "        [ 2.3647, -1.3455, -0.8168],\n",
      "        [-0.4757, -1.5004,  2.5832]], grad_fn=<AddBackward0>)\n",
      "progress: 827 loss= 0.1252913773059845\n",
      "tensor([[ 2.3645, -1.3451, -0.8169],\n",
      "        [-0.9452,  1.1006,  0.1220],\n",
      "        [-3.5697,  0.9144,  3.3004],\n",
      "        [ 2.3645, -1.3451, -0.8169],\n",
      "        [ 2.3645, -1.3451, -0.8169],\n",
      "        [-0.4772, -1.5001,  2.5847]], grad_fn=<AddBackward0>)\n",
      "progress: 828 loss= 0.1252160370349884\n",
      "tensor([[ 2.3659, -1.3460, -0.8176],\n",
      "        [-0.9450,  1.1012,  0.1211],\n",
      "        [-3.5693,  0.9137,  3.3003],\n",
      "        [ 2.3659, -1.3460, -0.8176],\n",
      "        [ 2.3659, -1.3460, -0.8176],\n",
      "        [-0.4762, -1.5014,  2.5848]], grad_fn=<AddBackward0>)\n",
      "progress: 829 loss= 0.12507258355617523\n",
      "tensor([[ 2.3671, -1.3470, -0.8178],\n",
      "        [-0.9450,  1.1010,  0.1213],\n",
      "        [-3.5702,  0.9131,  3.3022],\n",
      "        [ 2.3671, -1.3470, -0.8178],\n",
      "        [ 2.3671, -1.3470, -0.8178],\n",
      "        [-0.4765, -1.5025,  2.5864]], grad_fn=<AddBackward0>)\n",
      "progress: 830 loss= 0.1249823197722435\n",
      "tensor([[ 2.3667, -1.3464, -0.8179],\n",
      "        [-0.9469,  1.1030,  0.1213],\n",
      "        [-3.5735,  0.9152,  3.3037],\n",
      "        [ 2.3667, -1.3464, -0.8179],\n",
      "        [ 2.3667, -1.3464, -0.8179],\n",
      "        [-0.4779, -1.5023,  2.5877]], grad_fn=<AddBackward0>)\n",
      "progress: 831 loss= 0.12485027313232422\n",
      "tensor([[ 2.3684, -1.3474, -0.8187],\n",
      "        [-0.9460,  1.1028,  0.1206],\n",
      "        [-3.5731,  0.9145,  3.3036],\n",
      "        [ 2.3684, -1.3474, -0.8187],\n",
      "        [ 2.3684, -1.3474, -0.8187],\n",
      "        [-0.4769, -1.5035,  2.5878]], grad_fn=<AddBackward0>)\n",
      "progress: 832 loss= 0.12476136535406113\n",
      "tensor([[ 2.3682, -1.3470, -0.8189],\n",
      "        [-0.9476,  1.1045,  0.1206],\n",
      "        [-3.5764,  0.9166,  3.3053],\n",
      "        [ 2.3682, -1.3470, -0.8189],\n",
      "        [ 2.3682, -1.3470, -0.8189],\n",
      "        [-0.4784, -1.5033,  2.5894]], grad_fn=<AddBackward0>)\n",
      "progress: 833 loss= 0.12462708353996277\n",
      "tensor([[ 2.3695, -1.3480, -0.8191],\n",
      "        [-0.9470,  1.1045,  0.1201],\n",
      "        [-3.5762,  0.9156,  3.3065],\n",
      "        [ 2.3695, -1.3480, -0.8191],\n",
      "        [ 2.3695, -1.3480, -0.8191],\n",
      "        [-0.4776, -1.5047,  2.5902]], grad_fn=<AddBackward0>)\n",
      "progress: 834 loss= 0.12452546507120132\n",
      "tensor([[ 2.3696, -1.3475, -0.8198],\n",
      "        [-0.9484,  1.1059,  0.1199],\n",
      "        [-3.5792,  0.9179,  3.3070],\n",
      "        [ 2.3696, -1.3475, -0.8198],\n",
      "        [ 2.3696, -1.3475, -0.8198],\n",
      "        [-0.4789, -1.5043,  2.5910]], grad_fn=<AddBackward0>)\n",
      "progress: 835 loss= 0.12441393733024597\n",
      "tensor([[ 2.3704, -1.3484, -0.8197],\n",
      "        [-0.9491,  1.1065,  0.1200],\n",
      "        [-3.5802,  0.9173,  3.3089],\n",
      "        [ 2.3704, -1.3484, -0.8197],\n",
      "        [ 2.3704, -1.3484, -0.8197],\n",
      "        [-0.4792, -1.5054,  2.5926]], grad_fn=<AddBackward0>)\n",
      "progress: 836 loss= 0.12428417801856995\n",
      "tensor([[ 2.3708, -1.3481, -0.8204],\n",
      "        [-0.9491,  1.1074,  0.1194],\n",
      "        [-3.5823,  0.9191,  3.3096],\n",
      "        [ 2.3708, -1.3481, -0.8204],\n",
      "        [ 2.3708, -1.3481, -0.8204],\n",
      "        [-0.4794, -1.5054,  2.5932]], grad_fn=<AddBackward0>)\n",
      "progress: 837 loss= 0.12419899553060532\n",
      "tensor([[ 2.3719, -1.3489, -0.8208],\n",
      "        [-0.9501,  1.1083,  0.1193],\n",
      "        [-3.5830,  0.9187,  3.3102],\n",
      "        [ 2.3719, -1.3489, -0.8208],\n",
      "        [ 2.3719, -1.3489, -0.8208],\n",
      "        [-0.4796, -1.5064,  2.5940]], grad_fn=<AddBackward0>)\n",
      "progress: 838 loss= 0.12405610084533691\n",
      "tensor([[ 2.3732, -1.3499, -0.8212],\n",
      "        [-0.9488,  1.1077,  0.1187],\n",
      "        [-3.5828,  0.9178,  3.3113],\n",
      "        [ 2.3732, -1.3499, -0.8212],\n",
      "        [ 2.3732, -1.3499, -0.8212],\n",
      "        [-0.4787, -1.5078,  2.5949]], grad_fn=<AddBackward0>)\n",
      "progress: 839 loss= 0.12398245185613632\n",
      "tensor([[ 2.3732, -1.3495, -0.8215],\n",
      "        [-0.9508,  1.1097,  0.1187],\n",
      "        [-3.5860,  0.9199,  3.3128],\n",
      "        [ 2.3732, -1.3495, -0.8215],\n",
      "        [ 2.3732, -1.3495, -0.8215],\n",
      "        [-0.4802, -1.5076,  2.5962]], grad_fn=<AddBackward0>)\n",
      "progress: 840 loss= 0.1238265112042427\n",
      "tensor([[ 2.3740, -1.3503, -0.8217],\n",
      "        [-0.9510,  1.1097,  0.1188],\n",
      "        [-3.5867,  0.9195,  3.3135],\n",
      "        [ 2.3740, -1.3503, -0.8217],\n",
      "        [ 2.3740, -1.3503, -0.8217],\n",
      "        [-0.4803, -1.5085,  2.5971]], grad_fn=<AddBackward0>)\n",
      "progress: 841 loss= 0.12376400083303452\n",
      "tensor([[ 2.3745, -1.3500, -0.8224],\n",
      "        [-0.9515,  1.1112,  0.1180],\n",
      "        [-3.5889,  0.9213,  3.3144],\n",
      "        [ 2.3745, -1.3500, -0.8224],\n",
      "        [ 2.3745, -1.3500, -0.8224],\n",
      "        [-0.4806, -1.5086,  2.5978]], grad_fn=<AddBackward0>)\n",
      "progress: 842 loss= 0.12361907213926315\n",
      "tensor([[ 2.3754, -1.3509, -0.8223],\n",
      "        [-0.9520,  1.1114,  0.1183],\n",
      "        [-3.5898,  0.9206,  3.3163],\n",
      "        [ 2.3754, -1.3509, -0.8223],\n",
      "        [ 2.3754, -1.3509, -0.8223],\n",
      "        [-0.4809, -1.5097,  2.5994]], grad_fn=<AddBackward0>)\n",
      "progress: 843 loss= 0.12351737171411514\n",
      "tensor([[ 2.3757, -1.3505, -0.8231],\n",
      "        [-0.9523,  1.1127,  0.1173],\n",
      "        [-3.5917,  0.9226,  3.3161],\n",
      "        [ 2.3757, -1.3505, -0.8231],\n",
      "        [ 2.3757, -1.3505, -0.8231],\n",
      "        [-0.4811, -1.5096,  2.5995]], grad_fn=<AddBackward0>)\n",
      "progress: 844 loss= 0.123416967689991\n",
      "tensor([[ 2.3769, -1.3514, -0.8234],\n",
      "        [-0.9530,  1.1132,  0.1174],\n",
      "        [-3.5926,  0.9220,  3.3180],\n",
      "        [ 2.3769, -1.3514, -0.8234],\n",
      "        [ 2.3769, -1.3514, -0.8234],\n",
      "        [-0.4814, -1.5107,  2.6011]], grad_fn=<AddBackward0>)\n",
      "progress: 845 loss= 0.12327271699905396\n",
      "tensor([[ 2.3765, -1.3509, -0.8234],\n",
      "        [-0.9542,  1.1144,  0.1176],\n",
      "        [-3.5959,  0.9240,  3.3194],\n",
      "        [ 2.3765, -1.3509, -0.8234],\n",
      "        [ 2.3765, -1.3509, -0.8234],\n",
      "        [-0.4828, -1.5105,  2.6024]], grad_fn=<AddBackward0>)\n",
      "progress: 846 loss= 0.1232002004981041\n",
      "tensor([[ 2.3781, -1.3519, -0.8242],\n",
      "        [-0.9539,  1.1149,  0.1167],\n",
      "        [-3.5954,  0.9234,  3.3193],\n",
      "        [ 2.3781, -1.3519, -0.8242],\n",
      "        [ 2.3781, -1.3519, -0.8242],\n",
      "        [-0.4818, -1.5117,  2.6025]], grad_fn=<AddBackward0>)\n",
      "progress: 847 loss= 0.12305698543787003\n",
      "tensor([[ 2.3779, -1.3514, -0.8244],\n",
      "        [-0.9549,  1.1158,  0.1168],\n",
      "        [-3.5987,  0.9254,  3.3210],\n",
      "        [ 2.3779, -1.3514, -0.8244],\n",
      "        [ 2.3779, -1.3514, -0.8244],\n",
      "        [-0.4832, -1.5115,  2.6040]], grad_fn=<AddBackward0>)\n",
      "progress: 848 loss= 0.12297973036766052\n",
      "tensor([[ 2.3793, -1.3525, -0.8247],\n",
      "        [-0.9548,  1.1164,  0.1164],\n",
      "        [-3.5985,  0.9245,  3.3222],\n",
      "        [ 2.3793, -1.3525, -0.8247],\n",
      "        [ 2.3793, -1.3525, -0.8247],\n",
      "        [-0.4824, -1.5129,  2.6048]], grad_fn=<AddBackward0>)\n",
      "progress: 849 loss= 0.12284350395202637\n",
      "tensor([[ 2.3805, -1.3533, -0.8252],\n",
      "        [-0.9548,  1.1163,  0.1162],\n",
      "        [-3.5992,  0.9240,  3.3228],\n",
      "        [ 2.3805, -1.3533, -0.8252],\n",
      "        [ 2.3805, -1.3533, -0.8252],\n",
      "        [-0.4825, -1.5139,  2.6057]], grad_fn=<AddBackward0>)\n",
      "progress: 850 loss= 0.1227533295750618\n",
      "tensor([[ 2.3801, -1.3528, -0.8253],\n",
      "        [-0.9566,  1.1182,  0.1162],\n",
      "        [-3.6024,  0.9261,  3.3245],\n",
      "        [ 2.3801, -1.3528, -0.8253],\n",
      "        [ 2.3801, -1.3528, -0.8253],\n",
      "        [-0.4840, -1.5137,  2.6072]], grad_fn=<AddBackward0>)\n",
      "progress: 851 loss= 0.1226244792342186\n",
      "tensor([[ 2.3817, -1.3539, -0.8258],\n",
      "        [-0.9558,  1.1180,  0.1157],\n",
      "        [-3.6022,  0.9252,  3.3254],\n",
      "        [ 2.3817, -1.3539, -0.8258],\n",
      "        [ 2.3817, -1.3539, -0.8258],\n",
      "        [-0.4831, -1.5150,  2.6078]], grad_fn=<AddBackward0>)\n",
      "progress: 852 loss= 0.12252394109964371\n",
      "tensor([[ 2.3816, -1.3534, -0.8262],\n",
      "        [-0.9573,  1.1196,  0.1155],\n",
      "        [-3.6052,  0.9275,  3.3259],\n",
      "        [ 2.3816, -1.3534, -0.8262],\n",
      "        [ 2.3816, -1.3534, -0.8262],\n",
      "        [-0.4844, -1.5147,  2.6086]], grad_fn=<AddBackward0>)\n",
      "progress: 853 loss= 0.12241875380277634\n",
      "tensor([[ 2.3829, -1.3543, -0.8267],\n",
      "        [-0.9568,  1.1198,  0.1148],\n",
      "        [-3.6050,  0.9266,  3.3270],\n",
      "        [ 2.3829, -1.3543, -0.8267],\n",
      "        [ 2.3829, -1.3543, -0.8267],\n",
      "        [-0.4835, -1.5161,  2.6095]], grad_fn=<AddBackward0>)\n",
      "progress: 854 loss= 0.12229195982217789\n",
      "tensor([[ 2.3829, -1.3540, -0.8268],\n",
      "        [-0.9581,  1.1210,  0.1152],\n",
      "        [-3.6083,  0.9286,  3.3287],\n",
      "        [ 2.3829, -1.3540, -0.8268],\n",
      "        [ 2.3829, -1.3540, -0.8268],\n",
      "        [-0.4850, -1.5159,  2.6110]], grad_fn=<AddBackward0>)\n",
      "progress: 855 loss= 0.12220486253499985\n",
      "tensor([[ 2.3837, -1.3548, -0.8271],\n",
      "        [-0.9589,  1.1218,  0.1149],\n",
      "        [-3.6089,  0.9282,  3.3294],\n",
      "        [ 2.3837, -1.3548, -0.8271],\n",
      "        [ 2.3837, -1.3548, -0.8271],\n",
      "        [-0.4851, -1.5169,  2.6119]], grad_fn=<AddBackward0>)\n",
      "progress: 856 loss= 0.1220715269446373\n",
      "tensor([[ 2.3842, -1.3544, -0.8277],\n",
      "        [-0.9588,  1.1225,  0.1142],\n",
      "        [-3.6111,  0.9299,  3.3303],\n",
      "        [ 2.3842, -1.3544, -0.8277],\n",
      "        [ 2.3842, -1.3544, -0.8277],\n",
      "        [-0.4854, -1.5169,  2.6126]], grad_fn=<AddBackward0>)\n",
      "progress: 857 loss= 0.12198754400014877\n",
      "tensor([[ 2.3852, -1.3553, -0.8280],\n",
      "        [-0.9597,  1.1234,  0.1142],\n",
      "        [-3.6117,  0.9295,  3.3310],\n",
      "        [ 2.3852, -1.3553, -0.8280],\n",
      "        [ 2.3852, -1.3553, -0.8280],\n",
      "        [-0.4855, -1.5179,  2.6135]], grad_fn=<AddBackward0>)\n",
      "progress: 858 loss= 0.12185431271791458\n",
      "tensor([[ 2.3865, -1.3563, -0.8285],\n",
      "        [-0.9586,  1.1230,  0.1136],\n",
      "        [-3.6115,  0.9286,  3.3321],\n",
      "        [ 2.3865, -1.3563, -0.8285],\n",
      "        [ 2.3865, -1.3563, -0.8285],\n",
      "        [-0.4847, -1.5193,  2.6143]], grad_fn=<AddBackward0>)\n",
      "progress: 859 loss= 0.12177308648824692\n",
      "tensor([[ 2.3865, -1.3559, -0.8286],\n",
      "        [-0.9605,  1.1248,  0.1138],\n",
      "        [-3.6148,  0.9306,  3.3338],\n",
      "        [ 2.3865, -1.3559, -0.8286],\n",
      "        [ 2.3865, -1.3559, -0.8286],\n",
      "        [-0.4861, -1.5191,  2.6159]], grad_fn=<AddBackward0>)\n",
      "progress: 860 loss= 0.1216343343257904\n",
      "tensor([[ 2.3873, -1.3567, -0.8289],\n",
      "        [-0.9608,  1.1250,  0.1137],\n",
      "        [-3.6155,  0.9302,  3.3344],\n",
      "        [ 2.3873, -1.3567, -0.8289],\n",
      "        [ 2.3873, -1.3567, -0.8289],\n",
      "        [-0.4863, -1.5201,  2.6167]], grad_fn=<AddBackward0>)\n",
      "progress: 861 loss= 0.12155360728502274\n",
      "tensor([[ 2.3878, -1.3564, -0.8295],\n",
      "        [-0.9612,  1.1263,  0.1129],\n",
      "        [-3.6176,  0.9320,  3.3354],\n",
      "        [ 2.3878, -1.3564, -0.8295],\n",
      "        [ 2.3878, -1.3564, -0.8295],\n",
      "        [-0.4866, -1.5201,  2.6175]], grad_fn=<AddBackward0>)\n",
      "progress: 862 loss= 0.12142381072044373\n",
      "tensor([[ 2.3887, -1.3573, -0.8297],\n",
      "        [-0.9618,  1.1267,  0.1131],\n",
      "        [-3.6185,  0.9313,  3.3370],\n",
      "        [ 2.3887, -1.3573, -0.8297],\n",
      "        [ 2.3887, -1.3573, -0.8297],\n",
      "        [-0.4868, -1.5212,  2.6188]], grad_fn=<AddBackward0>)\n",
      "progress: 863 loss= 0.12131316214799881\n",
      "tensor([[ 2.3890, -1.3568, -0.8303],\n",
      "        [-0.9619,  1.1278,  0.1123],\n",
      "        [-3.6203,  0.9333,  3.3367],\n",
      "        [ 2.3890, -1.3568, -0.8303],\n",
      "        [ 2.3890, -1.3568, -0.8303],\n",
      "        [-0.4869, -1.5211,  2.6189]], grad_fn=<AddBackward0>)\n",
      "progress: 864 loss= 0.12123089283704758\n",
      "tensor([[ 2.3902, -1.3578, -0.8307],\n",
      "        [-0.9627,  1.1284,  0.1123],\n",
      "        [-3.6212,  0.9327,  3.3386],\n",
      "        [ 2.3902, -1.3578, -0.8307],\n",
      "        [ 2.3902, -1.3578, -0.8307],\n",
      "        [-0.4872, -1.5223,  2.6205]], grad_fn=<AddBackward0>)\n",
      "progress: 865 loss= 0.12108031660318375\n",
      "tensor([[ 2.3898, -1.3573, -0.8307],\n",
      "        [-0.9638,  1.1295,  0.1124],\n",
      "        [-3.6244,  0.9347,  3.3401],\n",
      "        [ 2.3898, -1.3573, -0.8307],\n",
      "        [ 2.3898, -1.3573, -0.8307],\n",
      "        [-0.4886, -1.5220,  2.6218]], grad_fn=<AddBackward0>)\n",
      "progress: 866 loss= 0.12101195007562637\n",
      "tensor([[ 2.3914, -1.3583, -0.8314],\n",
      "        [-0.9636,  1.1301,  0.1117],\n",
      "        [-3.6240,  0.9340,  3.3400],\n",
      "        [ 2.3914, -1.3583, -0.8314],\n",
      "        [ 2.3914, -1.3583, -0.8314],\n",
      "        [-0.4876, -1.5233,  2.6219]], grad_fn=<AddBackward0>)\n",
      "progress: 867 loss= 0.1208767518401146\n",
      "tensor([[ 2.3924, -1.3591, -0.8316],\n",
      "        [-0.9636,  1.1298,  0.1118],\n",
      "        [-3.6249,  0.9334,  3.3418],\n",
      "        [ 2.3924, -1.3591, -0.8316],\n",
      "        [ 2.3924, -1.3591, -0.8316],\n",
      "        [-0.4879, -1.5244,  2.6235]], grad_fn=<AddBackward0>)\n",
      "progress: 868 loss= 0.12079746276140213\n",
      "tensor([[ 2.3925, -1.3588, -0.8319],\n",
      "        [-0.9644,  1.1315,  0.1112],\n",
      "        [-3.6270,  0.9351,  3.3428],\n",
      "        [ 2.3925, -1.3588, -0.8319],\n",
      "        [ 2.3925, -1.3588, -0.8319],\n",
      "        [-0.4882, -1.5244,  2.6242]], grad_fn=<AddBackward0>)\n",
      "progress: 869 loss= 0.12066491693258286\n",
      "tensor([[ 2.3937, -1.3597, -0.8325],\n",
      "        [-0.9645,  1.1315,  0.1111],\n",
      "        [-3.6277,  0.9347,  3.3434],\n",
      "        [ 2.3937, -1.3597, -0.8325],\n",
      "        [ 2.3937, -1.3597, -0.8325],\n",
      "        [-0.4883, -1.5254,  2.6251]], grad_fn=<AddBackward0>)\n",
      "progress: 870 loss= 0.12057501822710037\n",
      "tensor([[ 2.3934, -1.3592, -0.8326],\n",
      "        [-0.9662,  1.1332,  0.1111],\n",
      "        [-3.6309,  0.9367,  3.3451],\n",
      "        [ 2.3934, -1.3592, -0.8326],\n",
      "        [ 2.3934, -1.3592, -0.8326],\n",
      "        [-0.4898, -1.5252,  2.6266]], grad_fn=<AddBackward0>)\n",
      "progress: 871 loss= 0.12045478075742722\n",
      "tensor([[ 2.3949, -1.3602, -0.8331],\n",
      "        [-0.9655,  1.1333,  0.1105],\n",
      "        [-3.6306,  0.9358,  3.3460],\n",
      "        [ 2.3949, -1.3602, -0.8331],\n",
      "        [ 2.3949, -1.3602, -0.8331],\n",
      "        [-0.4889, -1.5266,  2.6272]], grad_fn=<AddBackward0>)\n",
      "progress: 872 loss= 0.12034496665000916\n",
      "tensor([[ 2.3948, -1.3597, -0.8335],\n",
      "        [-0.9669,  1.1347,  0.1104],\n",
      "        [-3.6336,  0.9381,  3.3465],\n",
      "        [ 2.3948, -1.3597, -0.8335],\n",
      "        [ 2.3948, -1.3597, -0.8335],\n",
      "        [-0.4901, -1.5262,  2.6280]], grad_fn=<AddBackward0>)\n",
      "progress: 873 loss= 0.12025519460439682\n",
      "tensor([[ 2.3961, -1.3607, -0.8339],\n",
      "        [-0.9665,  1.1350,  0.1097],\n",
      "        [-3.6334,  0.9372,  3.3476],\n",
      "        [ 2.3961, -1.3607, -0.8339],\n",
      "        [ 2.3961, -1.3607, -0.8339],\n",
      "        [-0.4893, -1.5276,  2.6288]], grad_fn=<AddBackward0>)\n",
      "progress: 874 loss= 0.12012475728988647\n",
      "tensor([[ 2.3961, -1.3603, -0.8341],\n",
      "        [-0.9677,  1.1361,  0.1100],\n",
      "        [-3.6366,  0.9392,  3.3493],\n",
      "        [ 2.3961, -1.3603, -0.8341],\n",
      "        [ 2.3961, -1.3603, -0.8341],\n",
      "        [-0.4907, -1.5274,  2.6303]], grad_fn=<AddBackward0>)\n",
      "progress: 875 loss= 0.12004200369119644\n",
      "tensor([[ 2.3970, -1.3611, -0.8344],\n",
      "        [-0.9686,  1.1370,  0.1098],\n",
      "        [-3.6373,  0.9387,  3.3499],\n",
      "        [ 2.3970, -1.3611, -0.8344],\n",
      "        [ 2.3970, -1.3611, -0.8344],\n",
      "        [-0.4908, -1.5284,  2.6312]], grad_fn=<AddBackward0>)\n",
      "progress: 876 loss= 0.11990805715322495\n",
      "tensor([[ 2.3973, -1.3607, -0.8350],\n",
      "        [-0.9684,  1.1376,  0.1091],\n",
      "        [-3.6394,  0.9405,  3.3509],\n",
      "        [ 2.3973, -1.3607, -0.8350],\n",
      "        [ 2.3973, -1.3607, -0.8350],\n",
      "        [-0.4911, -1.5285,  2.6319]], grad_fn=<AddBackward0>)\n",
      "progress: 877 loss= 0.11983266472816467\n",
      "tensor([[ 2.3984, -1.3616, -0.8351],\n",
      "        [-0.9693,  1.1384,  0.1093],\n",
      "        [-3.6402,  0.9398,  3.3525],\n",
      "        [ 2.3984, -1.3616, -0.8351],\n",
      "        [ 2.3984, -1.3616, -0.8351],\n",
      "        [-0.4913, -1.5296,  2.6333]], grad_fn=<AddBackward0>)\n",
      "progress: 878 loss= 0.1196923777461052\n",
      "tensor([[ 2.3997, -1.3626, -0.8357],\n",
      "        [-0.9683,  1.1381,  0.1085],\n",
      "        [-3.6398,  0.9392,  3.3524],\n",
      "        [ 2.3997, -1.3626, -0.8357],\n",
      "        [ 2.3997, -1.3626, -0.8357],\n",
      "        [-0.4903, -1.5308,  2.6334]], grad_fn=<AddBackward0>)\n",
      "progress: 879 loss= 0.11962541937828064\n",
      "tensor([[ 2.3997, -1.3621, -0.8361],\n",
      "        [-0.9700,  1.1399,  0.1085],\n",
      "        [-3.6430,  0.9412,  3.3541],\n",
      "        [ 2.3997, -1.3621, -0.8361],\n",
      "        [ 2.3997, -1.3621, -0.8361],\n",
      "        [-0.4918, -1.5306,  2.6349]], grad_fn=<AddBackward0>)\n",
      "progress: 880 loss= 0.11948245018720627\n",
      "tensor([[ 2.4005, -1.3630, -0.8359],\n",
      "        [-0.9704,  1.1400,  0.1089],\n",
      "        [-3.6439,  0.9405,  3.3559],\n",
      "        [ 2.4005, -1.3630, -0.8359],\n",
      "        [ 2.4005, -1.3630, -0.8359],\n",
      "        [-0.4920, -1.5317,  2.6365]], grad_fn=<AddBackward0>)\n",
      "progress: 881 loss= 0.11940158158540726\n",
      "tensor([[ 2.4009, -1.3626, -0.8368],\n",
      "        [-0.9707,  1.1413,  0.1078],\n",
      "        [-3.6457,  0.9425,  3.3557],\n",
      "        [ 2.4009, -1.3626, -0.8368],\n",
      "        [ 2.4009, -1.3626, -0.8368],\n",
      "        [-0.4922, -1.5317,  2.6365]], grad_fn=<AddBackward0>)\n",
      "progress: 882 loss= 0.11928966641426086\n",
      "tensor([[ 2.4019, -1.3635, -0.8369],\n",
      "        [-0.9713,  1.1418,  0.1079],\n",
      "        [-3.6466,  0.9418,  3.3575],\n",
      "        [ 2.4019, -1.3635, -0.8369],\n",
      "        [ 2.4019, -1.3635, -0.8369],\n",
      "        [-0.4925, -1.5328,  2.6381]], grad_fn=<AddBackward0>)\n",
      "progress: 883 loss= 0.1191616877913475\n",
      "tensor([[ 2.4021, -1.3631, -0.8375],\n",
      "        [-0.9715,  1.1428,  0.1072],\n",
      "        [-3.6485,  0.9438,  3.3572],\n",
      "        [ 2.4021, -1.3631, -0.8375],\n",
      "        [ 2.4021, -1.3631, -0.8375],\n",
      "        [-0.4926, -1.5327,  2.6381]], grad_fn=<AddBackward0>)\n",
      "progress: 884 loss= 0.1190972849726677\n",
      "tensor([[ 2.4033, -1.3640, -0.8378],\n",
      "        [-0.9723,  1.1435,  0.1072],\n",
      "        [-3.6494,  0.9431,  3.3591],\n",
      "        [ 2.4033, -1.3640, -0.8378],\n",
      "        [ 2.4033, -1.3640, -0.8378],\n",
      "        [-0.4929, -1.5338,  2.6397]], grad_fn=<AddBackward0>)\n",
      "progress: 885 loss= 0.11894283443689346\n",
      "tensor([[ 2.4029, -1.3636, -0.8378],\n",
      "        [-0.9733,  1.1444,  0.1074],\n",
      "        [-3.6526,  0.9451,  3.3608],\n",
      "        [ 2.4029, -1.3636, -0.8378],\n",
      "        [ 2.4029, -1.3636, -0.8378],\n",
      "        [-0.4943, -1.5336,  2.6412]], grad_fn=<AddBackward0>)\n",
      "progress: 886 loss= 0.11888507008552551\n",
      "tensor([[ 2.4045, -1.3645, -0.8386],\n",
      "        [-0.9731,  1.1451,  0.1066],\n",
      "        [-3.6521,  0.9444,  3.3607],\n",
      "        [ 2.4045, -1.3645, -0.8386],\n",
      "        [ 2.4045, -1.3645, -0.8386],\n",
      "        [-0.4933, -1.5349,  2.6413]], grad_fn=<AddBackward0>)\n",
      "progress: 887 loss= 0.11874502897262573\n",
      "tensor([[ 2.4055, -1.3654, -0.8387],\n",
      "        [-0.9731,  1.1449,  0.1067],\n",
      "        [-3.6530,  0.9437,  3.3625],\n",
      "        [ 2.4055, -1.3654, -0.8387],\n",
      "        [ 2.4055, -1.3654, -0.8387],\n",
      "        [-0.4935, -1.5360,  2.6429]], grad_fn=<AddBackward0>)\n",
      "progress: 888 loss= 0.11865969747304916\n",
      "tensor([[ 2.4056, -1.3650, -0.8391],\n",
      "        [-0.9738,  1.1465,  0.1060],\n",
      "        [-3.6550,  0.9455,  3.3632],\n",
      "        [ 2.4056, -1.3650, -0.8391],\n",
      "        [ 2.4056, -1.3650, -0.8391],\n",
      "        [-0.4938, -1.5360,  2.6434]], grad_fn=<AddBackward0>)\n",
      "progress: 889 loss= 0.11853888630867004\n",
      "tensor([[ 2.4068, -1.3659, -0.8396],\n",
      "        [-0.9741,  1.1466,  0.1060],\n",
      "        [-3.6557,  0.9451,  3.3639],\n",
      "        [ 2.4068, -1.3659, -0.8396],\n",
      "        [ 2.4068, -1.3659, -0.8396],\n",
      "        [-0.4939, -1.5370,  2.6443]], grad_fn=<AddBackward0>)\n",
      "progress: 890 loss= 0.11845023185014725\n",
      "tensor([[ 2.4065, -1.3654, -0.8398],\n",
      "        [-0.9756,  1.1482,  0.1060],\n",
      "        [-3.6589,  0.9470,  3.3656],\n",
      "        [ 2.4065, -1.3654, -0.8398],\n",
      "        [ 2.4065, -1.3654, -0.8398],\n",
      "        [-0.4953, -1.5368,  2.6458]], grad_fn=<AddBackward0>)\n",
      "progress: 891 loss= 0.1183355525135994\n",
      "tensor([[ 2.4079, -1.3665, -0.8400],\n",
      "        [-0.9751,  1.1483,  0.1055],\n",
      "        [-3.6587,  0.9461,  3.3667],\n",
      "        [ 2.4079, -1.3665, -0.8400],\n",
      "        [ 2.4079, -1.3665, -0.8400],\n",
      "        [-0.4945, -1.5382,  2.6466]], grad_fn=<AddBackward0>)\n",
      "progress: 892 loss= 0.11823000758886337\n",
      "tensor([[ 2.4079, -1.3660, -0.8407],\n",
      "        [-0.9764,  1.1496,  0.1053],\n",
      "        [-3.6616,  0.9483,  3.3671],\n",
      "        [ 2.4079, -1.3660, -0.8407],\n",
      "        [ 2.4079, -1.3660, -0.8407],\n",
      "        [-0.4957, -1.5379,  2.6474]], grad_fn=<AddBackward0>)\n",
      "progress: 893 loss= 0.11813515424728394\n",
      "tensor([[ 2.4092, -1.3669, -0.8409],\n",
      "        [-0.9760,  1.1500,  0.1046],\n",
      "        [-3.6614,  0.9474,  3.3682],\n",
      "        [ 2.4092, -1.3669, -0.8409],\n",
      "        [ 2.4092, -1.3669, -0.8409],\n",
      "        [-0.4949, -1.5393,  2.6482]], grad_fn=<AddBackward0>)\n",
      "progress: 894 loss= 0.11800694465637207\n",
      "tensor([[ 2.4092, -1.3665, -0.8412],\n",
      "        [-0.9771,  1.1510,  0.1048],\n",
      "        [-3.6645,  0.9494,  3.3697],\n",
      "        [ 2.4092, -1.3665, -0.8412],\n",
      "        [ 2.4092, -1.3665, -0.8412],\n",
      "        [-0.4962, -1.5391,  2.6495]], grad_fn=<AddBackward0>)\n",
      "progress: 895 loss= 0.11793114989995956\n",
      "tensor([[ 2.4101, -1.3673, -0.8415],\n",
      "        [-0.9780,  1.1519,  0.1047],\n",
      "        [-3.6651,  0.9490,  3.3703],\n",
      "        [ 2.4101, -1.3673, -0.8415],\n",
      "        [ 2.4101, -1.3673, -0.8415],\n",
      "        [-0.4963, -1.5401,  2.6504]], grad_fn=<AddBackward0>)\n",
      "progress: 896 loss= 0.11780226230621338\n",
      "tensor([[ 2.4115, -1.3683, -0.8420],\n",
      "        [-0.9768,  1.1514,  0.1041],\n",
      "        [-3.6649,  0.9481,  3.3714],\n",
      "        [ 2.4115, -1.3683, -0.8420],\n",
      "        [ 2.4115, -1.3683, -0.8420],\n",
      "        [-0.4955, -1.5414,  2.6512]], grad_fn=<AddBackward0>)\n",
      "progress: 897 loss= 0.1177249550819397\n",
      "tensor([[ 2.4115, -1.3679, -0.8423],\n",
      "        [-0.9787,  1.1533,  0.1041],\n",
      "        [-3.6681,  0.9501,  3.3729],\n",
      "        [ 2.4115, -1.3679, -0.8423],\n",
      "        [ 2.4115, -1.3679, -0.8423],\n",
      "        [-0.4968, -1.5412,  2.6524]], grad_fn=<AddBackward0>)\n",
      "progress: 898 loss= 0.11758634448051453\n",
      "tensor([[ 2.4127, -1.3688, -0.8428],\n",
      "        [-0.9778,  1.1531,  0.1034],\n",
      "        [-3.6676,  0.9494,  3.3727],\n",
      "        [ 2.4127, -1.3688, -0.8428],\n",
      "        [ 2.4127, -1.3688, -0.8428],\n",
      "        [-0.4958, -1.5424,  2.6525]], grad_fn=<AddBackward0>)\n",
      "progress: 899 loss= 0.11752358078956604\n",
      "tensor([[ 2.4127, -1.3684, -0.8432],\n",
      "        [-0.9794,  1.1548,  0.1034],\n",
      "        [-3.6708,  0.9514,  3.3744],\n",
      "        [ 2.4127, -1.3684, -0.8432],\n",
      "        [ 2.4127, -1.3684, -0.8432],\n",
      "        [-0.4972, -1.5423,  2.6540]], grad_fn=<AddBackward0>)\n",
      "progress: 900 loss= 0.11739060282707214\n",
      "tensor([[ 2.4136, -1.3692, -0.8431],\n",
      "        [-0.9799,  1.1550,  0.1037],\n",
      "        [-3.6716,  0.9507,  3.3763],\n",
      "        [ 2.4136, -1.3692, -0.8431],\n",
      "        [ 2.4136, -1.3692, -0.8431],\n",
      "        [-0.4975, -1.5434,  2.6556]], grad_fn=<AddBackward0>)\n",
      "progress: 901 loss= 0.11729589849710464\n",
      "tensor([[ 2.4139, -1.3688, -0.8439],\n",
      "        [-0.9801,  1.1562,  0.1027],\n",
      "        [-3.6735,  0.9526,  3.3760],\n",
      "        [ 2.4139, -1.3688, -0.8439],\n",
      "        [ 2.4139, -1.3688, -0.8439],\n",
      "        [-0.4976, -1.5433,  2.6556]], grad_fn=<AddBackward0>)\n",
      "progress: 902 loss= 0.11720243841409683\n",
      "tensor([[ 2.4150, -1.3698, -0.8441],\n",
      "        [-0.9808,  1.1568,  0.1028],\n",
      "        [-3.6743,  0.9520,  3.3778],\n",
      "        [ 2.4150, -1.3698, -0.8441],\n",
      "        [ 2.4150, -1.3698, -0.8441],\n",
      "        [-0.4979, -1.5445,  2.6572]], grad_fn=<AddBackward0>)\n",
      "progress: 903 loss= 0.11706554889678955\n",
      "tensor([[ 2.4151, -1.3693, -0.8445],\n",
      "        [-0.9809,  1.1576,  0.1022],\n",
      "        [-3.6764,  0.9537,  3.3785],\n",
      "        [ 2.4151, -1.3693, -0.8445],\n",
      "        [ 2.4151, -1.3693, -0.8445],\n",
      "        [-0.4981, -1.5445,  2.6577]], grad_fn=<AddBackward0>)\n",
      "progress: 904 loss= 0.1170019805431366\n",
      "tensor([[ 2.4162, -1.3702, -0.8449],\n",
      "        [-0.9817,  1.1585,  0.1021],\n",
      "        [-3.6770,  0.9533,  3.3791],\n",
      "        [ 2.4162, -1.3702, -0.8449],\n",
      "        [ 2.4162, -1.3702, -0.8449],\n",
      "        [-0.4982, -1.5455,  2.6586]], grad_fn=<AddBackward0>)\n",
      "progress: 905 loss= 0.1168641448020935\n",
      "tensor([[ 2.4172, -1.3711, -0.8451],\n",
      "        [-0.9816,  1.1581,  0.1022],\n",
      "        [-3.6779,  0.9526,  3.3810],\n",
      "        [ 2.4172, -1.3711, -0.8451],\n",
      "        [ 2.4172, -1.3711, -0.8451],\n",
      "        [-0.4985, -1.5466,  2.6602]], grad_fn=<AddBackward0>)\n",
      "progress: 906 loss= 0.11679676175117493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.4174, -1.3708, -0.8454],\n",
      "        [-0.9825,  1.1599,  0.1017],\n",
      "        [-3.6799,  0.9543,  3.3819],\n",
      "        [ 2.4174, -1.3708, -0.8454],\n",
      "        [ 2.4174, -1.3708, -0.8454],\n",
      "        [-0.4988, -1.5467,  2.6609]], grad_fn=<AddBackward0>)\n",
      "progress: 907 loss= 0.11666832119226456\n",
      "tensor([[ 2.4186, -1.3716, -0.8459],\n",
      "        [-0.9826,  1.1599,  0.1015],\n",
      "        [-3.6805,  0.9539,  3.3825],\n",
      "        [ 2.4186, -1.3716, -0.8459],\n",
      "        [ 2.4186, -1.3716, -0.8459],\n",
      "        [-0.4989, -1.5477,  2.6618]], grad_fn=<AddBackward0>)\n",
      "progress: 908 loss= 0.11658170074224472\n",
      "tensor([[ 2.4181, -1.3711, -0.8460],\n",
      "        [-0.9843,  1.1616,  0.1015],\n",
      "        [-3.6837,  0.9558,  3.3842],\n",
      "        [ 2.4181, -1.3711, -0.8460],\n",
      "        [ 2.4181, -1.3711, -0.8460],\n",
      "        [-0.5003, -1.5475,  2.6633]], grad_fn=<AddBackward0>)\n",
      "progress: 909 loss= 0.11646430939435959\n",
      "tensor([[ 2.4197, -1.3721, -0.8465],\n",
      "        [-0.9836,  1.1615,  0.1011],\n",
      "        [-3.6834,  0.9550,  3.3851],\n",
      "        [ 2.4197, -1.3721, -0.8465],\n",
      "        [ 2.4197, -1.3721, -0.8465],\n",
      "        [-0.4994, -1.5488,  2.6638]], grad_fn=<AddBackward0>)\n",
      "progress: 910 loss= 0.11636870354413986\n",
      "tensor([[ 2.4196, -1.3716, -0.8469],\n",
      "        [-0.9850,  1.1630,  0.1009],\n",
      "        [-3.6863,  0.9572,  3.3855],\n",
      "        [ 2.4196, -1.3716, -0.8469],\n",
      "        [ 2.4196, -1.3716, -0.8469],\n",
      "        [-0.5006, -1.5485,  2.6646]], grad_fn=<AddBackward0>)\n",
      "progress: 911 loss= 0.11627284437417984\n",
      "tensor([[ 2.4209, -1.3726, -0.8474],\n",
      "        [-0.9845,  1.1633,  0.1002],\n",
      "        [-3.6861,  0.9562,  3.3866],\n",
      "        [ 2.4209, -1.3726, -0.8474],\n",
      "        [ 2.4209, -1.3726, -0.8474],\n",
      "        [-0.4998, -1.5499,  2.6654]], grad_fn=<AddBackward0>)\n",
      "progress: 912 loss= 0.11615157872438431\n",
      "tensor([[ 2.4209, -1.3722, -0.8475],\n",
      "        [-0.9857,  1.1644,  0.1006],\n",
      "        [-3.6893,  0.9582,  3.3883],\n",
      "        [ 2.4209, -1.3722, -0.8475],\n",
      "        [ 2.4209, -1.3722, -0.8475],\n",
      "        [-0.5011, -1.5497,  2.6669]], grad_fn=<AddBackward0>)\n",
      "progress: 913 loss= 0.11607394367456436\n",
      "tensor([[ 2.4217, -1.3730, -0.8478],\n",
      "        [-0.9865,  1.1652,  0.1003],\n",
      "        [-3.6899,  0.9577,  3.3889],\n",
      "        [ 2.4217, -1.3730, -0.8478],\n",
      "        [ 2.4217, -1.3730, -0.8478],\n",
      "        [-0.5012, -1.5507,  2.6678]], grad_fn=<AddBackward0>)\n",
      "progress: 914 loss= 0.11594662815332413\n",
      "tensor([[ 2.4221, -1.3727, -0.8483],\n",
      "        [-0.9864,  1.1659,  0.0996],\n",
      "        [-3.6919,  0.9594,  3.3898],\n",
      "        [ 2.4221, -1.3727, -0.8483],\n",
      "        [ 2.4221, -1.3727, -0.8483],\n",
      "        [-0.5015, -1.5508,  2.6685]], grad_fn=<AddBackward0>)\n",
      "progress: 915 loss= 0.11587098240852356\n",
      "tensor([[ 2.4231, -1.3735, -0.8487],\n",
      "        [-0.9873,  1.1667,  0.0996],\n",
      "        [-3.6925,  0.9590,  3.3905],\n",
      "        [ 2.4231, -1.3735, -0.8487],\n",
      "        [ 2.4231, -1.3735, -0.8487],\n",
      "        [-0.5016, -1.5518,  2.6694]], grad_fn=<AddBackward0>)\n",
      "progress: 916 loss= 0.1157454177737236\n",
      "tensor([[ 2.4244, -1.3744, -0.8491],\n",
      "        [-0.9862,  1.1663,  0.0989],\n",
      "        [-3.6923,  0.9580,  3.3916],\n",
      "        [ 2.4244, -1.3744, -0.8491],\n",
      "        [ 2.4244, -1.3744, -0.8491],\n",
      "        [-0.5008, -1.5531,  2.6702]], grad_fn=<AddBackward0>)\n",
      "progress: 917 loss= 0.11566907167434692\n",
      "tensor([[ 2.4244, -1.3741, -0.8492],\n",
      "        [-0.9880,  1.1681,  0.0991],\n",
      "        [-3.6955,  0.9600,  3.3932],\n",
      "        [ 2.4244, -1.3741, -0.8492],\n",
      "        [ 2.4244, -1.3741, -0.8492],\n",
      "        [-0.5022, -1.5530,  2.6717]], grad_fn=<AddBackward0>)\n",
      "progress: 918 loss= 0.11554174870252609\n",
      "tensor([[ 2.4252, -1.3748, -0.8495],\n",
      "        [-0.9882,  1.1683,  0.0990],\n",
      "        [-3.6961,  0.9596,  3.3938],\n",
      "        [ 2.4252, -1.3748, -0.8495],\n",
      "        [ 2.4252, -1.3748, -0.8495],\n",
      "        [-0.5022, -1.5540,  2.6725]], grad_fn=<AddBackward0>)\n",
      "progress: 919 loss= 0.11546370387077332\n",
      "tensor([[ 2.4256, -1.3745, -0.8501],\n",
      "        [-0.9887,  1.1696,  0.0983],\n",
      "        [-3.6981,  0.9613,  3.3948],\n",
      "        [ 2.4256, -1.3745, -0.8501],\n",
      "        [ 2.4256, -1.3745, -0.8501],\n",
      "        [-0.5025, -1.5540,  2.6733]], grad_fn=<AddBackward0>)\n",
      "progress: 920 loss= 0.1153440773487091\n",
      "tensor([[ 2.4266, -1.3754, -0.8503],\n",
      "        [-0.9892,  1.1699,  0.0985],\n",
      "        [-3.6989,  0.9606,  3.3964],\n",
      "        [ 2.4266, -1.3754, -0.8503],\n",
      "        [ 2.4266, -1.3754, -0.8503],\n",
      "        [-0.5027, -1.5551,  2.6746]], grad_fn=<AddBackward0>)\n",
      "progress: 921 loss= 0.11524033546447754\n",
      "tensor([[ 2.4268, -1.3750, -0.8509],\n",
      "        [-0.9894,  1.1710,  0.0976],\n",
      "        [-3.7007,  0.9626,  3.3961],\n",
      "        [ 2.4268, -1.3750, -0.8509],\n",
      "        [ 2.4268, -1.3750, -0.8509],\n",
      "        [-0.5029, -1.5550,  2.6746]], grad_fn=<AddBackward0>)\n",
      "progress: 922 loss= 0.11516469717025757\n",
      "tensor([[ 2.4279, -1.3759, -0.8512],\n",
      "        [-0.9901,  1.1716,  0.0977],\n",
      "        [-3.7016,  0.9619,  3.3979],\n",
      "        [ 2.4279, -1.3759, -0.8512],\n",
      "        [ 2.4279, -1.3759, -0.8512],\n",
      "        [-0.5031, -1.5562,  2.6762]], grad_fn=<AddBackward0>)\n",
      "progress: 923 loss= 0.11502396315336227\n",
      "tensor([[ 2.4275, -1.3754, -0.8511],\n",
      "        [-0.9912,  1.1726,  0.0980],\n",
      "        [-3.7047,  0.9638,  3.3996],\n",
      "        [ 2.4275, -1.3754, -0.8511],\n",
      "        [ 2.4275, -1.3754, -0.8511],\n",
      "        [-0.5045, -1.5560,  2.6777]], grad_fn=<AddBackward0>)\n",
      "progress: 924 loss= 0.11496912688016891\n",
      "tensor([[ 2.4291, -1.3764, -0.8519],\n",
      "        [-0.9910,  1.1733,  0.0970],\n",
      "        [-3.7042,  0.9631,  3.3994],\n",
      "        [ 2.4291, -1.3764, -0.8519],\n",
      "        [ 2.4291, -1.3764, -0.8519],\n",
      "        [-0.5035, -1.5573,  2.6778]], grad_fn=<AddBackward0>)\n",
      "progress: 925 loss= 0.11482813209295273\n",
      "tensor([[ 2.4301, -1.3773, -0.8520],\n",
      "        [-0.9909,  1.1730,  0.0971],\n",
      "        [-3.7051,  0.9624,  3.4013],\n",
      "        [ 2.4301, -1.3773, -0.8520],\n",
      "        [ 2.4301, -1.3773, -0.8520],\n",
      "        [-0.5037, -1.5584,  2.6793]], grad_fn=<AddBackward0>)\n",
      "progress: 926 loss= 0.11475438624620438\n",
      "tensor([[ 2.4302, -1.3769, -0.8524],\n",
      "        [-0.9917,  1.1746,  0.0965],\n",
      "        [-3.7071,  0.9642,  3.4020],\n",
      "        [ 2.4302, -1.3769, -0.8524],\n",
      "        [ 2.4302, -1.3769, -0.8524],\n",
      "        [-0.5039, -1.5584,  2.6798]], grad_fn=<AddBackward0>)\n",
      "progress: 927 loss= 0.11463818699121475\n",
      "tensor([[ 2.4314, -1.3777, -0.8529],\n",
      "        [-0.9918,  1.1747,  0.0964],\n",
      "        [-3.7077,  0.9637,  3.4026],\n",
      "        [ 2.4314, -1.3777, -0.8529],\n",
      "        [ 2.4314, -1.3777, -0.8529],\n",
      "        [-0.5040, -1.5594,  2.6807]], grad_fn=<AddBackward0>)\n",
      "progress: 928 loss= 0.11455412954092026\n",
      "tensor([[ 2.4311, -1.3772, -0.8531],\n",
      "        [-0.9934,  1.1763,  0.0964],\n",
      "        [-3.7108,  0.9657,  3.4042],\n",
      "        [ 2.4311, -1.3772, -0.8531],\n",
      "        [ 2.4311, -1.3772, -0.8531],\n",
      "        [-0.5054, -1.5592,  2.6821]], grad_fn=<AddBackward0>)\n",
      "progress: 929 loss= 0.11443662643432617\n",
      "tensor([[ 2.4325, -1.3782, -0.8536],\n",
      "        [-0.9928,  1.1763,  0.0959],\n",
      "        [-3.7105,  0.9648,  3.4051],\n",
      "        [ 2.4325, -1.3782, -0.8536],\n",
      "        [ 2.4325, -1.3782, -0.8536],\n",
      "        [-0.5045, -1.5606,  2.6827]], grad_fn=<AddBackward0>)\n",
      "progress: 930 loss= 0.11434131115674973\n",
      "tensor([[ 2.4325, -1.3778, -0.8540],\n",
      "        [-0.9941,  1.1778,  0.0957],\n",
      "        [-3.7134,  0.9669,  3.4055],\n",
      "        [ 2.4325, -1.3778, -0.8540],\n",
      "        [ 2.4325, -1.3778, -0.8540],\n",
      "        [-0.5057, -1.5603,  2.6835]], grad_fn=<AddBackward0>)\n",
      "progress: 931 loss= 0.11425086855888367\n",
      "tensor([[ 2.4337, -1.3787, -0.8543],\n",
      "        [-0.9937,  1.1780,  0.0951],\n",
      "        [-3.7131,  0.9660,  3.4066],\n",
      "        [ 2.4337, -1.3787, -0.8543],\n",
      "        [ 2.4337, -1.3787, -0.8543],\n",
      "        [-0.5049, -1.5616,  2.6843]], grad_fn=<AddBackward0>)\n",
      "progress: 932 loss= 0.114134281873703\n",
      "tensor([[ 2.4337, -1.3783, -0.8545],\n",
      "        [-0.9949,  1.1791,  0.0954],\n",
      "        [-3.7162,  0.9679,  3.4083],\n",
      "        [ 2.4337, -1.3783, -0.8545],\n",
      "        [ 2.4337, -1.3783, -0.8545],\n",
      "        [-0.5062, -1.5615,  2.6858]], grad_fn=<AddBackward0>)\n",
      "progress: 933 loss= 0.11405808478593826\n",
      "tensor([[ 2.4346, -1.3791, -0.8549],\n",
      "        [-0.9957,  1.1800,  0.0951],\n",
      "        [-3.7168,  0.9675,  3.4089],\n",
      "        [ 2.4346, -1.3791, -0.8549],\n",
      "        [ 2.4346, -1.3791, -0.8549],\n",
      "        [-0.5063, -1.5625,  2.6866]], grad_fn=<AddBackward0>)\n",
      "progress: 934 loss= 0.11392795294523239\n",
      "tensor([[ 2.4348, -1.3787, -0.8554],\n",
      "        [-0.9955,  1.1806,  0.0944],\n",
      "        [-3.7189,  0.9691,  3.4098],\n",
      "        [ 2.4348, -1.3787, -0.8554],\n",
      "        [ 2.4348, -1.3787, -0.8554],\n",
      "        [-0.5066, -1.5625,  2.6874]], grad_fn=<AddBackward0>)\n",
      "progress: 935 loss= 0.11386027187108994\n",
      "tensor([[ 2.4360, -1.3796, -0.8556],\n",
      "        [-0.9965,  1.1814,  0.0947],\n",
      "        [-3.7197,  0.9685,  3.4114],\n",
      "        [ 2.4360, -1.3796, -0.8556],\n",
      "        [ 2.4360, -1.3796, -0.8556],\n",
      "        [-0.5068, -1.5636,  2.6887]], grad_fn=<AddBackward0>)\n",
      "progress: 936 loss= 0.11372650414705276\n",
      "tensor([[ 2.4371, -1.3805, -0.8560],\n",
      "        [-0.9954,  1.1811,  0.0938],\n",
      "        [-3.7192,  0.9678,  3.4113],\n",
      "        [ 2.4371, -1.3805, -0.8560],\n",
      "        [ 2.4371, -1.3805, -0.8560],\n",
      "        [-0.5058, -1.5649,  2.6888]], grad_fn=<AddBackward0>)\n",
      "progress: 937 loss= 0.11366957426071167\n",
      "tensor([[ 2.4372, -1.3801, -0.8564],\n",
      "        [-0.9971,  1.1828,  0.0938],\n",
      "        [-3.7223,  0.9697,  3.4129],\n",
      "        [ 2.4372, -1.3801, -0.8564],\n",
      "        [ 2.4372, -1.3801, -0.8564],\n",
      "        [-0.5071, -1.5647,  2.6903]], grad_fn=<AddBackward0>)\n",
      "progress: 938 loss= 0.11353396624326706\n",
      "tensor([[ 2.4380, -1.3810, -0.8564],\n",
      "        [-0.9975,  1.1829,  0.0942],\n",
      "        [-3.7231,  0.9690,  3.4148],\n",
      "        [ 2.4380, -1.3810, -0.8564],\n",
      "        [ 2.4380, -1.3810, -0.8564],\n",
      "        [-0.5074, -1.5659,  2.6918]], grad_fn=<AddBackward0>)\n",
      "progress: 939 loss= 0.11345749348402023\n",
      "tensor([[ 2.4383, -1.3806, -0.8571],\n",
      "        [-0.9978,  1.1843,  0.0931],\n",
      "        [-3.7249,  0.9710,  3.4145],\n",
      "        [ 2.4383, -1.3806, -0.8571],\n",
      "        [ 2.4383, -1.3806, -0.8571],\n",
      "        [-0.5075, -1.5658,  2.6918]], grad_fn=<AddBackward0>)\n",
      "progress: 940 loss= 0.11335425823926926\n",
      "tensor([[ 2.4394, -1.3815, -0.8574],\n",
      "        [-0.9983,  1.1847,  0.0933],\n",
      "        [-3.7257,  0.9703,  3.4163],\n",
      "        [ 2.4394, -1.3815, -0.8574],\n",
      "        [ 2.4394, -1.3815, -0.8574],\n",
      "        [-0.5077, -1.5669,  2.6934]], grad_fn=<AddBackward0>)\n",
      "progress: 941 loss= 0.11323511600494385\n",
      "tensor([[ 2.4391, -1.3810, -0.8576],\n",
      "        [-0.9996,  1.1859,  0.0932],\n",
      "        [-3.7286,  0.9724,  3.4167],\n",
      "        [ 2.4391, -1.3810, -0.8576],\n",
      "        [ 2.4391, -1.3810, -0.8576],\n",
      "        [-0.5089, -1.5666,  2.6942]], grad_fn=<AddBackward0>)\n",
      "progress: 942 loss= 0.11317335814237595\n",
      "tensor([[ 2.4406, -1.3819, -0.8581],\n",
      "        [-0.9993,  1.1863,  0.0925],\n",
      "        [-3.7283,  0.9715,  3.4178],\n",
      "        [ 2.4406, -1.3819, -0.8581],\n",
      "        [ 2.4406, -1.3819, -0.8581],\n",
      "        [-0.5081, -1.5680,  2.6950]], grad_fn=<AddBackward0>)\n",
      "progress: 943 loss= 0.11303394287824631\n",
      "tensor([[ 2.4404, -1.3815, -0.8582],\n",
      "        [-1.0003,  1.1873,  0.0928],\n",
      "        [-3.7314,  0.9734,  3.4195],\n",
      "        [ 2.4404, -1.3815, -0.8582],\n",
      "        [ 2.4404, -1.3815, -0.8582],\n",
      "        [-0.5094, -1.5678,  2.6965]], grad_fn=<AddBackward0>)\n",
      "progress: 944 loss= 0.11297214776277542\n",
      "tensor([[ 2.4417, -1.3824, -0.8588],\n",
      "        [-1.0001,  1.1879,  0.0918],\n",
      "        [-3.7309,  0.9727,  3.4193],\n",
      "        [ 2.4417, -1.3824, -0.8588],\n",
      "        [ 2.4417, -1.3824, -0.8588],\n",
      "        [-0.5084, -1.5691,  2.6965]], grad_fn=<AddBackward0>)\n",
      "progress: 945 loss= 0.11284605413675308\n",
      "tensor([[ 2.4429, -1.3833, -0.8591],\n",
      "        [-1.0000,  1.1877,  0.0919],\n",
      "        [-3.7318,  0.9720,  3.4211],\n",
      "        [ 2.4429, -1.3833, -0.8591],\n",
      "        [ 2.4429, -1.3833, -0.8591],\n",
      "        [-0.5087, -1.5702,  2.6981]], grad_fn=<AddBackward0>)\n",
      "progress: 946 loss= 0.11276600509881973\n",
      "tensor([[ 2.4425, -1.3828, -0.8592],\n",
      "        [-1.0019,  1.1895,  0.0921],\n",
      "        [-3.7348,  0.9740,  3.4226],\n",
      "        [ 2.4425, -1.3828, -0.8592],\n",
      "        [ 2.4425, -1.3828, -0.8592],\n",
      "        [-0.5100, -1.5700,  2.6993]], grad_fn=<AddBackward0>)\n",
      "progress: 947 loss= 0.11265251040458679\n",
      "tensor([[ 2.4440, -1.3838, -0.8598],\n",
      "        [-1.0009,  1.1894,  0.0913],\n",
      "        [-3.7343,  0.9733,  3.4224],\n",
      "        [ 2.4440, -1.3838, -0.8598],\n",
      "        [ 2.4440, -1.3838, -0.8598],\n",
      "        [-0.5090, -1.5712,  2.6994]], grad_fn=<AddBackward0>)\n",
      "progress: 948 loss= 0.11257553100585938\n",
      "tensor([[ 2.4439, -1.3833, -0.8601],\n",
      "        [-1.0025,  1.1910,  0.0913],\n",
      "        [-3.7374,  0.9752,  3.4241],\n",
      "        [ 2.4439, -1.3833, -0.8601],\n",
      "        [ 2.4439, -1.3833, -0.8601],\n",
      "        [-0.5103, -1.5711,  2.7009]], grad_fn=<AddBackward0>)\n",
      "progress: 949 loss= 0.11245592683553696\n",
      "tensor([[ 2.4451, -1.3843, -0.8603],\n",
      "        [-1.0019,  1.1910,  0.0909],\n",
      "        [-3.7372,  0.9742,  3.4252],\n",
      "        [ 2.4451, -1.3843, -0.8603],\n",
      "        [ 2.4451, -1.3843, -0.8603],\n",
      "        [-0.5095, -1.5725,  2.7017]], grad_fn=<AddBackward0>)\n",
      "progress: 950 loss= 0.11237266659736633\n",
      "tensor([[ 2.4452, -1.3838, -0.8609],\n",
      "        [-1.0032,  1.1924,  0.0906],\n",
      "        [-3.7400,  0.9764,  3.4256],\n",
      "        [ 2.4452, -1.3838, -0.8609],\n",
      "        [ 2.4452, -1.3838, -0.8609],\n",
      "        [-0.5107, -1.5722,  2.7025]], grad_fn=<AddBackward0>)\n",
      "progress: 951 loss= 0.11227438598871231\n",
      "tensor([[ 2.4460, -1.3847, -0.8609],\n",
      "        [-1.0038,  1.1929,  0.0906],\n",
      "        [-3.7408,  0.9757,  3.4274],\n",
      "        [ 2.4460, -1.3847, -0.8609],\n",
      "        [ 2.4460, -1.3847, -0.8609],\n",
      "        [-0.5109, -1.5733,  2.7040]], grad_fn=<AddBackward0>)\n",
      "progress: 952 loss= 0.11215579509735107\n",
      "tensor([[ 2.4463, -1.3843, -0.8615],\n",
      "        [-1.0039,  1.1937,  0.0902],\n",
      "        [-3.7428,  0.9774,  3.4281],\n",
      "        [ 2.4463, -1.3843, -0.8615],\n",
      "        [ 2.4463, -1.3843, -0.8615],\n",
      "        [-0.5111, -1.5733,  2.7045]], grad_fn=<AddBackward0>)\n",
      "progress: 953 loss= 0.11208978295326233\n",
      "tensor([[ 2.4474, -1.3852, -0.8619],\n",
      "        [-1.0047,  1.1946,  0.0900],\n",
      "        [-3.7433,  0.9769,  3.4287],\n",
      "        [ 2.4474, -1.3852, -0.8619],\n",
      "        [ 2.4474, -1.3852, -0.8619],\n",
      "        [-0.5112, -1.5743,  2.7054]], grad_fn=<AddBackward0>)\n",
      "progress: 954 loss= 0.11195719987154007\n",
      "tensor([[ 2.4486, -1.3861, -0.8622],\n",
      "        [-1.0036,  1.1940,  0.0893],\n",
      "        [-3.7431,  0.9760,  3.4298],\n",
      "        [ 2.4486, -1.3861, -0.8622],\n",
      "        [ 2.4486, -1.3861, -0.8622],\n",
      "        [-0.5103, -1.5757,  2.7062]], grad_fn=<AddBackward0>)\n",
      "progress: 955 loss= 0.11189920455217361\n",
      "tensor([[ 2.4485, -1.3857, -0.8623],\n",
      "        [-1.0055,  1.1959,  0.0897],\n",
      "        [-3.7462,  0.9779,  3.4314],\n",
      "        [ 2.4485, -1.3857, -0.8623],\n",
      "        [ 2.4485, -1.3857, -0.8623],\n",
      "        [-0.5117, -1.5755,  2.7076]], grad_fn=<AddBackward0>)\n",
      "progress: 956 loss= 0.11177513003349304\n",
      "tensor([[ 2.4495, -1.3865, -0.8628],\n",
      "        [-1.0055,  1.1959,  0.0894],\n",
      "        [-3.7467,  0.9774,  3.4320],\n",
      "        [ 2.4495, -1.3865, -0.8628],\n",
      "        [ 2.4495, -1.3865, -0.8628],\n",
      "        [-0.5117, -1.5765,  2.7085]], grad_fn=<AddBackward0>)\n",
      "progress: 957 loss= 0.11169832944869995\n",
      "tensor([[ 2.4497, -1.3861, -0.8632],\n",
      "        [-1.0061,  1.1974,  0.0887],\n",
      "        [-3.7488,  0.9791,  3.4329],\n",
      "        [ 2.4497, -1.3861, -0.8632],\n",
      "        [ 2.4497, -1.3861, -0.8632],\n",
      "        [-0.5120, -1.5766,  2.7092]], grad_fn=<AddBackward0>)\n",
      "progress: 958 loss= 0.1115821972489357\n",
      "tensor([[ 2.4509, -1.3870, -0.8636],\n",
      "        [-1.0064,  1.1976,  0.0887],\n",
      "        [-3.7493,  0.9786,  3.4335],\n",
      "        [ 2.4509, -1.3870, -0.8636],\n",
      "        [ 2.4509, -1.3870, -0.8636],\n",
      "        [-0.5121, -1.5776,  2.7100]], grad_fn=<AddBackward0>)\n",
      "progress: 959 loss= 0.11149609833955765\n",
      "tensor([[ 2.4505, -1.3865, -0.8637],\n",
      "        [-1.0079,  1.1991,  0.0887],\n",
      "        [-3.7524,  0.9805,  3.4352],\n",
      "        [ 2.4505, -1.3865, -0.8637],\n",
      "        [ 2.4505, -1.3865, -0.8637],\n",
      "        [-0.5134, -1.5775,  2.7115]], grad_fn=<AddBackward0>)\n",
      "progress: 960 loss= 0.11140066385269165\n",
      "tensor([[ 2.4520, -1.3875, -0.8640],\n",
      "        [-1.0074,  1.1992,  0.0883],\n",
      "        [-3.7521,  0.9796,  3.4362],\n",
      "        [ 2.4520, -1.3875, -0.8640],\n",
      "        [ 2.4520, -1.3875, -0.8640],\n",
      "        [-0.5126, -1.5788,  2.7123]], grad_fn=<AddBackward0>)\n",
      "progress: 961 loss= 0.11129298806190491\n",
      "tensor([[ 2.4518, -1.3870, -0.8646],\n",
      "        [-1.0085,  1.2005,  0.0880],\n",
      "        [-3.7549,  0.9817,  3.4367],\n",
      "        [ 2.4518, -1.3870, -0.8646],\n",
      "        [ 2.4518, -1.3870, -0.8646],\n",
      "        [-0.5138, -1.5785,  2.7130]], grad_fn=<AddBackward0>)\n",
      "progress: 962 loss= 0.11121582239866257\n",
      "tensor([[ 2.4531, -1.3879, -0.8649],\n",
      "        [-1.0082,  1.2009,  0.0874],\n",
      "        [-3.7547,  0.9808,  3.4377],\n",
      "        [ 2.4531, -1.3879, -0.8649],\n",
      "        [ 2.4531, -1.3879, -0.8649],\n",
      "        [-0.5129, -1.5799,  2.7139]], grad_fn=<AddBackward0>)\n",
      "progress: 963 loss= 0.11108767986297607\n",
      "tensor([[ 2.4531, -1.3875, -0.8652],\n",
      "        [-1.0092,  1.2018,  0.0875],\n",
      "        [-3.7577,  0.9827,  3.4392],\n",
      "        [ 2.4531, -1.3875, -0.8652],\n",
      "        [ 2.4531, -1.3875, -0.8652],\n",
      "        [-0.5142, -1.5797,  2.7151]], grad_fn=<AddBackward0>)\n",
      "progress: 964 loss= 0.11102339625358582\n",
      "tensor([[ 2.4539, -1.3883, -0.8654],\n",
      "        [-1.0101,  1.2027,  0.0874],\n",
      "        [-3.7583,  0.9823,  3.4397],\n",
      "        [ 2.4539, -1.3883, -0.8654],\n",
      "        [ 2.4539, -1.3883, -0.8654],\n",
      "        [-0.5143, -1.5807,  2.7159]], grad_fn=<AddBackward0>)\n",
      "progress: 965 loss= 0.11090803146362305\n",
      "tensor([[ 2.4554, -1.3893, -0.8660],\n",
      "        [-1.0090,  1.2022,  0.0868],\n",
      "        [-3.7580,  0.9813,  3.4408],\n",
      "        [ 2.4554, -1.3893, -0.8660],\n",
      "        [ 2.4554, -1.3893, -0.8660],\n",
      "        [-0.5134, -1.5821,  2.7167]], grad_fn=<AddBackward0>)\n",
      "progress: 966 loss= 0.11082897335290909\n",
      "tensor([[ 2.4552, -1.3889, -0.8660],\n",
      "        [-1.0108,  1.2040,  0.0871],\n",
      "        [-3.7611,  0.9832,  3.4425],\n",
      "        [ 2.4552, -1.3889, -0.8660],\n",
      "        [ 2.4552, -1.3889, -0.8660],\n",
      "        [-0.5148, -1.5820,  2.7182]], grad_fn=<AddBackward0>)\n",
      "progress: 967 loss= 0.1107177808880806\n",
      "tensor([[ 2.4566, -1.3897, -0.8667],\n",
      "        [-1.0099,  1.2039,  0.0861],\n",
      "        [-3.7606,  0.9825,  3.4423],\n",
      "        [ 2.4566, -1.3897, -0.8667],\n",
      "        [ 2.4566, -1.3897, -0.8667],\n",
      "        [-0.5137, -1.5832,  2.7183]], grad_fn=<AddBackward0>)\n",
      "progress: 968 loss= 0.11063840240240097\n",
      "tensor([[ 2.4565, -1.3893, -0.8669],\n",
      "        [-1.0114,  1.2055,  0.0861],\n",
      "        [-3.7636,  0.9844,  3.4440],\n",
      "        [ 2.4565, -1.3893, -0.8669],\n",
      "        [ 2.4565, -1.3893, -0.8669],\n",
      "        [-0.5151, -1.5830,  2.7197]], grad_fn=<AddBackward0>)\n",
      "progress: 969 loss= 0.11052241921424866\n",
      "tensor([[ 2.4574, -1.3901, -0.8672],\n",
      "        [-1.0119,  1.2058,  0.0861],\n",
      "        [-3.7642,  0.9839,  3.4445],\n",
      "        [ 2.4574, -1.3901, -0.8672],\n",
      "        [ 2.4574, -1.3901, -0.8672],\n",
      "        [-0.5151, -1.5840,  2.7205]], grad_fn=<AddBackward0>)\n",
      "progress: 970 loss= 0.11044350266456604\n",
      "tensor([[ 2.4577, -1.3898, -0.8677],\n",
      "        [-1.0121,  1.2069,  0.0854],\n",
      "        [-3.7662,  0.9856,  3.4455],\n",
      "        [ 2.4577, -1.3898, -0.8677],\n",
      "        [ 2.4577, -1.3898, -0.8677],\n",
      "        [-0.5154, -1.5841,  2.7213]], grad_fn=<AddBackward0>)\n",
      "progress: 971 loss= 0.11034607887268066\n",
      "tensor([[ 2.4587, -1.3907, -0.8677],\n",
      "        [-1.0128,  1.2074,  0.0856],\n",
      "        [-3.7670,  0.9849,  3.4472],\n",
      "        [ 2.4587, -1.3907, -0.8677],\n",
      "        [ 2.4587, -1.3907, -0.8677],\n",
      "        [-0.5156, -1.5853,  2.7228]], grad_fn=<AddBackward0>)\n",
      "progress: 972 loss= 0.11023068428039551\n",
      "tensor([[ 2.4588, -1.3903, -0.8684],\n",
      "        [-1.0128,  1.2083,  0.0848],\n",
      "        [-3.7687,  0.9867,  3.4470],\n",
      "        [ 2.4588, -1.3903, -0.8684],\n",
      "        [ 2.4588, -1.3903, -0.8684],\n",
      "        [-0.5157, -1.5852,  2.7228]], grad_fn=<AddBackward0>)\n",
      "progress: 973 loss= 0.11017324775457382\n",
      "tensor([[ 2.4599, -1.3912, -0.8686],\n",
      "        [-1.0136,  1.2091,  0.0848],\n",
      "        [-3.7695,  0.9860,  3.4488],\n",
      "        [ 2.4599, -1.3912, -0.8686],\n",
      "        [ 2.4599, -1.3912, -0.8686],\n",
      "        [-0.5159, -1.5864,  2.7244]], grad_fn=<AddBackward0>)\n",
      "progress: 974 loss= 0.11003053188323975\n",
      "tensor([[ 2.4608, -1.3920, -0.8687],\n",
      "        [-1.0135,  1.2088,  0.0850],\n",
      "        [-3.7703,  0.9854,  3.4503],\n",
      "        [ 2.4608, -1.3920, -0.8687],\n",
      "        [ 2.4608, -1.3920, -0.8687],\n",
      "        [-0.5161, -1.5874,  2.7257]], grad_fn=<AddBackward0>)\n",
      "progress: 975 loss= 0.1099785789847374\n",
      "tensor([[ 2.4611, -1.3916, -0.8694],\n",
      "        [-1.0143,  1.2105,  0.0841],\n",
      "        [-3.7720,  0.9873,  3.4500],\n",
      "        [ 2.4611, -1.3916, -0.8694],\n",
      "        [ 2.4611, -1.3916, -0.8694],\n",
      "        [-0.5162, -1.5874,  2.7257]], grad_fn=<AddBackward0>)\n",
      "progress: 976 loss= 0.10986217856407166\n",
      "tensor([[ 2.4622, -1.3925, -0.8697],\n",
      "        [-1.0144,  1.2104,  0.0842],\n",
      "        [-3.7728,  0.9865,  3.4518],\n",
      "        [ 2.4622, -1.3925, -0.8697],\n",
      "        [ 2.4622, -1.3925, -0.8697],\n",
      "        [-0.5164, -1.5885,  2.7272]], grad_fn=<AddBackward0>)\n",
      "progress: 977 loss= 0.10977313667535782\n",
      "tensor([[ 2.4622, -1.3921, -0.8700],\n",
      "        [-1.0150,  1.2119,  0.0835],\n",
      "        [-3.7747,  0.9882,  3.4525],\n",
      "        [ 2.4622, -1.3921, -0.8700],\n",
      "        [ 2.4622, -1.3921, -0.8700],\n",
      "        [-0.5167, -1.5886,  2.7277]], grad_fn=<AddBackward0>)\n",
      "progress: 978 loss= 0.109671950340271\n",
      "tensor([[ 2.4633, -1.3929, -0.8704],\n",
      "        [-1.0153,  1.2121,  0.0835],\n",
      "        [-3.7753,  0.9878,  3.4531],\n",
      "        [ 2.4633, -1.3929, -0.8704],\n",
      "        [ 2.4633, -1.3929, -0.8704],\n",
      "        [-0.5167, -1.5896,  2.7286]], grad_fn=<AddBackward0>)\n",
      "progress: 979 loss= 0.1095908060669899\n",
      "tensor([[ 2.4632, -1.3925, -0.8707],\n",
      "        [-1.0167,  1.2135,  0.0835],\n",
      "        [-3.7783,  0.9896,  3.4547],\n",
      "        [ 2.4632, -1.3925, -0.8707],\n",
      "        [ 2.4632, -1.3925, -0.8707],\n",
      "        [-0.5180, -1.5894,  2.7300]], grad_fn=<AddBackward0>)\n",
      "progress: 980 loss= 0.10948903113603592\n",
      "tensor([[ 2.4644, -1.3934, -0.8709],\n",
      "        [-1.0163,  1.2137,  0.0830],\n",
      "        [-3.7781,  0.9887,  3.4558],\n",
      "        [ 2.4644, -1.3934, -0.8709],\n",
      "        [ 2.4644, -1.3934, -0.8709],\n",
      "        [-0.5172, -1.5908,  2.7308]], grad_fn=<AddBackward0>)\n",
      "progress: 981 loss= 0.10938870906829834\n",
      "tensor([[ 2.4645, -1.3930, -0.8715],\n",
      "        [-1.0174,  1.2149,  0.0829],\n",
      "        [-3.7808,  0.9908,  3.4562],\n",
      "        [ 2.4645, -1.3930, -0.8715],\n",
      "        [ 2.4645, -1.3930, -0.8715],\n",
      "        [-0.5183, -1.5905,  2.7316]], grad_fn=<AddBackward0>)\n",
      "progress: 982 loss= 0.10931094735860825\n",
      "tensor([[ 2.4652, -1.3938, -0.8715],\n",
      "        [-1.0182,  1.2156,  0.0829],\n",
      "        [-3.7816,  0.9901,  3.4580],\n",
      "        [ 2.4652, -1.3938, -0.8715],\n",
      "        [ 2.4652, -1.3938, -0.8715],\n",
      "        [-0.5185, -1.5917,  2.7331]], grad_fn=<AddBackward0>)\n",
      "progress: 983 loss= 0.10918828099966049\n",
      "tensor([[ 2.4656, -1.3935, -0.8720],\n",
      "        [-1.0181,  1.2163,  0.0823],\n",
      "        [-3.7836,  0.9918,  3.4587],\n",
      "        [ 2.4656, -1.3935, -0.8720],\n",
      "        [ 2.4656, -1.3935, -0.8720],\n",
      "        [-0.5188, -1.5917,  2.7336]], grad_fn=<AddBackward0>)\n",
      "progress: 984 loss= 0.10912624001502991\n",
      "tensor([[ 2.4666, -1.3943, -0.8724],\n",
      "        [-1.0189,  1.2171,  0.0822],\n",
      "        [-3.7841,  0.9913,  3.4593],\n",
      "        [ 2.4666, -1.3943, -0.8724],\n",
      "        [ 2.4666, -1.3943, -0.8724],\n",
      "        [-0.5188, -1.5927,  2.7344]], grad_fn=<AddBackward0>)\n",
      "progress: 985 loss= 0.10900750756263733\n",
      "tensor([[ 2.4678, -1.3952, -0.8727],\n",
      "        [-1.0178,  1.2167,  0.0816],\n",
      "        [-3.7838,  0.9903,  3.4603],\n",
      "        [ 2.4678, -1.3952, -0.8727],\n",
      "        [ 2.4678, -1.3952, -0.8727],\n",
      "        [-0.5180, -1.5941,  2.7352]], grad_fn=<AddBackward0>)\n",
      "progress: 986 loss= 0.10893938690423965\n",
      "tensor([[ 2.4678, -1.3948, -0.8729],\n",
      "        [-1.0196,  1.2184,  0.0818],\n",
      "        [-3.7869,  0.9922,  3.4619],\n",
      "        [ 2.4678, -1.3948, -0.8729],\n",
      "        [ 2.4678, -1.3948, -0.8729],\n",
      "        [-0.5193, -1.5939,  2.7367]], grad_fn=<AddBackward0>)\n",
      "progress: 987 loss= 0.10882294178009033\n",
      "tensor([[ 2.4687, -1.3956, -0.8732],\n",
      "        [-1.0198,  1.2186,  0.0817],\n",
      "        [-3.7874,  0.9917,  3.4625],\n",
      "        [ 2.4687, -1.3956, -0.8732],\n",
      "        [ 2.4687, -1.3956, -0.8732],\n",
      "        [-0.5193, -1.5949,  2.7375]], grad_fn=<AddBackward0>)\n",
      "progress: 988 loss= 0.10874833911657333\n",
      "tensor([[ 2.4689, -1.3952, -0.8737],\n",
      "        [-1.0202,  1.2199,  0.0809],\n",
      "        [-3.7894,  0.9934,  3.4634],\n",
      "        [ 2.4689, -1.3952, -0.8737],\n",
      "        [ 2.4689, -1.3952, -0.8737],\n",
      "        [-0.5196, -1.5950,  2.7382]], grad_fn=<AddBackward0>)\n",
      "progress: 989 loss= 0.10863876342773438\n",
      "tensor([[ 2.4700, -1.3961, -0.8739],\n",
      "        [-1.0207,  1.2202,  0.0812],\n",
      "        [-3.7901,  0.9927,  3.4650],\n",
      "        [ 2.4700, -1.3961, -0.8739],\n",
      "        [ 2.4700, -1.3961, -0.8739],\n",
      "        [-0.5197, -1.5961,  2.7395]], grad_fn=<AddBackward0>)\n",
      "progress: 990 loss= 0.10854389518499374\n",
      "tensor([[ 2.4701, -1.3957, -0.8745],\n",
      "        [-1.0209,  1.2213,  0.0803],\n",
      "        [-3.7918,  0.9946,  3.4647],\n",
      "        [ 2.4701, -1.3957, -0.8745],\n",
      "        [ 2.4701, -1.3957, -0.8745],\n",
      "        [-0.5199, -1.5961,  2.7395]], grad_fn=<AddBackward0>)\n",
      "progress: 991 loss= 0.10847396403551102\n",
      "tensor([[ 2.4712, -1.3966, -0.8748],\n",
      "        [-1.0216,  1.2219,  0.0803],\n",
      "        [-3.7926,  0.9939,  3.4665],\n",
      "        [ 2.4712, -1.3966, -0.8748],\n",
      "        [ 2.4712, -1.3966, -0.8748],\n",
      "        [-0.5201, -1.5972,  2.7410]], grad_fn=<AddBackward0>)\n",
      "progress: 992 loss= 0.10834620147943497\n",
      "tensor([[ 2.4709, -1.3962, -0.8748],\n",
      "        [-1.0227,  1.2228,  0.0807],\n",
      "        [-3.7956,  0.9957,  3.4681],\n",
      "        [ 2.4709, -1.3962, -0.8748],\n",
      "        [ 2.4709, -1.3962, -0.8748],\n",
      "        [-0.5214, -1.5971,  2.7425]], grad_fn=<AddBackward0>)\n",
      "progress: 993 loss= 0.10829181224107742\n",
      "tensor([[ 2.4723, -1.3970, -0.8755],\n",
      "        [-1.0224,  1.2235,  0.0796],\n",
      "        [-3.7951,  0.9950,  3.4679],\n",
      "        [ 2.4723, -1.3970, -0.8755],\n",
      "        [ 2.4723, -1.3970, -0.8755],\n",
      "        [-0.5204, -1.5983,  2.7426]], grad_fn=<AddBackward0>)\n",
      "progress: 994 loss= 0.10816353559494019\n",
      "tensor([[ 2.4734, -1.3979, -0.8757],\n",
      "        [-1.0223,  1.2231,  0.0798],\n",
      "        [-3.7959,  0.9943,  3.4697],\n",
      "        [ 2.4734, -1.3979, -0.8757],\n",
      "        [ 2.4734, -1.3979, -0.8757],\n",
      "        [-0.5206, -1.5994,  2.7441]], grad_fn=<AddBackward0>)\n",
      "progress: 995 loss= 0.10809653252363205\n",
      "tensor([[ 2.4730, -1.3974, -0.8759],\n",
      "        [-1.0241,  1.2251,  0.0797],\n",
      "        [-3.7986,  0.9964,  3.4701],\n",
      "        [ 2.4730, -1.3974, -0.8759],\n",
      "        [ 2.4730, -1.3974, -0.8759],\n",
      "        [-0.5217, -1.5992,  2.7448]], grad_fn=<AddBackward0>)\n",
      "progress: 996 loss= 0.10799458622932434\n",
      "tensor([[ 2.4745, -1.3983, -0.8764],\n",
      "        [-1.0232,  1.2248,  0.0790],\n",
      "        [-3.7984,  0.9954,  3.4712],\n",
      "        [ 2.4745, -1.3983, -0.8764],\n",
      "        [ 2.4745, -1.3983, -0.8764],\n",
      "        [-0.5209, -1.6005,  2.7456]], grad_fn=<AddBackward0>)\n",
      "progress: 997 loss= 0.1079087182879448\n",
      "tensor([[ 2.4743, -1.3979, -0.8765],\n",
      "        [-1.0248,  1.2264,  0.0792],\n",
      "        [-3.8014,  0.9973,  3.4728],\n",
      "        [ 2.4743, -1.3979, -0.8765],\n",
      "        [ 2.4743, -1.3979, -0.8765],\n",
      "        [-0.5222, -1.6004,  2.7471]], grad_fn=<AddBackward0>)\n",
      "progress: 998 loss= 0.1078045666217804\n",
      "tensor([[ 2.4756, -1.3988, -0.8771],\n",
      "        [-1.0240,  1.2264,  0.0784],\n",
      "        [-3.8008,  0.9966,  3.4727],\n",
      "        [ 2.4756, -1.3988, -0.8771],\n",
      "        [ 2.4756, -1.3988, -0.8771],\n",
      "        [-0.5212, -1.6016,  2.7472]], grad_fn=<AddBackward0>)\n",
      "progress: 999 loss= 0.10772519558668137\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    output = model(x_data)\n",
    "    print(output)\n",
    "    loss = criterion(output, y_data)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(\"progress:\", epoch, \"loss=\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a901868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './weights/'\n",
    "\n",
    "torch.save(model, 'model.pt')  # 전체 모델 저장\n",
    "torch.save(model.state_dict(), 'model_state_dict.pt')  # 모델 객체의 state_dict 저장\n",
    "torch.save({\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict()\n",
    "}, 'all.tar')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1460263b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
